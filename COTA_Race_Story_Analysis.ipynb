{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NUMBER</th>\n",
              "      <th>DRIVER_NUMBER</th>\n",
              "      <th>LAP_NUMBER</th>\n",
              "      <th>LAP_TIME</th>\n",
              "      <th>LAP_IMPROVEMENT</th>\n",
              "      <th>CROSSING_FINISH_LINE_IN_PIT</th>\n",
              "      <th>S1</th>\n",
              "      <th>S1_IMPROVEMENT</th>\n",
              "      <th>S2</th>\n",
              "      <th>S2_IMPROVEMENT</th>\n",
              "      <th>...</th>\n",
              "      <th>IM1_time</th>\n",
              "      <th>IM1_elapsed</th>\n",
              "      <th>IM2a_time</th>\n",
              "      <th>IM2a_elapsed</th>\n",
              "      <th>IM2_time</th>\n",
              "      <th>IM2_elapsed</th>\n",
              "      <th>IM3a_time</th>\n",
              "      <th>IM3a_elapsed</th>\n",
              "      <th>FL_time</th>\n",
              "      <th>FL_elapsed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3:46.084</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>53.893</td>\n",
              "      <td>0</td>\n",
              "      <td>1:28.398</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>53.893</td>\n",
              "      <td>32.095</td>\n",
              "      <td>1:25.988</td>\n",
              "      <td>56.303</td>\n",
              "      <td>2:22.291</td>\n",
              "      <td>36.726</td>\n",
              "      <td>2:59.017</td>\n",
              "      <td>47.067</td>\n",
              "      <td>3:46.084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2:48.736</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>45.381</td>\n",
              "      <td>0</td>\n",
              "      <td>1:00.988</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>14.439</td>\n",
              "      <td>45.381</td>\n",
              "      <td>24.320</td>\n",
              "      <td>1:09.701</td>\n",
              "      <td>36.668</td>\n",
              "      <td>1:46.369</td>\n",
              "      <td>30.435</td>\n",
              "      <td>2:16.804</td>\n",
              "      <td>31.932</td>\n",
              "      <td>2:48.736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2:36.896</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>33.659</td>\n",
              "      <td>0</td>\n",
              "      <td>1:01.873</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>12.848</td>\n",
              "      <td>33.659</td>\n",
              "      <td>25.793</td>\n",
              "      <td>59.452</td>\n",
              "      <td>36.080</td>\n",
              "      <td>1:35.532</td>\n",
              "      <td>28.996</td>\n",
              "      <td>2:04.528</td>\n",
              "      <td>32.368</td>\n",
              "      <td>2:36.896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2:33.653</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>33.486</td>\n",
              "      <td>0</td>\n",
              "      <td>58.603</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>12.588</td>\n",
              "      <td>33.486</td>\n",
              "      <td>22.818</td>\n",
              "      <td>56.304</td>\n",
              "      <td>35.785</td>\n",
              "      <td>1:32.089</td>\n",
              "      <td>29.336</td>\n",
              "      <td>2:01.425</td>\n",
              "      <td>32.228</td>\n",
              "      <td>2:33.653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2:33.941</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>33.822</td>\n",
              "      <td>0</td>\n",
              "      <td>59.473</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>13.136</td>\n",
              "      <td>33.822</td>\n",
              "      <td>23.179</td>\n",
              "      <td>57.001</td>\n",
              "      <td>36.294</td>\n",
              "      <td>1:33.295</td>\n",
              "      <td>29.126</td>\n",
              "      <td>2:02.421</td>\n",
              "      <td>31.520</td>\n",
              "      <td>2:33.941</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 39 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   NUMBER   DRIVER_NUMBER   LAP_NUMBER  LAP_TIME   LAP_IMPROVEMENT  \\\n",
              "0       3               1            1  3:46.084                 0   \n",
              "1       3               1            2  2:48.736                 0   \n",
              "2       3               1            3  2:36.896                 0   \n",
              "3       3               1            4  2:33.653                 0   \n",
              "4       3               1            5  2:33.941                 0   \n",
              "\n",
              "   CROSSING_FINISH_LINE_IN_PIT      S1   S1_IMPROVEMENT        S2  \\\n",
              "0                          NaN  53.893                0  1:28.398   \n",
              "1                          NaN  45.381                0  1:00.988   \n",
              "2                          NaN  33.659                0  1:01.873   \n",
              "3                          NaN  33.486                0    58.603   \n",
              "4                          NaN  33.822                0    59.473   \n",
              "\n",
              "    S2_IMPROVEMENT  ... IM1_time  IM1_elapsed  IM2a_time IM2a_elapsed  \\\n",
              "0                0  ...      NaN       53.893     32.095     1:25.988   \n",
              "1                0  ...   14.439       45.381     24.320     1:09.701   \n",
              "2                0  ...   12.848       33.659     25.793       59.452   \n",
              "3                0  ...   12.588       33.486     22.818       56.304   \n",
              "4                0  ...   13.136       33.822     23.179       57.001   \n",
              "\n",
              "  IM2_time IM2_elapsed IM3a_time IM3a_elapsed  FL_time FL_elapsed  \n",
              "0   56.303    2:22.291    36.726     2:59.017   47.067   3:46.084  \n",
              "1   36.668    1:46.369    30.435     2:16.804   31.932   2:48.736  \n",
              "2   36.080    1:35.532    28.996     2:04.528   32.368   2:36.896  \n",
              "3   35.785    1:32.089    29.336     2:01.425   32.228   2:33.653  \n",
              "4   36.294    1:33.295    29.126     2:02.421   31.520   2:33.941  \n",
              "\n",
              "[5 rows x 39 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lap_analysis.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "LAP ANALYSIS DATA STRUCTURE\n",
            "================================================================================\n",
            "\n",
            "âœ“ Key columns for our story:\n",
            "   âœ“ NUMBER\n",
            "   âœ“ DRIVER_NUMBER\n",
            "   âœ“ LAP_NUMBER\n",
            "   âœ“ LAP_TIME\n",
            "   âœ“ LAP_IMPROVEMENT\n",
            "   âœ“ S1\n",
            "   âœ“ S1_IMPROVEMENT\n",
            "   âœ“ S2\n",
            "   âœ“ S2_IMPROVEMENT\n",
            "   âœ“ S3\n",
            "   âœ“ S3_IMPROVEMENT\n",
            "   âœ“ KPH\n",
            "   âœ“ TOP_SPEED\n",
            "   âœ“ FLAG_AT_FL\n",
            "   âœ“ ELAPSED\n",
            "\n",
            "\n",
            "First few rows:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NUMBER</th>\n",
              "      <th>DRIVER_NUMBER</th>\n",
              "      <th>LAP_NUMBER</th>\n",
              "      <th>LAP_TIME</th>\n",
              "      <th>LAP_IMPROVEMENT</th>\n",
              "      <th>S1</th>\n",
              "      <th>S1_IMPROVEMENT</th>\n",
              "      <th>S2</th>\n",
              "      <th>S2_IMPROVEMENT</th>\n",
              "      <th>S3</th>\n",
              "      <th>S3_IMPROVEMENT</th>\n",
              "      <th>KPH</th>\n",
              "      <th>TOP_SPEED</th>\n",
              "      <th>FLAG_AT_FL</th>\n",
              "      <th>ELAPSED</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3:46.084</td>\n",
              "      <td>0</td>\n",
              "      <td>53.893</td>\n",
              "      <td>0</td>\n",
              "      <td>1:28.398</td>\n",
              "      <td>0</td>\n",
              "      <td>1:23.793</td>\n",
              "      <td>0</td>\n",
              "      <td>87.1</td>\n",
              "      <td>107.8</td>\n",
              "      <td>FCY</td>\n",
              "      <td>3:46.084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2:48.736</td>\n",
              "      <td>0</td>\n",
              "      <td>45.381</td>\n",
              "      <td>0</td>\n",
              "      <td>1:00.988</td>\n",
              "      <td>0</td>\n",
              "      <td>1:02.367</td>\n",
              "      <td>0</td>\n",
              "      <td>116.7</td>\n",
              "      <td>202.2</td>\n",
              "      <td>GF</td>\n",
              "      <td>6:34.820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2:36.896</td>\n",
              "      <td>0</td>\n",
              "      <td>33.659</td>\n",
              "      <td>0</td>\n",
              "      <td>1:01.873</td>\n",
              "      <td>0</td>\n",
              "      <td>1:01.364</td>\n",
              "      <td>0</td>\n",
              "      <td>125.6</td>\n",
              "      <td>200.0</td>\n",
              "      <td>GF</td>\n",
              "      <td>9:11.716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2:33.653</td>\n",
              "      <td>0</td>\n",
              "      <td>33.486</td>\n",
              "      <td>0</td>\n",
              "      <td>58.603</td>\n",
              "      <td>0</td>\n",
              "      <td>1:01.564</td>\n",
              "      <td>0</td>\n",
              "      <td>128.2</td>\n",
              "      <td>201.5</td>\n",
              "      <td>GF</td>\n",
              "      <td>11:45.369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2:33.941</td>\n",
              "      <td>0</td>\n",
              "      <td>33.822</td>\n",
              "      <td>0</td>\n",
              "      <td>59.473</td>\n",
              "      <td>0</td>\n",
              "      <td>1:00.646</td>\n",
              "      <td>0</td>\n",
              "      <td>128.0</td>\n",
              "      <td>197.1</td>\n",
              "      <td>GF</td>\n",
              "      <td>14:19.310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>2:32.592</td>\n",
              "      <td>0</td>\n",
              "      <td>33.142</td>\n",
              "      <td>0</td>\n",
              "      <td>58.442</td>\n",
              "      <td>0</td>\n",
              "      <td>1:01.008</td>\n",
              "      <td>0</td>\n",
              "      <td>129.1</td>\n",
              "      <td>203.0</td>\n",
              "      <td>GF</td>\n",
              "      <td>16:51.902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>2:32.568</td>\n",
              "      <td>0</td>\n",
              "      <td>33.219</td>\n",
              "      <td>0</td>\n",
              "      <td>58.950</td>\n",
              "      <td>0</td>\n",
              "      <td>1:00.399</td>\n",
              "      <td>0</td>\n",
              "      <td>129.1</td>\n",
              "      <td>197.1</td>\n",
              "      <td>GF</td>\n",
              "      <td>19:24.470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>2:32.909</td>\n",
              "      <td>0</td>\n",
              "      <td>33.285</td>\n",
              "      <td>0</td>\n",
              "      <td>58.871</td>\n",
              "      <td>0</td>\n",
              "      <td>1:00.753</td>\n",
              "      <td>0</td>\n",
              "      <td>128.8</td>\n",
              "      <td>197.8</td>\n",
              "      <td>GF</td>\n",
              "      <td>21:57.379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>2:32.070</td>\n",
              "      <td>2</td>\n",
              "      <td>33.334</td>\n",
              "      <td>0</td>\n",
              "      <td>58.537</td>\n",
              "      <td>0</td>\n",
              "      <td>1:00.199</td>\n",
              "      <td>2</td>\n",
              "      <td>129.5</td>\n",
              "      <td>198.5</td>\n",
              "      <td>GF</td>\n",
              "      <td>24:29.449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>2:32.311</td>\n",
              "      <td>0</td>\n",
              "      <td>33.319</td>\n",
              "      <td>0</td>\n",
              "      <td>58.636</td>\n",
              "      <td>0</td>\n",
              "      <td>1:00.356</td>\n",
              "      <td>0</td>\n",
              "      <td>129.3</td>\n",
              "      <td>197.8</td>\n",
              "      <td>GF</td>\n",
              "      <td>27:01.760</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   NUMBER  DRIVER_NUMBER  LAP_NUMBER  LAP_TIME  LAP_IMPROVEMENT      S1  \\\n",
              "0       3              1           1  3:46.084                0  53.893   \n",
              "1       3              1           2  2:48.736                0  45.381   \n",
              "2       3              1           3  2:36.896                0  33.659   \n",
              "3       3              1           4  2:33.653                0  33.486   \n",
              "4       3              1           5  2:33.941                0  33.822   \n",
              "5       3              1           6  2:32.592                0  33.142   \n",
              "6       3              1           7  2:32.568                0  33.219   \n",
              "7       3              1           8  2:32.909                0  33.285   \n",
              "8       3              1           9  2:32.070                2  33.334   \n",
              "9       3              1          10  2:32.311                0  33.319   \n",
              "\n",
              "   S1_IMPROVEMENT        S2  S2_IMPROVEMENT        S3  S3_IMPROVEMENT    KPH  \\\n",
              "0               0  1:28.398               0  1:23.793               0   87.1   \n",
              "1               0  1:00.988               0  1:02.367               0  116.7   \n",
              "2               0  1:01.873               0  1:01.364               0  125.6   \n",
              "3               0    58.603               0  1:01.564               0  128.2   \n",
              "4               0    59.473               0  1:00.646               0  128.0   \n",
              "5               0    58.442               0  1:01.008               0  129.1   \n",
              "6               0    58.950               0  1:00.399               0  129.1   \n",
              "7               0    58.871               0  1:00.753               0  128.8   \n",
              "8               0    58.537               0  1:00.199               2  129.5   \n",
              "9               0    58.636               0  1:00.356               0  129.3   \n",
              "\n",
              "   TOP_SPEED FLAG_AT_FL    ELAPSED  \n",
              "0      107.8        FCY   3:46.084  \n",
              "1      202.2         GF   6:34.820  \n",
              "2      200.0         GF   9:11.716  \n",
              "3      201.5         GF  11:45.369  \n",
              "4      197.1         GF  14:19.310  \n",
              "5      203.0         GF  16:51.902  \n",
              "6      197.1         GF  19:24.470  \n",
              "7      197.8         GF  21:57.379  \n",
              "8      198.5         GF  24:29.449  \n",
              "9      197.8         GF  27:01.760  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Step 1.7: Examine the structure of lap analysis data\n",
        "print(f\"{'='*80}\")\n",
        "print(\"LAP ANALYSIS DATA STRUCTURE\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "print(f\"\\nâœ“ Key columns for our story:\")\n",
        "key_columns = ['NUMBER', 'DRIVER_NUMBER', 'LAP_NUMBER', 'LAP_TIME', 'LAP_IMPROVEMENT',\n",
        "               'S1', 'S1_IMPROVEMENT', 'S2', 'S2_IMPROVEMENT', 'S3', 'S3_IMPROVEMENT',\n",
        "               'KPH', 'TOP_SPEED', 'FLAG_AT_FL', 'ELAPSED']\n",
        "\n",
        "for col in key_columns:\n",
        "    if col in lap_analysis.columns:\n",
        "        print(f\"   âœ“ {col}\")\n",
        "    else:\n",
        "        print(f\"   âœ— {col} (missing)\")\n",
        "\n",
        "print(f\"\\n\\nFirst few rows:\")\n",
        "lap_analysis[key_columns].head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TIME_UTC_SECONDS</th>\n",
              "      <th>TIME_UTC_STR</th>\n",
              "      <th>AIR_TEMP</th>\n",
              "      <th>TRACK_TEMP</th>\n",
              "      <th>HUMIDITY</th>\n",
              "      <th>PRESSURE</th>\n",
              "      <th>WIND_SPEED</th>\n",
              "      <th>WIND_DIRECTION</th>\n",
              "      <th>RAIN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1745700936</td>\n",
              "      <td>4/26/2025 8:55:36 PM</td>\n",
              "      <td>28.69</td>\n",
              "      <td>43.2</td>\n",
              "      <td>61.65</td>\n",
              "      <td>993.1</td>\n",
              "      <td>23.76</td>\n",
              "      <td>141</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1745700998</td>\n",
              "      <td>4/26/2025 8:56:38 PM</td>\n",
              "      <td>28.63</td>\n",
              "      <td>43.1</td>\n",
              "      <td>61.66</td>\n",
              "      <td>993.2</td>\n",
              "      <td>14.40</td>\n",
              "      <td>147</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1745701061</td>\n",
              "      <td>4/26/2025 8:57:41 PM</td>\n",
              "      <td>28.59</td>\n",
              "      <td>42.9</td>\n",
              "      <td>62.10</td>\n",
              "      <td>993.2</td>\n",
              "      <td>13.32</td>\n",
              "      <td>151</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1745701124</td>\n",
              "      <td>4/26/2025 8:58:44 PM</td>\n",
              "      <td>28.55</td>\n",
              "      <td>42.6</td>\n",
              "      <td>62.01</td>\n",
              "      <td>993.1</td>\n",
              "      <td>15.48</td>\n",
              "      <td>143</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1745701186</td>\n",
              "      <td>4/26/2025 8:59:46 PM</td>\n",
              "      <td>28.60</td>\n",
              "      <td>42.6</td>\n",
              "      <td>62.71</td>\n",
              "      <td>993.1</td>\n",
              "      <td>9.36</td>\n",
              "      <td>135</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   TIME_UTC_SECONDS          TIME_UTC_STR  AIR_TEMP  TRACK_TEMP  HUMIDITY  \\\n",
              "0        1745700936  4/26/2025 8:55:36 PM     28.69        43.2     61.65   \n",
              "1        1745700998  4/26/2025 8:56:38 PM     28.63        43.1     61.66   \n",
              "2        1745701061  4/26/2025 8:57:41 PM     28.59        42.9     62.10   \n",
              "3        1745701124  4/26/2025 8:58:44 PM     28.55        42.6     62.01   \n",
              "4        1745701186  4/26/2025 8:59:46 PM     28.60        42.6     62.71   \n",
              "\n",
              "   PRESSURE  WIND_SPEED  WIND_DIRECTION  RAIN  \n",
              "0     993.1       23.76             141     0  \n",
              "1     993.2       14.40             147     0  \n",
              "2     993.2       13.32             151     0  \n",
              "3     993.1       15.48             143     0  \n",
              "4     993.1        9.36             135     0  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Step 1.8: Load weather data (important for understanding race conditions)\n",
        "weather_data = pd.read_csv(\n",
        "    DATA_DIR / \"26_Weather_Race 1_Anonymized.CSV\",\n",
        "    sep=';'\n",
        ")\n",
        "weather_data.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(44, 9)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "weather_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "DATA VALIDATION & BASIC STATISTICS\n",
            "================================================================================\n",
            "\n",
            "ðŸ“Š Race Results:\n",
            "   - Total drivers: 31\n",
            "   - Drivers classified: 31\n",
            "   - Total laps completed: 17\n",
            "\n",
            "ðŸ“Š Lap Analysis:\n",
            "   - Total lap records: 486\n",
            "   - Unique car numbers: 30\n",
            "   - Max lap number: 17\n",
            "   - Total drivers (by NUMBER): [2, 3, 5, 7, 8, 11, 13, 14, 15, 16, 18, 21, 31, 41, 46, 47, 51, 55, 57, 71, 72, 73, 78, 80, 86, 88, 89, 93, 98, 113]\n",
            "\n",
            "ðŸ“Š Weather Data:\n",
            "   - Weather records: 44\n",
            "   - Temperature range: 28.5Â°C to 29.1Â°C\n",
            "   - Track temp range: 40.2Â°C to 43.2Â°C\n",
            "\n",
            "âœ“ All datasets loaded and validated!\n"
          ]
        }
      ],
      "source": [
        "# Step 1.9: Basic data validation and statistics\n",
        "print(f\"{'='*80}\")\n",
        "print(\"DATA VALIDATION & BASIC STATISTICS\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "print(f\"\\nðŸ“Š Race Results:\")\n",
        "print(f\"   - Total drivers: {len(race_results)}\")\n",
        "print(f\"   - Drivers classified: {len(race_results[race_results['STATUS'] == 'Classified'])}\")\n",
        "print(f\"   - Total laps completed: {race_results['LAPS'].max()}\")\n",
        "\n",
        "print(f\"\\nðŸ“Š Lap Analysis:\")\n",
        "print(f\"   - Total lap records: {len(lap_analysis)}\")\n",
        "print(f\"   - Unique car numbers: {lap_analysis['NUMBER'].nunique()}\")\n",
        "print(f\"   - Max lap number: {lap_analysis['LAP_NUMBER'].max()}\")\n",
        "print(f\"   - Total drivers (by NUMBER): {sorted(lap_analysis['NUMBER'].unique())}\")\n",
        "\n",
        "print(f\"\\nðŸ“Š Weather Data:\")\n",
        "print(f\"   - Weather records: {len(weather_data)}\")\n",
        "print(f\"   - Temperature range: {weather_data['AIR_TEMP'].min():.1f}Â°C to {weather_data['AIR_TEMP'].max():.1f}Â°C\")\n",
        "print(f\"   - Track temp range: {weather_data['TRACK_TEMP'].min():.1f}Â°C to {weather_data['TRACK_TEMP'].max():.1f}Â°C\")\n",
        "\n",
        "print(f\"\\nâœ“ All datasets loaded and validated!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing time conversion function:\n",
            "   '2:28.630' -> 148.63 seconds\n",
            "   '45:57.575' -> 2757.575 seconds\n",
            "   '1:23.793' -> 83.793 seconds\n",
            "   '-' -> nan seconds\n",
            "   '' -> nan seconds\n",
            "\n",
            "âœ“ Time conversion function ready!\n"
          ]
        }
      ],
      "source": [
        "# Step 1.10: Helper function to convert time format (MM:SS.mmm) to total seconds\n",
        "# This will be essential for calculations and comparisons\n",
        "\n",
        "def time_to_seconds(time_str):\n",
        "    \"\"\"\n",
        "    Convert time string in format MM:SS.mmm or MM:SS to total seconds.\n",
        "    Returns NaN if input is invalid.\n",
        "    \"\"\"\n",
        "    if pd.isna(time_str) or time_str == '' or time_str == '-':\n",
        "        return np.nan\n",
        "    \n",
        "    try:\n",
        "        # Handle format like \"2:28.630\" (MM:SS.mmm)\n",
        "        parts = str(time_str).split(':')\n",
        "        if len(parts) == 2:\n",
        "            minutes = int(parts[0])\n",
        "            seconds_str = parts[1]\n",
        "            # Handle seconds with decimals\n",
        "            seconds = float(seconds_str)\n",
        "            return minutes * 60 + seconds\n",
        "        else:\n",
        "            return np.nan\n",
        "    except:\n",
        "        return np.nan\n",
        "\n",
        "# Test the function\n",
        "test_times = [\"2:28.630\", \"45:57.575\", \"1:23.793\", \"-\", \"\"]\n",
        "print(\"Testing time conversion function:\")\n",
        "for t in test_times:\n",
        "    result = time_to_seconds(t)\n",
        "    print(f\"   '{t}' -> {result} seconds\")\n",
        "\n",
        "print(\"\\nâœ“ Time conversion function ready!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['2', '28.630']"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str(\"2:28.630\").split(':')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "parts = str(\"2:28.630\").split(':')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "minutes = int(parts[0])\n",
        "minutes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "28.63"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "seconds_str = parts[1]\n",
        "seconds = float(seconds_str)\n",
        "seconds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.series.Series'>\n",
            "RangeIndex: 486 entries, 0 to 485\n",
            "Series name: LAP_TIME\n",
            "Non-Null Count  Dtype \n",
            "--------------  ----- \n",
            "486 non-null    object\n",
            "dtypes: object(1)\n",
            "memory usage: 3.9+ KB\n"
          ]
        }
      ],
      "source": [
        "lap_analysis['LAP_TIME'].info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NUMBER</th>\n",
              "      <th>DRIVER_NUMBER</th>\n",
              "      <th>LAP_NUMBER</th>\n",
              "      <th>LAP_TIME</th>\n",
              "      <th>LAP_IMPROVEMENT</th>\n",
              "      <th>CROSSING_FINISH_LINE_IN_PIT</th>\n",
              "      <th>S1</th>\n",
              "      <th>S1_IMPROVEMENT</th>\n",
              "      <th>S2</th>\n",
              "      <th>S2_IMPROVEMENT</th>\n",
              "      <th>...</th>\n",
              "      <th>IM1_elapsed</th>\n",
              "      <th>IM2a_time</th>\n",
              "      <th>IM2a_elapsed</th>\n",
              "      <th>IM2_time</th>\n",
              "      <th>IM2_elapsed</th>\n",
              "      <th>IM3a_time</th>\n",
              "      <th>IM3a_elapsed</th>\n",
              "      <th>FL_time</th>\n",
              "      <th>FL_elapsed</th>\n",
              "      <th>LAP_TIME_SECONDS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3:46.084</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>53.893</td>\n",
              "      <td>0</td>\n",
              "      <td>1:28.398</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>53.893</td>\n",
              "      <td>32.095</td>\n",
              "      <td>1:25.988</td>\n",
              "      <td>56.303</td>\n",
              "      <td>2:22.291</td>\n",
              "      <td>36.726</td>\n",
              "      <td>2:59.017</td>\n",
              "      <td>47.067</td>\n",
              "      <td>3:46.084</td>\n",
              "      <td>226.084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2:48.736</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>45.381</td>\n",
              "      <td>0</td>\n",
              "      <td>1:00.988</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>45.381</td>\n",
              "      <td>24.320</td>\n",
              "      <td>1:09.701</td>\n",
              "      <td>36.668</td>\n",
              "      <td>1:46.369</td>\n",
              "      <td>30.435</td>\n",
              "      <td>2:16.804</td>\n",
              "      <td>31.932</td>\n",
              "      <td>2:48.736</td>\n",
              "      <td>168.736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2:36.896</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>33.659</td>\n",
              "      <td>0</td>\n",
              "      <td>1:01.873</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>33.659</td>\n",
              "      <td>25.793</td>\n",
              "      <td>59.452</td>\n",
              "      <td>36.080</td>\n",
              "      <td>1:35.532</td>\n",
              "      <td>28.996</td>\n",
              "      <td>2:04.528</td>\n",
              "      <td>32.368</td>\n",
              "      <td>2:36.896</td>\n",
              "      <td>156.896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2:33.653</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>33.486</td>\n",
              "      <td>0</td>\n",
              "      <td>58.603</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>33.486</td>\n",
              "      <td>22.818</td>\n",
              "      <td>56.304</td>\n",
              "      <td>35.785</td>\n",
              "      <td>1:32.089</td>\n",
              "      <td>29.336</td>\n",
              "      <td>2:01.425</td>\n",
              "      <td>32.228</td>\n",
              "      <td>2:33.653</td>\n",
              "      <td>153.653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2:33.941</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>33.822</td>\n",
              "      <td>0</td>\n",
              "      <td>59.473</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>33.822</td>\n",
              "      <td>23.179</td>\n",
              "      <td>57.001</td>\n",
              "      <td>36.294</td>\n",
              "      <td>1:33.295</td>\n",
              "      <td>29.126</td>\n",
              "      <td>2:02.421</td>\n",
              "      <td>31.520</td>\n",
              "      <td>2:33.941</td>\n",
              "      <td>153.941</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 40 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   NUMBER  DRIVER_NUMBER  LAP_NUMBER  LAP_TIME  LAP_IMPROVEMENT  \\\n",
              "0       3              1           1  3:46.084                0   \n",
              "1       3              1           2  2:48.736                0   \n",
              "2       3              1           3  2:36.896                0   \n",
              "3       3              1           4  2:33.653                0   \n",
              "4       3              1           5  2:33.941                0   \n",
              "\n",
              "  CROSSING_FINISH_LINE_IN_PIT      S1  S1_IMPROVEMENT        S2  \\\n",
              "0                         NaN  53.893               0  1:28.398   \n",
              "1                         NaN  45.381               0  1:00.988   \n",
              "2                         NaN  33.659               0  1:01.873   \n",
              "3                         NaN  33.486               0    58.603   \n",
              "4                         NaN  33.822               0    59.473   \n",
              "\n",
              "   S2_IMPROVEMENT  ... IM1_elapsed  IM2a_time  IM2a_elapsed IM2_time  \\\n",
              "0               0  ...      53.893     32.095      1:25.988   56.303   \n",
              "1               0  ...      45.381     24.320      1:09.701   36.668   \n",
              "2               0  ...      33.659     25.793        59.452   36.080   \n",
              "3               0  ...      33.486     22.818        56.304   35.785   \n",
              "4               0  ...      33.822     23.179        57.001   36.294   \n",
              "\n",
              "  IM2_elapsed IM3a_time IM3a_elapsed FL_time  FL_elapsed LAP_TIME_SECONDS  \n",
              "0    2:22.291    36.726     2:59.017  47.067    3:46.084          226.084  \n",
              "1    1:46.369    30.435     2:16.804  31.932    2:48.736          168.736  \n",
              "2    1:35.532    28.996     2:04.528  32.368    2:36.896          156.896  \n",
              "3    1:32.089    29.336     2:01.425  32.228    2:33.653          153.653  \n",
              "4    1:33.295    29.126     2:02.421  31.520    2:33.941          153.941  \n",
              "\n",
              "[5 rows x 40 columns]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lap_analysis.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    3:46.084\n",
              "1    2:48.736\n",
              "2    2:36.896\n",
              "3    2:33.653\n",
              "4    2:33.941\n",
              "5    2:32.592\n",
              "6    2:32.568\n",
              "7    2:32.909\n",
              "8    2:32.070\n",
              "9    2:32.311\n",
              "Name: LAP_TIME, dtype: object"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lap_analysis['LAP_TIME'].head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current LAP_TIME format (sample):\n",
            "0    3:46.084\n",
            "1    2:48.736\n",
            "2    2:36.896\n",
            "3    2:33.653\n",
            "4    2:33.941\n",
            "5    2:32.592\n",
            "6    2:32.568\n",
            "7    2:32.909\n",
            "8    2:32.070\n",
            "9    2:32.311\n",
            "Name: LAP_TIME, dtype: object\n",
            "\n",
            "âœ“ LAP_TIME converted to seconds\n",
            "\n",
            "   Sample converted values:\n",
            "   Original  Seconds\n",
            "0  3:46.084  226.084\n",
            "1  2:48.736  168.736\n",
            "2  2:36.896  156.896\n",
            "3  2:33.653  153.653\n",
            "4  2:33.941  153.941\n",
            "5  2:32.592  152.592\n",
            "6  2:32.568  152.568\n",
            "7  2:32.909  152.909\n",
            "8  2:32.070  152.070\n",
            "9  2:32.311  152.311\n",
            "\n",
            "   Statistics:\n",
            "   - Fastest lap: 148.630 seconds\n",
            "   - Slowest lap: 741.996 seconds\n",
            "   - Average lap time: 165.335 seconds\n"
          ]
        }
      ],
      "source": [
        "# Step 1.11: Convert LAP_TIME in lap_analysis to seconds for easier analysis\n",
        "# First, let's check the current format\n",
        "\n",
        "print(\"Current LAP_TIME format (sample):\")\n",
        "print(lap_analysis['LAP_TIME'].head(10))\n",
        "\n",
        "# Convert to seconds\n",
        "lap_analysis['LAP_TIME_SECONDS'] = lap_analysis['LAP_TIME'].apply(time_to_seconds)\n",
        "\n",
        "print(f\"\\nâœ“ LAP_TIME converted to seconds\")\n",
        "print(f\"\\n   Sample converted values:\")\n",
        "sample_df = pd.DataFrame({\n",
        "    'Original': lap_analysis['LAP_TIME'].head(10),\n",
        "    'Seconds': lap_analysis['LAP_TIME_SECONDS'].head(10)\n",
        "})\n",
        "print(sample_df)\n",
        "\n",
        "print(f\"\\n   Statistics:\")\n",
        "print(f\"   - Fastest lap: {lap_analysis['LAP_TIME_SECONDS'].min():.3f} seconds\")\n",
        "print(f\"   - Slowest lap: {lap_analysis['LAP_TIME_SECONDS'].max():.3f} seconds\")\n",
        "print(f\"   - Average lap time: {lap_analysis['LAP_TIME_SECONDS'].mean():.3f} seconds\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Sector times converted to seconds\n",
            "\n",
            "   Sample conversion:\n",
            "       S1  S1_SECONDS_CALC        S2  S2_SECONDS_CALC        S3  \\\n",
            "0  53.893           53.893  1:28.398           88.398  1:23.793   \n",
            "1  45.381           45.381  1:00.988           60.988  1:02.367   \n",
            "2  33.659           33.659  1:01.873           61.873  1:01.364   \n",
            "3  33.486           33.486    58.603           58.603  1:01.564   \n",
            "4  33.822           33.822    59.473           59.473  1:00.646   \n",
            "5  33.142           33.142    58.442           58.442  1:01.008   \n",
            "6  33.219           33.219    58.950           58.950  1:00.399   \n",
            "7  33.285           33.285    58.871           58.871  1:00.753   \n",
            "8  33.334           33.334    58.537           58.537  1:00.199   \n",
            "9  33.319           33.319    58.636           58.636  1:00.356   \n",
            "\n",
            "   S3_SECONDS_CALC  \n",
            "0           83.793  \n",
            "1           62.367  \n",
            "2           61.364  \n",
            "3           61.564  \n",
            "4           60.646  \n",
            "5           61.008  \n",
            "6           60.399  \n",
            "7           60.753  \n",
            "8           60.199  \n",
            "9           60.356  \n",
            "\n",
            "   Verification (S1 + S2 + S3 should â‰ˆ LAP_TIME):\n",
            "   Average difference: 0.000 seconds\n"
          ]
        }
      ],
      "source": [
        "# Step 1.12: Convert sector times to seconds\n",
        "# Sectors are in format like \"53.893\" (SS.mmm) or \"1:28.398\" (MM:SS.mmm)\n",
        "\n",
        "def sector_to_seconds(sector_str):\n",
        "    \"\"\"Convert sector time to seconds. Handles both SS.mmm and MM:SS.mmm formats.\"\"\"\n",
        "    if pd.isna(sector_str) or sector_str == '':\n",
        "        return np.nan\n",
        "    \n",
        "    try:\n",
        "        sector_str = str(sector_str).strip()\n",
        "        if ':' in sector_str:\n",
        "            # Format: MM:SS.mmm\n",
        "            parts = sector_str.split(':')\n",
        "            minutes = int(parts[0])\n",
        "            seconds = float(parts[1])\n",
        "            return minutes * 60 + seconds\n",
        "        else:\n",
        "            # Format: SS.mmm\n",
        "            return float(sector_str)\n",
        "    except:\n",
        "        return np.nan\n",
        "\n",
        "# Convert sector times\n",
        "lap_analysis['S1_SECONDS_CALC'] = lap_analysis['S1'].apply(sector_to_seconds)\n",
        "lap_analysis['S2_SECONDS_CALC'] = lap_analysis['S2'].apply(sector_to_seconds)\n",
        "lap_analysis['S3_SECONDS_CALC'] = lap_analysis['S3'].apply(sector_to_seconds)\n",
        "\n",
        "print(\"âœ“ Sector times converted to seconds\")\n",
        "print(f\"\\n   Sample conversion:\")\n",
        "sector_sample = lap_analysis[['S1', 'S1_SECONDS_CALC', 'S2', 'S2_SECONDS_CALC', 'S3', 'S3_SECONDS_CALC']].head(10)\n",
        "print(sector_sample)\n",
        "\n",
        "print(f\"\\n   Verification (S1 + S2 + S3 should â‰ˆ LAP_TIME):\")\n",
        "lap_analysis['SECTORS_SUM'] = (lap_analysis['S1_SECONDS_CALC'] + \n",
        "                                 lap_analysis['S2_SECONDS_CALC'] + \n",
        "                                 lap_analysis['S3_SECONDS_CALC'])\n",
        "lap_analysis['TIME_DIFF'] = abs(lap_analysis['SECTORS_SUM'] - lap_analysis['LAP_TIME_SECONDS'])\n",
        "print(f\"   Average difference: {lap_analysis['TIME_DIFF'].mean():.3f} seconds\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "60.988"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "time_to_seconds(lap_analysis['S2'][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "60.988"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sector_to_seconds(lap_analysis['S2'][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "NUMBER                                           3\n",
              "DRIVER_NUMBER                                    1\n",
              "LAP_NUMBER                                      11\n",
              "LAP_TIME                                  2:32.852\n",
              "LAP_IMPROVEMENT                                  0\n",
              "CROSSING_FINISH_LINE_IN_PIT                    NaN\n",
              "S1                                          33.186\n",
              "S1_IMPROVEMENT                                   0\n",
              "S2                                          59.437\n",
              "S2_IMPROVEMENT                                   0\n",
              "S3                                        1:00.229\n",
              "S3_IMPROVEMENT                                   0\n",
              "KPH                                          128.9\n",
              "ELAPSED                                  29:34.612\n",
              "HOUR                                  16:24:14.851\n",
              "S1_LARGE                                  0:33.186\n",
              "S2_LARGE                                  0:59.437\n",
              "S3_LARGE                                  1:00.229\n",
              "TOP_SPEED                                    197.8\n",
              "PIT_TIME                                       NaN\n",
              "CLASS                                           Am\n",
              "GROUP                                          NaN\n",
              "MANUFACTURER                   Toyota Gazoo Racing\n",
              "FLAG_AT_FL                                     FCY\n",
              "S1_SECONDS                                  33.186\n",
              "S2_SECONDS                                  59.437\n",
              "S3_SECONDS                                  60.229\n",
              "IM1a_time                                   20.654\n",
              "IM1a_elapsed                                20.654\n",
              "IM1_time                                    12.532\n",
              "IM1_elapsed                                 33.186\n",
              "IM2a_time                                   23.324\n",
              "IM2a_elapsed                                56.510\n",
              "IM2_time                                    36.113\n",
              "IM2_elapsed                               1:32.623\n",
              "IM3a_time                                   28.964\n",
              "IM3a_elapsed                              2:01.587\n",
              "FL_time                                     31.265\n",
              "FL_elapsed                                2:32.852\n",
              "LAP_TIME_SECONDS                           152.852\n",
              "S1_SECONDS_CALC                             33.186\n",
              "S2_SECONDS_CALC                             59.437\n",
              "S3_SECONDS_CALC                             60.229\n",
              "SECTORS_SUM                                152.852\n",
              "TIME_DIFF                                      0.0\n",
              "Name: 10, dtype: object"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lap_analysis.iloc[10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating unified driver dataset...\n",
            "âœ“ Driver summary created (31 drivers)\n",
            "\n",
            "   Top 10 drivers:\n",
            "   CAR_NUMBER  FINAL_POSITION  TOTAL_LAPS TOTAL_RACE_TIME FASTEST_LAP_TIME  \\\n",
            "0          46               1          17       45:57.575         2:28.630   \n",
            "1           7               2          17       45:58.259         2:28.678   \n",
            "2          16               3          17       45:58.588         2:28.726   \n",
            "3          55               4          17       45:58.880         2:28.679   \n",
            "4          72               5          17       45:59.793         2:28.848   \n",
            "5          13               6          17       46:00.172         2:28.745   \n",
            "6          78               7          17       46:02.598         2:29.293   \n",
            "7          41               8          17       46:03.531         2:29.262   \n",
            "8          71               9          17       46:04.116         2:29.526   \n",
            "9          21              10          17       46:04.348         2:28.989   \n",
            "\n",
            "   FASTEST_LAP_SPEED  \n",
            "0              132.5  \n",
            "1              132.5  \n",
            "2              132.4  \n",
            "3              132.5  \n",
            "4              132.3  \n",
            "5              132.4  \n",
            "6              131.9  \n",
            "7              132.0  \n",
            "8              131.7  \n",
            "9              132.2  \n",
            "\n",
            "   Car numbers in lap data: [2, 3, 5, 7, 8, 11, 13, 14, 15, 16, 18, 21, 31, 41, 46, 47, 51, 55, 57, 71, 72, 73, 78, 80, 86, 88, 89, 93, 98, 113]\n",
            "   Car numbers in results: [2, 3, 5, 7, 8, 11, 13, 14, 15, 16, 18, 21, 31, 41, 46, 47, 51, 55, 57, 71, 72, 73, 78, 80, 86, 88, 89, 93, 98, 113]\n",
            "   Match: True\n"
          ]
        }
      ],
      "source": [
        "# Step 1.13: Create a unified driver identifier\n",
        "# We'll use NUMBER as the primary identifier and merge it with race results\n",
        "\n",
        "print(\"Creating unified driver dataset...\")\n",
        "\n",
        "# Create driver summary from race results\n",
        "drivers = race_results[['NUMBER', 'POSITION', 'LAPS', 'TOTAL_TIME', 'FL_TIME', 'FL_KPH']].copy()\n",
        "drivers.columns = ['CAR_NUMBER', 'FINAL_POSITION', 'TOTAL_LAPS', 'TOTAL_RACE_TIME', 'FASTEST_LAP_TIME', 'FASTEST_LAP_SPEED']\n",
        "\n",
        "print(f\"âœ“ Driver summary created ({len(drivers)} drivers)\")\n",
        "print(f\"\\n   Top 10 drivers:\")\n",
        "print(drivers.head(10))\n",
        "\n",
        "# Verify car numbers match\n",
        "lap_cars = set(lap_analysis['NUMBER'].unique())\n",
        "result_cars = set(drivers['CAR_NUMBER'].unique())\n",
        "print(f\"\\n   Car numbers in lap data: {sorted(lap_cars)}\")\n",
        "print(f\"   Car numbers in results: {sorted(result_cars)}\")\n",
        "print(f\"   Match: {lap_cars == result_cars}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Weather data prepared\n",
            "\n",
            "   Time range:\n",
            "   Start: 2025-04-26 20:55:36\n",
            "   End: 2025-04-26 21:40:31\n",
            "   Duration: 0 days 00:44:55\n",
            "\n",
            "   Weather summary:\n",
            "   Air temp: 28.5Â°C to 29.1Â°C\n",
            "   Track temp: 40.2Â°C to 43.2Â°C\n",
            "   Humidity: 61.0% to 64.4%\n",
            "   Rain: 0 records with rain\n"
          ]
        }
      ],
      "source": [
        "# Step 1.14: Prepare weather data for merging\n",
        "# Convert time columns and prepare for joining with lap data\n",
        "\n",
        "# Convert UTC time string to datetime\n",
        "weather_data['TIME_DATETIME'] = pd.to_datetime(weather_data['TIME_UTC_STR'])\n",
        "\n",
        "# Sort by time\n",
        "weather_data = weather_data.sort_values('TIME_DATETIME').reset_index(drop=True)\n",
        "\n",
        "print(\"âœ“ Weather data prepared\")\n",
        "print(f\"\\n   Time range:\")\n",
        "print(f\"   Start: {weather_data['TIME_DATETIME'].min()}\")\n",
        "print(f\"   End: {weather_data['TIME_DATETIME'].max()}\")\n",
        "print(f\"   Duration: {weather_data['TIME_DATETIME'].max() - weather_data['TIME_DATETIME'].min()}\")\n",
        "\n",
        "print(f\"\\n   Weather summary:\")\n",
        "print(f\"   Air temp: {weather_data['AIR_TEMP'].min():.1f}Â°C to {weather_data['AIR_TEMP'].max():.1f}Â°C\")\n",
        "print(f\"   Track temp: {weather_data['TRACK_TEMP'].min():.1f}Â°C to {weather_data['TRACK_TEMP'].max():.1f}Â°C\")\n",
        "print(f\"   Humidity: {weather_data['HUMIDITY'].min():.1f}% to {weather_data['HUMIDITY'].max():.1f}%\")\n",
        "print(f\"   Rain: {weather_data['RAIN'].sum()} records with rain\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 1.1: Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.3.2'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.__version__\n",
        "pd.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   1. 00_Results GR Cup Race 1 Official_Anonymized.CSV\n",
            "   2. 03_Provisional Results_Race 1_Anonymized.CSV\n",
            "   3. 05_Provisional Results by Class_Race 1_Anonymized.CSV\n",
            "   4. 23_AnalysisEnduranceWithSections_Race 1_Anonymized.CSV\n",
            "   5. 26_Weather_Race 1_Anonymized.CSV\n",
            "   6. 99_Best 10 Laps By Driver_Race 1_Anonymized.CSV\n",
            "   7. COTA_lap_end_time_R1.csv\n",
            "   8. COTA_lap_start_time_R1.csv\n",
            "   9. COTA_lap_time_R1.csv\n",
            "   10. R1_cota_telemetry_data.csv\n",
            "   11. 00_Results GR Cup Race 1 Official_Anonymized.CSV\n",
            "   12. 03_Provisional Results_Race 1_Anonymized.CSV\n",
            "   13. 05_Provisional Results by Class_Race 1_Anonymized.CSV\n",
            "   14. 23_AnalysisEnduranceWithSections_Race 1_Anonymized.CSV\n",
            "   15. 26_Weather_Race 1_Anonymized.CSV\n",
            "   16. 99_Best 10 Laps By Driver_Race 1_Anonymized.CSV\n",
            "   17. COTA_lap_end_time_R1.csv\n",
            "   18. COTA_lap_start_time_R1.csv\n",
            "   19. COTA_lap_time_R1.csv\n",
            "   20. R1_cota_telemetry_data.csv\n"
          ]
        }
      ],
      "source": [
        "# Step 1.2: Set up data directory paths\n",
        "DATA_DIR = Path(\"circuit-of-the-americas/COTA/Race 1\")\n",
        "\n",
        "# Verify the directory exists\n",
        "if DATA_DIR.exists():\n",
        "    csv_files = [f for f in DATA_DIR.glob(\"*.CSV\")] + [f for f in DATA_DIR.glob(\"*.csv\")]\n",
        "    for i, f in enumerate(csv_files, 1):\n",
        "        print(f\"   {i}. {f.name}\")\n",
        "else:\n",
        "    print(f\"âœ— Error: Data directory not found at {DATA_DIR}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>POSITION</th>\n",
              "      <th>NUMBER</th>\n",
              "      <th>STATUS</th>\n",
              "      <th>LAPS</th>\n",
              "      <th>TOTAL_TIME</th>\n",
              "      <th>GAP_FIRST</th>\n",
              "      <th>GAP_PREVIOUS</th>\n",
              "      <th>FL_LAPNUM</th>\n",
              "      <th>FL_TIME</th>\n",
              "      <th>FL_KPH</th>\n",
              "      <th>...</th>\n",
              "      <th>ECM Car Id</th>\n",
              "      <th>ECM Brand Id</th>\n",
              "      <th>ECM Country Id</th>\n",
              "      <th>*Extra 7</th>\n",
              "      <th>*Extra 8</th>\n",
              "      <th>*Extra 9</th>\n",
              "      <th>Sort Key</th>\n",
              "      <th>DRIVER_*Extra 3</th>\n",
              "      <th>DRIVER_*Extra 4</th>\n",
              "      <th>DRIVER_*Extra 5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>46</td>\n",
              "      <td>Classified</td>\n",
              "      <td>17</td>\n",
              "      <td>45:57.575</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>8</td>\n",
              "      <td>2:28.630</td>\n",
              "      <td>132.5</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Classified</td>\n",
              "      <td>17</td>\n",
              "      <td>45:58.259</td>\n",
              "      <td>+0.684</td>\n",
              "      <td>+0.684</td>\n",
              "      <td>7</td>\n",
              "      <td>2:28.678</td>\n",
              "      <td>132.5</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>16</td>\n",
              "      <td>Classified</td>\n",
              "      <td>17</td>\n",
              "      <td>45:58.588</td>\n",
              "      <td>+1.013</td>\n",
              "      <td>+0.329</td>\n",
              "      <td>9</td>\n",
              "      <td>2:28.726</td>\n",
              "      <td>132.4</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>55</td>\n",
              "      <td>Classified</td>\n",
              "      <td>17</td>\n",
              "      <td>45:58.880</td>\n",
              "      <td>+1.305</td>\n",
              "      <td>+0.292</td>\n",
              "      <td>10</td>\n",
              "      <td>2:28.679</td>\n",
              "      <td>132.5</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>72</td>\n",
              "      <td>Classified</td>\n",
              "      <td>17</td>\n",
              "      <td>45:59.793</td>\n",
              "      <td>+2.218</td>\n",
              "      <td>+0.913</td>\n",
              "      <td>9</td>\n",
              "      <td>2:28.848</td>\n",
              "      <td>132.3</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 28 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   POSITION  NUMBER      STATUS  LAPS TOTAL_TIME GAP_FIRST GAP_PREVIOUS  \\\n",
              "0         1      46  Classified    17  45:57.575         -            -   \n",
              "1         2       7  Classified    17  45:58.259    +0.684       +0.684   \n",
              "2         3      16  Classified    17  45:58.588    +1.013       +0.329   \n",
              "3         4      55  Classified    17  45:58.880    +1.305       +0.292   \n",
              "4         5      72  Classified    17  45:59.793    +2.218       +0.913   \n",
              "\n",
              "   FL_LAPNUM   FL_TIME  FL_KPH  ... ECM Car Id ECM Brand Id ECM Country Id  \\\n",
              "0          8  2:28.630   132.5  ...        NaN          NaN            NaN   \n",
              "1          7  2:28.678   132.5  ...        NaN          NaN            NaN   \n",
              "2          9  2:28.726   132.4  ...        NaN          NaN            NaN   \n",
              "3         10  2:28.679   132.5  ...        NaN          NaN            NaN   \n",
              "4          9  2:28.848   132.3  ...        NaN          NaN            NaN   \n",
              "\n",
              "  *Extra 7  *Extra 8  *Extra 9  Sort Key  DRIVER_*Extra 3  DRIVER_*Extra 4  \\\n",
              "0      NaN       NaN       NaN       NaN              NaN              NaN   \n",
              "1      NaN       NaN       NaN       NaN              NaN              NaN   \n",
              "2      NaN       NaN       NaN       NaN              NaN              NaN   \n",
              "3      NaN       NaN       NaN       NaN              NaN              NaN   \n",
              "4      NaN       NaN       NaN       NaN              NaN              NaN   \n",
              "\n",
              "   DRIVER_*Extra 5  \n",
              "0              NaN  \n",
              "1              NaN  \n",
              "2              NaN  \n",
              "3              NaN  \n",
              "4              NaN  \n",
              "\n",
              "[5 rows x 28 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Step 1.3: Load the main race results file\n",
        "# This will be our primary reference for driver information\n",
        "\n",
        "race_results = pd.read_csv(\n",
        "    DATA_DIR / \"00_Results GR Cup Race 1 Official_Anonymized.CSV\",\n",
        "    sep=';'\n",
        ")\n",
        "race_results.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['POSITION', 'NUMBER', 'STATUS', 'LAPS', 'TOTAL_TIME', 'GAP_FIRST', 'GAP_PREVIOUS', 'FL_LAPNUM', 'FL_TIME', 'FL_KPH', 'CLASS', 'GROUP', 'DIVISION', 'VEHICLE', 'TIRES', 'ECM Participant Id', 'ECM Team Id', 'ECM Category Id', 'ECM Car Id', 'ECM Brand Id', 'ECM Country Id', '*Extra 7', '*Extra 8', '*Extra 9', 'Sort Key', 'DRIVER_*Extra 3', 'DRIVER_*Extra 4', 'DRIVER_*Extra 5']\n"
          ]
        }
      ],
      "source": [
        "# Step 1.4: Clean column names (remove leading/trailing spaces)\n",
        "# Some columns from the CSV have extra spaces\n",
        "\n",
        "race_results.columns = race_results.columns.str.strip()\n",
        "print(list(race_results.columns))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Total Drivers: 31\n",
            "Key Columns: POSITION, NUMBER, STATUS, LAPS, TOTAL_TIME\n",
            "\n",
            "Top 10 Finishers:\n",
            "   POSITION  NUMBER      STATUS  LAPS TOTAL_TIME   FL_TIME\n",
            "0         1      46  Classified    17  45:57.575  2:28.630\n",
            "1         2       7  Classified    17  45:58.259  2:28.678\n",
            "2         3      16  Classified    17  45:58.588  2:28.726\n",
            "3         4      55  Classified    17  45:58.880  2:28.679\n",
            "4         5      72  Classified    17  45:59.793  2:28.848\n",
            "5         6      13  Classified    17  46:00.172  2:28.745\n",
            "6         7      78  Classified    17  46:02.598  2:29.293\n",
            "7         8      41  Classified    17  46:03.531  2:29.262\n",
            "8         9      71  Classified    17  46:04.116  2:29.526\n",
            "9        10      21  Classified    17  46:04.348  2:28.989\n",
            "\n",
            "\n",
            "Full dataset:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>POSITION</th>\n",
              "      <th>NUMBER</th>\n",
              "      <th>STATUS</th>\n",
              "      <th>LAPS</th>\n",
              "      <th>TOTAL_TIME</th>\n",
              "      <th>GAP_FIRST</th>\n",
              "      <th>GAP_PREVIOUS</th>\n",
              "      <th>FL_LAPNUM</th>\n",
              "      <th>FL_TIME</th>\n",
              "      <th>FL_KPH</th>\n",
              "      <th>...</th>\n",
              "      <th>ECM Car Id</th>\n",
              "      <th>ECM Brand Id</th>\n",
              "      <th>ECM Country Id</th>\n",
              "      <th>*Extra 7</th>\n",
              "      <th>*Extra 8</th>\n",
              "      <th>*Extra 9</th>\n",
              "      <th>Sort Key</th>\n",
              "      <th>DRIVER_*Extra 3</th>\n",
              "      <th>DRIVER_*Extra 4</th>\n",
              "      <th>DRIVER_*Extra 5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>46</td>\n",
              "      <td>Classified</td>\n",
              "      <td>17</td>\n",
              "      <td>45:57.575</td>\n",
              "      <td>-</td>\n",
              "      <td>-</td>\n",
              "      <td>8</td>\n",
              "      <td>2:28.630</td>\n",
              "      <td>132.5</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>Classified</td>\n",
              "      <td>17</td>\n",
              "      <td>45:58.259</td>\n",
              "      <td>+0.684</td>\n",
              "      <td>+0.684</td>\n",
              "      <td>7</td>\n",
              "      <td>2:28.678</td>\n",
              "      <td>132.5</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>16</td>\n",
              "      <td>Classified</td>\n",
              "      <td>17</td>\n",
              "      <td>45:58.588</td>\n",
              "      <td>+1.013</td>\n",
              "      <td>+0.329</td>\n",
              "      <td>9</td>\n",
              "      <td>2:28.726</td>\n",
              "      <td>132.4</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>55</td>\n",
              "      <td>Classified</td>\n",
              "      <td>17</td>\n",
              "      <td>45:58.880</td>\n",
              "      <td>+1.305</td>\n",
              "      <td>+0.292</td>\n",
              "      <td>10</td>\n",
              "      <td>2:28.679</td>\n",
              "      <td>132.5</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>72</td>\n",
              "      <td>Classified</td>\n",
              "      <td>17</td>\n",
              "      <td>45:59.793</td>\n",
              "      <td>+2.218</td>\n",
              "      <td>+0.913</td>\n",
              "      <td>9</td>\n",
              "      <td>2:28.848</td>\n",
              "      <td>132.3</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 28 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   POSITION  NUMBER      STATUS  LAPS TOTAL_TIME GAP_FIRST GAP_PREVIOUS  \\\n",
              "0         1      46  Classified    17  45:57.575         -            -   \n",
              "1         2       7  Classified    17  45:58.259    +0.684       +0.684   \n",
              "2         3      16  Classified    17  45:58.588    +1.013       +0.329   \n",
              "3         4      55  Classified    17  45:58.880    +1.305       +0.292   \n",
              "4         5      72  Classified    17  45:59.793    +2.218       +0.913   \n",
              "\n",
              "   FL_LAPNUM   FL_TIME  FL_KPH  ... ECM Car Id ECM Brand Id ECM Country Id  \\\n",
              "0          8  2:28.630   132.5  ...        NaN          NaN            NaN   \n",
              "1          7  2:28.678   132.5  ...        NaN          NaN            NaN   \n",
              "2          9  2:28.726   132.4  ...        NaN          NaN            NaN   \n",
              "3         10  2:28.679   132.5  ...        NaN          NaN            NaN   \n",
              "4          9  2:28.848   132.3  ...        NaN          NaN            NaN   \n",
              "\n",
              "  *Extra 7  *Extra 8  *Extra 9  Sort Key  DRIVER_*Extra 3  DRIVER_*Extra 4  \\\n",
              "0      NaN       NaN       NaN       NaN              NaN              NaN   \n",
              "1      NaN       NaN       NaN       NaN              NaN              NaN   \n",
              "2      NaN       NaN       NaN       NaN              NaN              NaN   \n",
              "3      NaN       NaN       NaN       NaN              NaN              NaN   \n",
              "4      NaN       NaN       NaN       NaN              NaN              NaN   \n",
              "\n",
              "   DRIVER_*Extra 5  \n",
              "0              NaN  \n",
              "1              NaN  \n",
              "2              NaN  \n",
              "3              NaN  \n",
              "4              NaN  \n",
              "\n",
              "[5 rows x 28 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Step 1.5: Display the cleaned race results data\n",
        "# Let's see what we're working with\n",
        "\n",
        "print(f\"\\nTotal Drivers: {len(race_results)}\")\n",
        "print(f\"Key Columns: POSITION, NUMBER, STATUS, LAPS, TOTAL_TIME\")\n",
        "print(f\"\\nTop 10 Finishers:\")\n",
        "print(race_results[['POSITION', 'NUMBER', 'STATUS', 'LAPS', 'TOTAL_TIME', 'FL_TIME']].head(10))\n",
        "\n",
        "print(f\"\\n\\nFull dataset:\")\n",
        "race_results.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lap_analysis = pd.read_csv(\n",
        "    DATA_DIR / \"23_AnalysisEnduranceWithSections_Race 1_Anonymized.CSV\",\n",
        "    sep=';'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(486, 39)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "lap_analysis.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Phase 2: Basic Race Overview\n",
        "\n",
        "Now that we have all our data prepared, let's extract the fundamental race story elements.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "BASIC RACE OVERVIEW\n",
            "================================================================================\n",
            "\n",
            "ðŸ Race Summary:\n",
            "   - Track: Circuit of the Americas (COTA)\n",
            "   - Total Drivers: 31\n",
            "   - Drivers Classified: 31\n",
            "   - Total Laps: 17\n",
            "\n",
            "â±ï¸  Race Duration:\n",
            "   - Winner's Total Time: 45:57.575\n",
            "\n",
            "ðŸ† Race Winner:\n",
            "   - Car Number: 46\n",
            "   - Fastest Lap: 2:28.630 (on lap 8)\n",
            "   - Fastest Lap Speed: 132.5 km/h\n"
          ]
        }
      ],
      "source": [
        "# Step 2.1: Basic Race Statistics - Overall Race Summary\n",
        "print(\"=\" * 80)\n",
        "print(\"BASIC RACE OVERVIEW\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(f\"\\nðŸ Race Summary:\")\n",
        "print(f\"   - Track: Circuit of the Americas (COTA)\")\n",
        "print(f\"   - Total Drivers: {len(race_results)}\")\n",
        "print(f\"   - Drivers Classified: {len(race_results[race_results['STATUS'] == 'Classified'])}\")\n",
        "print(f\"   - Total Laps: {race_results['LAPS'].max()}\")\n",
        "\n",
        "# Calculate race duration (assuming winner's time is total race time)\n",
        "print(f\"\\nâ±ï¸  Race Duration:\")\n",
        "winner_time = race_results[race_results['POSITION'] == 1]['TOTAL_TIME'].values[0]\n",
        "print(f\"   - Winner's Total Time: {winner_time}\")\n",
        "\n",
        "print(f\"\\nðŸ† Race Winner:\")\n",
        "winner = race_results[race_results['POSITION'] == 1].iloc[0]\n",
        "print(f\"   - Car Number: {winner['NUMBER']}\")\n",
        "print(f\"   - Fastest Lap: {winner['FL_TIME']} (on lap {winner['FL_LAPNUM']})\")\n",
        "print(f\"   - Fastest Lap Speed: {winner['FL_KPH']} km/h\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "FASTEST LAP OF THE RACE\n",
            "================================================================================\n",
            "\n",
            "âš¡ Overall Fastest Lap:\n",
            "   - Car Number: 46\n",
            "   - Lap Number: 8\n",
            "   - Time: 2:28.630\n",
            "   - Speed: 132.5 km/h\n",
            "\n",
            "ðŸ“Š Top 5 Fastest Laps:\n",
            "   46 - 2:28.630 (lap 8, 132.5 km/h)\n",
            "    7 - 2:28.678 (lap 7, 132.5 km/h)\n",
            "   55 - 2:28.679 (lap 10, 132.5 km/h)\n",
            "   16 - 2:28.726 (lap 9, 132.4 km/h)\n",
            "   13 - 2:28.745 (lap 9, 132.4 km/h)\n"
          ]
        }
      ],
      "source": [
        "# Step 2.2: Identify Fastest Lap of the Race\n",
        "# Find the absolute fastest lap across all drivers\n",
        "\n",
        "# Get fastest lap times from race results\n",
        "fastest_laps = race_results[['NUMBER', 'FL_TIME', 'FL_LAPNUM', 'FL_KPH']].copy()\n",
        "fastest_laps['FL_TIME_SECONDS'] = fastest_laps['FL_TIME'].apply(time_to_seconds)\n",
        "\n",
        "# Find overall fastest lap\n",
        "overall_fastest_idx = fastest_laps['FL_TIME_SECONDS'].idxmin()\n",
        "overall_fastest = fastest_laps.loc[overall_fastest_idx]\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"FASTEST LAP OF THE RACE\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\nâš¡ Overall Fastest Lap:\")\n",
        "print(f\"   - Car Number: {overall_fastest['NUMBER']}\")\n",
        "print(f\"   - Lap Number: {overall_fastest['FL_LAPNUM']}\")\n",
        "print(f\"   - Time: {overall_fastest['FL_TIME']}\")\n",
        "print(f\"   - Speed: {overall_fastest['FL_KPH']} km/h\")\n",
        "\n",
        "print(f\"\\nðŸ“Š Top 5 Fastest Laps:\")\n",
        "top_5_fastest = fastest_laps.nsmallest(5, 'FL_TIME_SECONDS')[['NUMBER', 'FL_TIME', 'FL_LAPNUM', 'FL_KPH']]\n",
        "for idx, row in top_5_fastest.iterrows():\n",
        "    print(f\"   {row['NUMBER']:2d} - {row['FL_TIME']} (lap {row['FL_LAPNUM']}, {row['FL_KPH']} km/h)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "RACE COMPLETION STATISTICS\n",
            "================================================================================\n",
            "\n",
            "ðŸ“‹ Completion Status:\n",
            "   - Classified: 31 drivers\n",
            "\n",
            "ðŸ“Š Laps Completed Distribution:\n",
            "LAPS\n",
            "17    26\n",
            "14     1\n",
            "13     1\n",
            "10     1\n",
            "6      1\n",
            "1      1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "ðŸ’¡ Race Finish Rate:\n",
            "   - Drivers who completed all 17 laps: 26/31\n",
            "   - Completion Rate: 83.9%\n"
          ]
        }
      ],
      "source": [
        "# Step 2.3: Race Completion Statistics\n",
        "print(\"=\" * 80)\n",
        "print(\"RACE COMPLETION STATISTICS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "completion_status = race_results['STATUS'].value_counts()\n",
        "print(f\"\\nðŸ“‹ Completion Status:\")\n",
        "for status, count in completion_status.items():\n",
        "    print(f\"   - {status}: {count} drivers\")\n",
        "\n",
        "print(f\"\\nðŸ“Š Laps Completed Distribution:\")\n",
        "laps_distribution = race_results['LAPS'].value_counts().sort_index(ascending=False)\n",
        "print(laps_distribution)\n",
        "\n",
        "print(f\"\\nðŸ’¡ Race Finish Rate:\")\n",
        "total_laps = race_results['LAPS'].max()\n",
        "finished_all_laps = len(race_results[race_results['LAPS'] == total_laps])\n",
        "print(f\"   - Drivers who completed all {total_laps} laps: {finished_all_laps}/{len(race_results)}\")\n",
        "print(f\"   - Completion Rate: {finished_all_laps/len(race_results)*100:.1f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "FINAL POSITION GAPS\n",
            "================================================================================\n",
            "\n",
            "ðŸ“ Top 10 Final Gaps to Winner:\n",
            "   P 1 - Car #46: Leader\n",
            "   P 2 - Car # 7: +0.684s (+0.684)\n",
            "   P 3 - Car #16: +1.013s (+1.013)\n",
            "   P 4 - Car #55: +1.305s (+1.305)\n",
            "   P 5 - Car #72: +2.218s (+2.218)\n",
            "   P 6 - Car #13: +2.597s (+2.597)\n",
            "   P 7 - Car #78: +5.023s (+5.023)\n",
            "   P 8 - Car #41: +5.956s (+5.956)\n",
            "   P 9 - Car #71: +6.541s (+6.541)\n",
            "   P10 - Car #21: +6.773s (+6.773)\n",
            "\n",
            "ðŸ“Š Gap Statistics:\n",
            "   - Smallest gap to leader: 0.684s\n",
            "   - Largest gap to leader: 57.854s\n",
            "   - Average gap (excluding leader): 18.195s\n"
          ]
        }
      ],
      "source": [
        "# Step 2.4: Analyze Gap to Leader (Final Positions)\n",
        "print(\"=\" * 80)\n",
        "print(\"FINAL POSITION GAPS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Convert gap times to seconds for analysis\n",
        "def parse_gap(gap_str):\n",
        "    \"\"\"Parse gap string like '+0.684' or '-' to seconds\"\"\"\n",
        "    if pd.isna(gap_str) or gap_str == '-' or gap_str == '':\n",
        "        return 0  # Leader or no gap\n",
        "    \n",
        "    gap_str = str(gap_str).strip()\n",
        "    if gap_str.startswith('+'):\n",
        "        try:\n",
        "            return float(gap_str[1:])\n",
        "        except:\n",
        "            return np.nan\n",
        "    return np.nan\n",
        "\n",
        "race_results['GAP_FIRST_SECONDS'] = race_results['GAP_FIRST'].apply(parse_gap)\n",
        "race_results['GAP_PREVIOUS_SECONDS'] = race_results['GAP_PREVIOUS'].apply(parse_gap)\n",
        "\n",
        "print(f\"\\nðŸ“ Top 10 Final Gaps to Winner:\")\n",
        "top_10 = race_results.nsmallest(10, 'POSITION')[['POSITION', 'NUMBER', 'GAP_FIRST', 'GAP_FIRST_SECONDS']]\n",
        "for idx, row in top_10.iterrows():\n",
        "    if row['POSITION'] == 1:\n",
        "        print(f\"   P{row['POSITION']:2d} - Car #{row['NUMBER']:2d}: Leader\")\n",
        "    else:\n",
        "        print(f\"   P{row['POSITION']:2d} - Car #{row['NUMBER']:2d}: +{row['GAP_FIRST_SECONDS']:.3f}s ({row['GAP_FIRST']})\")\n",
        "\n",
        "print(f\"\\nðŸ“Š Gap Statistics:\")\n",
        "valid_gaps = race_results['GAP_FIRST_SECONDS'][race_results['GAP_FIRST_SECONDS'] > 0]\n",
        "if len(valid_gaps) > 0:\n",
        "    print(f\"   - Smallest gap to leader: {valid_gaps.min():.3f}s\")\n",
        "    print(f\"   - Largest gap to leader: {valid_gaps.max():.3f}s\")\n",
        "    print(f\"   - Average gap (excluding leader): {valid_gaps.mean():.3f}s\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "LAP ANALYSIS OVERVIEW\n",
            "================================================================================\n",
            "\n",
            "ðŸ“ˆ Lap Data Summary:\n",
            "   - Total lap records: 486\n",
            "   - Unique cars: 30\n",
            "   - Unique drivers: 1\n",
            "   - Laps per car range: 1 to 34\n",
            "\n",
            "â±ï¸  Lap Time Statistics:\n",
            "   - Fastest lap in dataset: 148.630s\n",
            "   - Slowest lap in dataset: 741.996s\n",
            "   - Average lap time: 165.335s\n",
            "   - Median lap time: 152.419s\n",
            "\n",
            "âš¡ Fastest Lap Record:\n",
            "   - Car Number: 46\n",
            "   - Lap Number: 8\n",
            "   - Time: 2:28.630 (148.630s)\n",
            "   - Speed: 132.5 km/h\n"
          ]
        }
      ],
      "source": [
        "# Step 2.5: Lap Analysis Overview - Key Statistics\n",
        "print(\"=\" * 80)\n",
        "print(\"LAP ANALYSIS OVERVIEW\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(f\"\\nðŸ“ˆ Lap Data Summary:\")\n",
        "print(f\"   - Total lap records: {len(lap_analysis):,}\")\n",
        "print(f\"   - Unique cars: {lap_analysis['NUMBER'].nunique()}\")\n",
        "print(f\"   - Unique drivers: {lap_analysis['DRIVER_NUMBER'].nunique()}\")\n",
        "print(f\"   - Laps per car range: {lap_analysis.groupby('NUMBER')['LAP_NUMBER'].count().min()} to {lap_analysis.groupby('NUMBER')['LAP_NUMBER'].count().max()}\")\n",
        "\n",
        "# Check if we have LAP_TIME_SECONDS calculated, if not, calculate it\n",
        "if 'LAP_TIME_SECONDS' not in lap_analysis.columns:\n",
        "    lap_analysis['LAP_TIME_SECONDS'] = lap_analysis['LAP_TIME'].apply(time_to_sec)\n",
        "\n",
        "print(f\"\\nâ±ï¸  Lap Time Statistics:\")\n",
        "print(f\"   - Fastest lap in dataset: {lap_analysis['LAP_TIME_SECONDS'].min():.3f}s\")\n",
        "print(f\"   - Slowest lap in dataset: {lap_analysis['LAP_TIME_SECONDS'].max():.3f}s\")\n",
        "print(f\"   - Average lap time: {lap_analysis['LAP_TIME_SECONDS'].mean():.3f}s\")\n",
        "print(f\"   - Median lap time: {lap_analysis['LAP_TIME_SECONDS'].median():.3f}s\")\n",
        "\n",
        "# Find which car and lap had the fastest time\n",
        "fastest_lap_record = lap_analysis.loc[lap_analysis['LAP_TIME_SECONDS'].idxmin()]\n",
        "    print(f\"\\nâš¡ Fastest Lap Record:\")\n",
        "    print(f\"   - Car Number: {fastest_lap_record['NUMBER']}\")\n",
        "    print(f\"   - Lap Number: {fastest_lap_record['LAP_NUMBER']}\")\n",
        "    print(f\"   - Time: {fastest_lap_record['LAP_TIME']} ({fastest_lap_record['LAP_TIME_SECONDS']:.3f}s)\")\n",
        "    print(f\"   - Speed: {fastest_lap_record['KPH']:.1f} km/h\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Phase 2 Progress:**\n",
        "âœ… Basic race statistics extracted\n",
        "âœ… Fastest lap identified\n",
        "âœ… Race completion analyzed\n",
        "âœ… Position gaps calculated\n",
        "âœ… Lap analysis overview complete\n",
        "\n",
        "**Next:** We'll start Phase 3 - Position Over Time Analysis to track how positions changed throughout the race.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Phase 3: Position Over Time Analysis\n",
        "\n",
        "Tracking how each driver's position changed throughout the race - this is crucial for the race story!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "POSITION OVER TIME ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "âœ“ Filtered lap data:\n",
            "   - Total valid lap records: 485\n",
            "   - Removed invalid/slow laps: 1\n",
            "\n",
            "âœ“ Cumulative time calculated for each driver\n"
          ]
        }
      ],
      "source": [
        "# Step 3.1: Calculate position for each driver at each lap\n",
        "# We need to rank drivers by lap time at each lap to determine their position\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"POSITION OVER TIME ANALYSIS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Ensure we have LAP_TIME_SECONDS\n",
        "if 'LAP_TIME_SECONDS' not in lap_analysis.columns:\n",
        "    lap_analysis['LAP_TIME_SECONDS'] = lap_analysis['LAP_TIME'].apply(time_to_sec)\n",
        "\n",
        "# Remove invalid lap times (NaN, very slow laps that might be pit stops or issues)\n",
        "valid_laps = lap_analysis[\n",
        "    (lap_analysis['LAP_TIME_SECONDS'].notna()) & \n",
        "    (lap_analysis['LAP_TIME_SECONDS'] < 500)  # Filter out very slow laps (likely pit stops/issues)\n",
        "].copy()\n",
        "\n",
        "print(f\"\\nâœ“ Filtered lap data:\")\n",
        "print(f\"   - Total valid lap records: {len(valid_laps):,}\")\n",
        "print(f\"   - Removed invalid/slow laps: {len(lap_analysis) - len(valid_laps):,}\")\n",
        "\n",
        "# Calculate cumulative time for each driver at each lap\n",
        "valid_laps = valid_laps.sort_values(['NUMBER', 'LAP_NUMBER'])\n",
        "valid_laps['CUMULATIVE_TIME'] = valid_laps.groupby('NUMBER')['LAP_TIME_SECONDS'].cumsum()\n",
        "\n",
        "print(f\"\\nâœ“ Cumulative time calculated for each driver\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NUMBER</th>\n",
              "      <th>DRIVER_NUMBER</th>\n",
              "      <th>LAP_NUMBER</th>\n",
              "      <th>LAP_TIME</th>\n",
              "      <th>LAP_IMPROVEMENT</th>\n",
              "      <th>CROSSING_FINISH_LINE_IN_PIT</th>\n",
              "      <th>S1</th>\n",
              "      <th>S1_IMPROVEMENT</th>\n",
              "      <th>S2</th>\n",
              "      <th>S2_IMPROVEMENT</th>\n",
              "      <th>...</th>\n",
              "      <th>IM3a_elapsed</th>\n",
              "      <th>FL_time</th>\n",
              "      <th>FL_elapsed</th>\n",
              "      <th>LAP_TIME_SECONDS</th>\n",
              "      <th>S1_SECONDS_CALC</th>\n",
              "      <th>S2_SECONDS_CALC</th>\n",
              "      <th>S3_SECONDS_CALC</th>\n",
              "      <th>SECTORS_SUM</th>\n",
              "      <th>TIME_DIFF</th>\n",
              "      <th>CUMULATIVE_TIME</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3:52.412</td>\n",
              "      <td>0</td>\n",
              "      <td>B</td>\n",
              "      <td>47.663</td>\n",
              "      <td>0</td>\n",
              "      <td>1:24.393</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>2:54.458</td>\n",
              "      <td>57.954</td>\n",
              "      <td>3:52.412</td>\n",
              "      <td>232.412</td>\n",
              "      <td>47.663</td>\n",
              "      <td>84.393</td>\n",
              "      <td>100.356</td>\n",
              "      <td>232.412</td>\n",
              "      <td>2.842171e-14</td>\n",
              "      <td>232.412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3:46.084</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>53.893</td>\n",
              "      <td>0</td>\n",
              "      <td>1:28.398</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>2:59.017</td>\n",
              "      <td>47.067</td>\n",
              "      <td>3:46.084</td>\n",
              "      <td>226.084</td>\n",
              "      <td>53.893</td>\n",
              "      <td>88.398</td>\n",
              "      <td>83.793</td>\n",
              "      <td>226.084</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>226.084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3:45.016</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>51.110</td>\n",
              "      <td>0</td>\n",
              "      <td>1:27.200</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>2:56.155</td>\n",
              "      <td>48.861</td>\n",
              "      <td>3:45.016</td>\n",
              "      <td>225.016</td>\n",
              "      <td>51.110</td>\n",
              "      <td>87.200</td>\n",
              "      <td>86.706</td>\n",
              "      <td>225.016</td>\n",
              "      <td>2.842171e-14</td>\n",
              "      <td>451.100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2:48.736</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>45.381</td>\n",
              "      <td>0</td>\n",
              "      <td>1:00.988</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>2:16.804</td>\n",
              "      <td>31.932</td>\n",
              "      <td>2:48.736</td>\n",
              "      <td>168.736</td>\n",
              "      <td>45.381</td>\n",
              "      <td>60.988</td>\n",
              "      <td>62.367</td>\n",
              "      <td>168.736</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>619.836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2:47.237</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>44.356</td>\n",
              "      <td>0</td>\n",
              "      <td>1:00.329</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>2:14.665</td>\n",
              "      <td>32.572</td>\n",
              "      <td>2:47.237</td>\n",
              "      <td>167.237</td>\n",
              "      <td>44.356</td>\n",
              "      <td>60.329</td>\n",
              "      <td>62.552</td>\n",
              "      <td>167.237</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>787.073</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 46 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     NUMBER  DRIVER_NUMBER  LAP_NUMBER  LAP_TIME  LAP_IMPROVEMENT  \\\n",
              "118       2              1           1  3:52.412                0   \n",
              "0         3              1           1  3:46.084                0   \n",
              "136       3              1           1  3:45.016                0   \n",
              "1         3              1           2  2:48.736                0   \n",
              "137       3              1           2  2:47.237                0   \n",
              "\n",
              "    CROSSING_FINISH_LINE_IN_PIT      S1  S1_IMPROVEMENT        S2  \\\n",
              "118                           B  47.663               0  1:24.393   \n",
              "0                           NaN  53.893               0  1:28.398   \n",
              "136                         NaN  51.110               0  1:27.200   \n",
              "1                           NaN  45.381               0  1:00.988   \n",
              "137                         NaN  44.356               0  1:00.329   \n",
              "\n",
              "     S2_IMPROVEMENT  ... IM3a_elapsed  FL_time  FL_elapsed LAP_TIME_SECONDS  \\\n",
              "118               2  ...     2:54.458   57.954    3:52.412          232.412   \n",
              "0                 0  ...     2:59.017   47.067    3:46.084          226.084   \n",
              "136               0  ...     2:56.155   48.861    3:45.016          225.016   \n",
              "1                 0  ...     2:16.804   31.932    2:48.736          168.736   \n",
              "137               0  ...     2:14.665   32.572    2:47.237          167.237   \n",
              "\n",
              "    S1_SECONDS_CALC S2_SECONDS_CALC S3_SECONDS_CALC SECTORS_SUM     TIME_DIFF  \\\n",
              "118          47.663          84.393         100.356     232.412  2.842171e-14   \n",
              "0            53.893          88.398          83.793     226.084  0.000000e+00   \n",
              "136          51.110          87.200          86.706     225.016  2.842171e-14   \n",
              "1            45.381          60.988          62.367     168.736  0.000000e+00   \n",
              "137          44.356          60.329          62.552     167.237  0.000000e+00   \n",
              "\n",
              "    CUMULATIVE_TIME  \n",
              "118         232.412  \n",
              "0           226.084  \n",
              "136         451.100  \n",
              "1           619.836  \n",
              "137         787.073  \n",
              "\n",
              "[5 rows x 46 columns]"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "valid_laps.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3.1a: Data Quality Check and Deduplication for Lap Records\n",
        "We will check for duplicate (NUMBER, LAP_NUMBER) records and, if found, deduplicate by keeping the fastest lap per (car, lap). This ensures position calculations are accurate. This cell augments Step 3.1 without altering it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "STEP 3.1a - CHECKING & FIXING DUPLICATE LAP RECORDS\n",
            "================================================================================\n",
            "\n",
            "ðŸ“Š Duplicate Analysis:\n",
            "   - Unique (car, lap) pairs: 469\n",
            "   - Pairs with duplicates: 17\n",
            "\n",
            "âš ï¸  Duplicates detected. Deduplicating by keeping the fastest lap per (car, lap)\n",
            "\n",
            "âœ“ valid_laps prepared for position calculation\n",
            "   - Records: 468\n",
            "   - Unique cars: 30\n",
            "   - Laps range: 1 to 17\n"
          ]
        }
      ],
      "source": [
        "# Check and fix duplicates for (NUMBER, LAP_NUMBER)\n",
        "print(\"=\" * 80)\n",
        "print(\"STEP 3.1a - CHECKING & FIXING DUPLICATE LAP RECORDS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Ensure LAP_TIME_SECONDS exists\n",
        "if 'LAP_TIME_SECONDS' not in lap_analysis.columns:\n",
        "    lap_analysis['LAP_TIME_SECONDS'] = lap_analysis['LAP_TIME'].apply(time_to_sec)\n",
        "\n",
        "# Check duplicates by (NUMBER, LAP_NUMBER)\n",
        "duplicate_check = lap_analysis.groupby(['NUMBER', 'LAP_NUMBER']).size().reset_index(name='COUNT')\n",
        "duplicates = duplicate_check[duplicate_check['COUNT'] > 1]\n",
        "\n",
        "print(f\"\\nðŸ“Š Duplicate Analysis:\")\n",
        "print(f\"   - Unique (car, lap) pairs: {len(duplicate_check)}\")\n",
        "print(f\"   - Pairs with duplicates: {len(duplicates)}\")\n",
        "\n",
        "# Build a deduplicated dataset for position analysis\n",
        "if len(duplicates) > 0:\n",
        "    print(\"\\nâš ï¸  Duplicates detected. Deduplicating by keeping the fastest lap per (car, lap)\")\n",
        "    lap_analysis_dedup = lap_analysis.sort_values('LAP_TIME_SECONDS').drop_duplicates(\n",
        "        subset=['NUMBER', 'LAP_NUMBER'], keep='first'\n",
        "    ).reset_index(drop=True)\n",
        "else:\n",
        "    print(\"\\nâœ“ No duplicates detected. Using original lap_analysis\")\n",
        "    lap_analysis_dedup = lap_analysis.copy()\n",
        "\n",
        "# Rebuild valid_laps from deduplicated data\n",
        "valid_laps = lap_analysis_dedup[\n",
        "    (lap_analysis_dedup['LAP_TIME_SECONDS'].notna()) & \n",
        "    (lap_analysis_dedup['LAP_TIME_SECONDS'] < 500)\n",
        "].copy()\n",
        "\n",
        "# Recompute cumulative time over deduped data\n",
        "valid_laps = valid_laps.sort_values(['NUMBER', 'LAP_NUMBER'])\n",
        "valid_laps['CUMULATIVE_TIME'] = valid_laps.groupby('NUMBER')['LAP_TIME_SECONDS'].cumsum()\n",
        "\n",
        "print(f\"\\nâœ“ valid_laps prepared for position calculation\")\n",
        "print(f\"   - Records: {len(valid_laps)}\")\n",
        "print(f\"   - Unique cars: {valid_laps['NUMBER'].nunique()}\")\n",
        "print(f\"   - Laps range: {valid_laps['LAP_NUMBER'].min()} to {valid_laps['LAP_NUMBER'].max()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3.2a: Recalculate Positions Using Deduplicated Data\n",
        "This cell recomputes `position_df` using the `valid_laps` produced in Step 3.1a (if duplicates existed), keeping your original Step 3.2 intact.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recomputing positions with deduplicated data (if any)...\n",
            "\n",
            "âœ“ position_df recomputed\n",
            "   - Total records: 468\n",
            "   - Unique cars: 30\n",
            "   - Laps range: 1 to 17\n"
          ]
        }
      ],
      "source": [
        "# Recompute positions based on deduplicated valid_laps\n",
        "print(\"Recomputing positions with deduplicated data (if any)...\")\n",
        "position_over_time_dedup = []\n",
        "\n",
        "for lap_num in sorted(valid_laps['LAP_NUMBER'].unique()):\n",
        "    lap_data = valid_laps[valid_laps['LAP_NUMBER'] == lap_num].copy()\n",
        "    lap_data['POSITION_AT_LAP'] = lap_data['CUMULATIVE_TIME'].rank(method='min').astype(int)\n",
        "    position_over_time_dedup.append(\n",
        "        lap_data[['NUMBER', 'LAP_NUMBER', 'CUMULATIVE_TIME', 'POSITION_AT_LAP', 'LAP_TIME_SECONDS']]\n",
        "    )\n",
        "\n",
        "position_df = pd.concat(position_over_time_dedup, ignore_index=True)\n",
        "\n",
        "print(f\"\\nâœ“ position_df recomputed\")\n",
        "print(f\"   - Total records: {len(position_df)}\")\n",
        "print(f\"   - Unique cars: {position_df['NUMBER'].nunique()}\")\n",
        "print(f\"   - Laps range: {position_df['LAP_NUMBER'].min()} to {position_df['LAP_NUMBER'].max()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating positions for each lap...\n",
            "âœ“ Position calculated for 485 lap records\n",
            "   - Laps analyzed: 1 to 17\n",
            "   - Unique cars tracked: 30\n",
            "\n",
            "   Sample position data (first 20 records):\n",
            "    NUMBER  LAP_NUMBER  CUMULATIVE_TIME  POSITION_AT_LAP  LAP_TIME_SECONDS\n",
            "0        2           1          232.412               30           232.412\n",
            "1        3           1          226.084               23           226.084\n",
            "2        3           1          451.100               31           225.016\n",
            "3        5           1          224.242               17           224.242\n",
            "4        7           1          221.242                2           221.242\n",
            "5        8           1          228.304               28           228.304\n",
            "6       11           1          225.563               21           225.563\n",
            "7       13           1          221.580                3           221.580\n",
            "8       14           1          224.381               18           224.381\n",
            "9       15           1          222.783                9           222.783\n",
            "10      16           1          222.042                4           222.042\n",
            "11      18           1          227.239               26           227.239\n",
            "12      21           1          222.783                9           222.783\n",
            "13      31           1          223.327               14           223.327\n",
            "14      41           1          222.681                8           222.681\n",
            "15      46           1          221.204                1           221.204\n",
            "16      47           1          223.295               13           223.295\n",
            "17      51           1          226.479               24           226.479\n",
            "18      55           1          222.396                7           222.396\n",
            "19      57           1          227.803               27           227.803\n"
          ]
        }
      ],
      "source": [
        "# Step 3.2: Calculate position at each lap based on cumulative time\n",
        "# Driver with lowest cumulative time at each lap is in position 1\n",
        "\n",
        "print(\"Calculating positions for each lap...\")\n",
        "\n",
        "# For each lap, rank drivers by cumulative time\n",
        "position_over_time = []\n",
        "\n",
        "for lap_num in sorted(valid_laps['LAP_NUMBER'].unique()):\n",
        "    lap_data = valid_laps[valid_laps['LAP_NUMBER'] == lap_num].copy()\n",
        "    \n",
        "    # Rank by cumulative time (lower = better position)\n",
        "    lap_data['POSITION_AT_LAP'] = lap_data['CUMULATIVE_TIME'].rank(method='min').astype(int)\n",
        "    \n",
        "    position_over_time.append(lap_data[['NUMBER', 'LAP_NUMBER', 'CUMULATIVE_TIME', 'POSITION_AT_LAP', 'LAP_TIME_SECONDS']])\n",
        "\n",
        "# Combine all laps\n",
        "position_df = pd.concat(position_over_time, ignore_index=True)\n",
        "\n",
        "print(f\"âœ“ Position calculated for {len(position_df):,} lap records\")\n",
        "print(f\"   - Laps analyzed: {position_df['LAP_NUMBER'].min()} to {position_df['LAP_NUMBER'].max()}\")\n",
        "print(f\"   - Unique cars tracked: {position_df['NUMBER'].nunique()}\")\n",
        "\n",
        "# Display sample\n",
        "print(f\"\\n   Sample position data (first 20 records):\")\n",
        "print(position_df.head(20))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "BIGGEST POSITION CHANGES\n",
            "================================================================================\n",
            "\n",
            "ðŸ“ˆ Biggest Position Gains (from start to finish):\n",
            "   Car #71: P29 â†’ P10 (Gained 19 positions)\n",
            "   Car # 3: P21 â†’ P 5 (Gained 16 positions)\n",
            "   Car # 3: P21 â†’ P 5 (Gained 16 positions)\n",
            "   Car # 8: P28 â†’ P22 (Gained 6 positions)\n",
            "   Car #57: P27 â†’ P21 (Gained 6 positions)\n",
            "   Car #86: P25 â†’ P19 (Gained 6 positions)\n",
            "   Car #88: P19 â†’ P14 (Gained 5 positions)\n",
            "   Car #78: P12 â†’ P 8 (Gained 4 positions)\n",
            "   Car #14: P18 â†’ P15 (Gained 3 positions)\n",
            "   Car #18: P26 â†’ P23 (Gained 3 positions)\n",
            "\n",
            "ðŸ“‰ Biggest Position Losses (from start to finish):\n",
            "   Car #89: P 5 â†’ P18 (Lost 13 positions)\n",
            "   Car #113: P16 â†’ P25 (Lost 9 positions)\n",
            "   Car #13: P 3 â†’ P 7 (Lost 4 positions)\n",
            "   Car #21: P 9 â†’ P11 (Lost 2 positions)\n",
            "   Car #41: P 8 â†’ P 9 (Lost 1 positions)\n",
            "   Car #73: P23 â†’ P24 (Lost 1 positions)\n",
            "   Car #93: P15 â†’ P16 (Lost 1 positions)\n",
            "   Car #98: P11 â†’ P12 (Lost 1 positions)\n",
            "   Car # 5: P17 â†’ P17 (Lost 0 positions)\n",
            "   Car # 7: P 2 â†’ P 2 (Lost 0 positions)\n"
          ]
        }
      ],
      "source": [
        "# Step 3.3: Identify biggest position changes (gains and losses)\n",
        "print(\"=\" * 80)\n",
        "print(\"BIGGEST POSITION CHANGES\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Get starting and ending positions for each driver\n",
        "start_positions = position_df[position_df['LAP_NUMBER'] == position_df['LAP_NUMBER'].min()].copy()\n",
        "end_positions = position_df[position_df['LAP_NUMBER'] == position_df['LAP_NUMBER'].max()].copy()\n",
        "\n",
        "# Merge to compare\n",
        "position_change = pd.merge(\n",
        "    start_positions[['NUMBER', 'POSITION_AT_LAP']].rename(columns={'POSITION_AT_LAP': 'START_POSITION'}),\n",
        "    end_positions[['NUMBER', 'POSITION_AT_LAP']].rename(columns={'POSITION_AT_LAP': 'END_POSITION'}),\n",
        "    on='NUMBER'\n",
        ")\n",
        "\n",
        "# Calculate position change (negative = gained positions, positive = lost positions)\n",
        "position_change['POSITION_CHANGE'] = position_change['START_POSITION'] - position_change['END_POSITION']\n",
        "position_change['POSITIONS_GAINED'] = position_change['POSITION_CHANGE'].apply(lambda x: abs(x) if x > 0 else 0)\n",
        "position_change['POSITIONS_LOST'] = position_change['POSITION_CHANGE'].apply(lambda x: abs(x) if x < 0 else 0)\n",
        "\n",
        "# Merge with final race results to see actual final position\n",
        "position_change = position_change.merge(\n",
        "    race_results[['NUMBER', 'POSITION']].rename(columns={'POSITION': 'FINAL_POSITION'}),\n",
        "    on='NUMBER'\n",
        ")\n",
        "\n",
        "print(f\"\\nðŸ“ˆ Biggest Position Gains (from start to finish):\")\n",
        "biggest_gains = position_change.nlargest(10, 'POSITION_CHANGE')[['NUMBER', 'START_POSITION', 'END_POSITION', 'FINAL_POSITION', 'POSITION_CHANGE']]\n",
        "for idx, row in biggest_gains.iterrows():\n",
        "    print(f\"   Car #{row['NUMBER']:2d}: P{row['START_POSITION']:2d} â†’ P{row['END_POSITION']:2d} (Gained {row['POSITION_CHANGE']:.0f} positions)\")\n",
        "\n",
        "print(f\"\\nðŸ“‰ Biggest Position Losses (from start to finish):\")\n",
        "biggest_losses = position_change.nsmallest(10, 'POSITION_CHANGE')[['NUMBER', 'START_POSITION', 'END_POSITION', 'FINAL_POSITION', 'POSITION_CHANGE']]\n",
        "for idx, row in biggest_losses.iterrows():\n",
        "    print(f\"   Car #{row['NUMBER']:2d}: P{row['START_POSITION']:2d} â†’ P{row['END_POSITION']:2d} (Lost {abs(row['POSITION_CHANGE']):.0f} positions)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "POSITION VOLATILITY ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "ðŸŽ¯ Most Consistent Drivers (smallest position range):\n",
            "   Car #2.0: Best P30, Worst P30, Range: 0, Avg: 30.0\n",
            "   Car #7.0: Best P1, Worst P3, Range: 2, Avg: 1.8\n",
            "   Car #16.0: Best P3, Worst P5, Range: 2, Avg: 3.6\n",
            "   Car #21.0: Best P9, Worst P11, Range: 2, Avg: 9.9\n",
            "   Car #41.0: Best P7, Worst P9, Range: 2, Avg: 8.2\n",
            "   Car #72.0: Best P6, Worst P8, Range: 2, Avg: 6.7\n",
            "   Car #98.0: Best P11, Worst P13, Range: 2, Avg: 11.8\n",
            "   Car #46.0: Best P1, Worst P4, Range: 3, Avg: 2.2\n",
            "   Car #55.0: Best P4, Worst P7, Range: 3, Avg: 5.7\n",
            "   Car #11.0: Best P18, Worst P22, Range: 4, Avg: 19.4\n",
            "\n",
            "ðŸŒŠ Most Volatile Drivers (largest position range):\n",
            "   Car #31.0: Best P1, Worst P28, Range: 27, Avg: 11.6\n",
            "   Car #89.0: Best P5, Worst P28, Range: 23, Avg: 20.4\n",
            "   Car #3.0: Best P1, Worst P21, Range: 20, Avg: 13.5\n",
            "   Car #15.0: Best P9, Worst P29, Range: 20, Avg: 25.5\n",
            "   Car #71.0: Best P10, Worst P29, Range: 19, Avg: 14.8\n",
            "   Car #113.0: Best P12, Worst P25, Range: 13, Avg: 15.4\n",
            "   Car #80.0: Best P20, Worst P28, Range: 8, Avg: 24.1\n",
            "   Car #5.0: Best P12, Worst P18, Range: 6, Avg: 15.9\n",
            "   Car #8.0: Best P22, Worst P28, Range: 6, Avg: 25.1\n",
            "   Car #51.0: Best P21, Worst P27, Range: 6, Avg: 22.6\n"
          ]
        }
      ],
      "source": [
        "# Step 3.4: Track position changes throughout the race (lap-by-lap)\n",
        "# Find drivers who made the most dramatic moves during the race\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"POSITION VOLATILITY ANALYSIS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Calculate position range for each driver (best position to worst position)\n",
        "position_stats = position_df.groupby('NUMBER').agg({\n",
        "    'POSITION_AT_LAP': ['min', 'max', 'mean', 'std'],\n",
        "    'LAP_NUMBER': 'count'\n",
        "}).reset_index()\n",
        "\n",
        "position_stats.columns = ['NUMBER', 'BEST_POSITION', 'WORST_POSITION', 'AVG_POSITION', 'POSITION_STD', 'TOTAL_LAPS']\n",
        "\n",
        "# Calculate position range\n",
        "position_stats['POSITION_RANGE'] = position_stats['WORST_POSITION'] - position_stats['BEST_POSITION']\n",
        "\n",
        "print(f\"\\nðŸŽ¯ Most Consistent Drivers (smallest position range):\")\n",
        "most_consistent = position_stats.nsmallest(10, 'POSITION_RANGE')[['NUMBER', 'BEST_POSITION', 'WORST_POSITION', 'POSITION_RANGE', 'AVG_POSITION']]\n",
        "for idx, row in most_consistent.iterrows():\n",
        "    print(f\"   Car #{row['NUMBER']}: Best P{row['BEST_POSITION']:.0f}, Worst P{row['WORST_POSITION']:.0f}, Range: {row['POSITION_RANGE']:.0f}, Avg: {row['AVG_POSITION']:.1f}\")\n",
        "\n",
        "print(f\"\\nðŸŒŠ Most Volatile Drivers (largest position range):\")\n",
        "most_volatile = position_stats.nlargest(10, 'POSITION_RANGE')[['NUMBER', 'BEST_POSITION', 'WORST_POSITION', 'POSITION_RANGE', 'AVG_POSITION']]\n",
        "for idx, row in most_volatile.iterrows():\n",
        "    print(f\"   Car #{row['NUMBER']}: Best P{row['BEST_POSITION']:.0f}, Worst P{row['WORST_POSITION']:.0f}, Range: {row['POSITION_RANGE']:.0f}, Avg: {row['AVG_POSITION']:.1f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "KEY OVERTAKING MOMENTS\n",
            "================================================================================\n",
            "\n",
            "âš¡ Significant Position Changes (3+ positions in one lap):\n",
            "   Total significant changes: 22\n",
            "\n",
            "   Top 15 Biggest Single-Lap Position Changes:\n",
            "   Car #31.0 on Lap 7.0: P27 â†’ P1 (Gained 26 positions)\n",
            "   Car #71.0 on Lap 2.0: P29 â†’ P17 (Gained 12 positions)\n",
            "   Car #31.0 on Lap 12.0: P7 â†’ P1 (Gained 6 positions)\n",
            "   Car #14.0 on Lap 2.0: P18 â†’ P14 (Gained 4 positions)\n",
            "   Car #89.0 on Lap 14.0: P23 â†’ P19 (Gained 4 positions)\n",
            "   Car #5.0 on Lap 2.0: P17 â†’ P13 (Gained 4 positions)\n",
            "   Car #80.0 on Lap 14.0: P25 â†’ P22 (Gained 3 positions)\n",
            "   Car #71.0 on Lap 14.0: P14 â†’ P11 (Gained 3 positions)\n",
            "   Car #80.0 on Lap 2.0: P20 â†’ P23 (Lost 3 positions)\n",
            "   Car #5.0 on Lap 7.0: P13 â†’ P16 (Lost 3 positions)\n",
            "   Car #113.0 on Lap 15.0: P15 â†’ P18 (Lost 3 positions)\n",
            "   Car #80.0 on Lap 7.0: P23 â†’ P26 (Lost 3 positions)\n",
            "   Car #31.0 on Lap 10.0: P3 â†’ P7 (Lost 4 positions)\n",
            "   Car #113.0 on Lap 16.0: P18 â†’ P24 (Lost 6 positions)\n",
            "   Car #73.0 on Lap 15.0: P18 â†’ P24 (Lost 6 positions)\n"
          ]
        }
      ],
      "source": [
        "# Step 3.5: Identify key overtaking moments\n",
        "# Find laps where positions changed significantly\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"KEY OVERTAKING MOMENTS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Calculate position changes between consecutive laps for each driver\n",
        "position_df_sorted = position_df.sort_values(['NUMBER', 'LAP_NUMBER']).copy()\n",
        "position_df_sorted['PREV_POSITION'] = position_df_sorted.groupby('NUMBER')['POSITION_AT_LAP'].shift(1)\n",
        "position_df_sorted['POSITION_DELTA'] = position_df_sorted['PREV_POSITION'] - position_df_sorted['POSITION_AT_LAP']\n",
        "\n",
        "# Find significant position changes (3+ positions in one lap)\n",
        "significant_changes = position_df_sorted[\n",
        "    (position_df_sorted['POSITION_DELTA'].abs() >= 3) & \n",
        "    (position_df_sorted['PREV_POSITION'].notna())\n",
        "].copy()\n",
        "\n",
        "print(f\"\\nâš¡ Significant Position Changes (3+ positions in one lap):\")\n",
        "print(f\"   Total significant changes: {len(significant_changes)}\")\n",
        "\n",
        "if len(significant_changes) > 0:\n",
        "    significant_changes = significant_changes.sort_values('POSITION_DELTA', ascending=False)\n",
        "    print(f\"\\n   Top 15 Biggest Single-Lap Position Changes:\")\n",
        "    for idx, row in significant_changes.head(15).iterrows():\n",
        "        direction = \"Gained\" if row['POSITION_DELTA'] > 0 else \"Lost\"\n",
        "        print(f\"   Car #{row['NUMBER']} on Lap {row['LAP_NUMBER']}: P{row['PREV_POSITION']:.0f} â†’ P{row['POSITION_AT_LAP']:.0f} ({direction} {abs(row['POSITION_DELTA']):.0f} positions)\")\n",
        "else:\n",
        "    print(\"   No single-lap changes of 3+ positions found\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "RACE LEADERSHIP CHANGES\n",
            "================================================================================\n",
            "\n",
            "ðŸ Race Leadership Timeline:\n",
            "   Total laps with leader data: 17\n",
            "\n",
            "   Number of leader changes: 7\n",
            "\n",
            "   Leader Changes:\n",
            "   Lap  1: Car #46 takes the lead\n",
            "   Lap  4: Car #7 takes the lead\n",
            "   Lap  7: Car #31 takes the lead\n",
            "   Lap  9: Car #7 takes the lead\n",
            "   Lap 12: Car #31 takes the lead\n",
            "   Lap 14: Car #7 takes the lead\n",
            "   Lap 16: Car #46 takes the lead\n",
            "\n",
            "   Laps Led by Each Driver:\n",
            "   Car # 7: 8 laps (47.1%)\n",
            "   Car #46: 5 laps (29.4%)\n",
            "   Car #31: 4 laps (23.5%)\n"
          ]
        }
      ],
      "source": [
        "# Step 3.6: Leader changes throughout the race\n",
        "# Track which driver led at each lap\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"RACE LEADERSHIP CHANGES\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Find leader at each lap (position 1)\n",
        "leaders = position_df[position_df['POSITION_AT_LAP'] == 1].copy()\n",
        "leaders = leaders.sort_values('LAP_NUMBER')\n",
        "\n",
        "print(f\"\\nðŸ Race Leadership Timeline:\")\n",
        "print(f\"   Total laps with leader data: {len(leaders)}\")\n",
        "\n",
        "# Identify when leader changed\n",
        "leaders['LEADER_NUMBER'] = leaders['NUMBER']\n",
        "leaders['PREV_LEADER'] = leaders['LEADER_NUMBER'].shift(1)\n",
        "leaders['LEADER_CHANGED'] = leaders['LEADER_NUMBER'] != leaders['PREV_LEADER']\n",
        "\n",
        "leader_changes = leaders[leaders['LEADER_CHANGED'] == True].copy()\n",
        "\n",
        "print(f\"\\n   Number of leader changes: {len(leader_changes)}\")\n",
        "\n",
        "if len(leader_changes) > 0:\n",
        "    print(f\"\\n   Leader Changes:\")\n",
        "    for idx, row in leader_changes.iterrows():\n",
        "        print(f\"   Lap {row['LAP_NUMBER']:2d}: Car #{row['NUMBER']} takes the lead\")\n",
        "else:\n",
        "    print(f\"\\n   No leader changes - one driver led the entire race!\")\n",
        "\n",
        "# Show who led most laps\n",
        "leader_counts = leaders.groupby('NUMBER').size().sort_values(ascending=False)\n",
        "print(f\"\\n   Laps Led by Each Driver:\")\n",
        "for car_num, laps_led in leader_counts.items():\n",
        "    percentage = (laps_led / len(leaders)) * 100\n",
        "    print(f\"   Car #{car_num:2d}: {laps_led} laps ({percentage:.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Phase 3 Progress:**\n",
        "âœ… Position over time calculated\n",
        "âœ… Biggest position changes identified\n",
        "âœ… Position volatility analyzed\n",
        "âœ… Key overtaking moments found\n",
        "âœ… Race leadership tracked\n",
        "\n",
        "**Next:** We'll analyze Sector Performance to understand where drivers gain/lose time.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Phase 4: Sector Performance Analysis\n",
        "\n",
        "Understand where time is gained or lost (S1, S2, S3) per driver/car and per lap.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Sector seconds columns ready: ['S1_SEC', 'S2_SEC', 'S3_SEC']\n",
            "Valid sector rows: 486\n"
          ]
        }
      ],
      "source": [
        "# Step 4.1: Ensure sector times (in seconds) are available\n",
        "# We will create S1_SEC, S2_SEC, S3_SEC if missing\n",
        "\n",
        "def to_seconds_any(x):\n",
        "    if pd.isna(x) or x == '' or x == '-':\n",
        "        return np.nan\n",
        "    try:\n",
        "        s = str(x).strip()\n",
        "        if ':' in s:\n",
        "            m, rest = s.split(':', 1)\n",
        "            return int(m) * 60 + float(rest)\n",
        "        return float(s)\n",
        "    except Exception:\n",
        "        return np.nan\n",
        "\n",
        "for col_src, col_dst in [('S1','S1_SEC'), ('S2','S2_SEC'), ('S3','S3_SEC')]:\n",
        "    if col_src in lap_analysis.columns and col_dst not in lap_analysis.columns:\n",
        "        lap_analysis[col_dst] = lap_analysis[col_src].apply(to_seconds_any)\n",
        "\n",
        "print(\"âœ“ Sector seconds columns ready:\", [c for c in ['S1_SEC','S2_SEC','S3_SEC'] if c in lap_analysis.columns])\n",
        "\n",
        "# Filter valid sector rows\n",
        "sectors_valid = lap_analysis.dropna(subset=['S1_SEC','S2_SEC','S3_SEC']).copy()\n",
        "print(f\"Valid sector rows: {len(sectors_valid):,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Car sector averages (first 10):\n",
            "   NUMBER     S1_avg     S2_avg      S3_avg  S1_best  S2_best  S3_best  \\\n",
            "0       2  47.663000  84.393000  100.356000   47.663   84.393  100.356   \n",
            "1       3  36.020824  62.729618   64.522824   32.914   57.593   60.037   \n",
            "2       5  35.788824  62.686647   64.694412   32.663   57.820   59.768   \n",
            "3       7  35.884765  62.028824   64.336941   32.544   56.689   59.129   \n",
            "4       8  36.173647  63.284529   64.648118   33.467   58.681   61.245   \n",
            "5      11  36.427100  61.313700   63.267400   33.048   57.988   60.261   \n",
            "6      13  35.920471  62.148941   64.293647   32.526   56.786   59.131   \n",
            "7      14  36.055118  62.372588   64.359294   32.837   57.505   59.468   \n",
            "8      15  75.806333  63.268167   65.743000   33.127   58.301   60.320   \n",
            "9      16  35.854647  62.146176   64.269059   32.431   56.909   59.189   \n",
            "\n",
            "   S1_avg_rank  S2_avg_rank  S3_avg_rank  \n",
            "0         28.0         30.0         30.0  \n",
            "1         15.0         17.0         21.0  \n",
            "2          6.0         16.0         25.0  \n",
            "3         11.0          4.0         16.0  \n",
            "4         18.0         26.0         24.0  \n",
            "5         23.0          2.0          1.0  \n",
            "6         13.0          7.0         14.0  \n",
            "7         16.0         10.0         17.0  \n",
            "8         29.0         25.0         28.0  \n",
            "9         10.0          6.0         13.0  \n"
          ]
        }
      ],
      "source": [
        "# Step 4.2: Sector averages and ranks per car\n",
        "car_sector_stats = sectors_valid.groupby('NUMBER').agg(\n",
        "    S1_avg=('S1_SEC','mean'), S2_avg=('S2_SEC','mean'), S3_avg=('S3_SEC','mean'),\n",
        "    S1_best=('S1_SEC','min'), S2_best=('S2_SEC','min'), S3_best=('S3_SEC','min')\n",
        ").reset_index()\n",
        "\n",
        "# Ranks (lower is better)\n",
        "for col in ['S1_avg','S2_avg','S3_avg']:\n",
        "    car_sector_stats[col + '_rank'] = car_sector_stats[col].rank(method='min')\n",
        "\n",
        "print(\"Car sector averages (first 10):\")\n",
        "print(car_sector_stats.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 10 improvements possible (delta to ideal):\n",
            "Car # 2: best 232.412s, ideal 232.412s, delta 0.000s\n",
            "Car #80: best 152.369s, ideal 152.365s, delta 0.004s\n",
            "Car #88: best 149.418s, ideal 149.355s, delta 0.063s\n",
            "Car #31: best 150.244s, ideal 150.167s, delta 0.077s\n",
            "Car #71: best 149.526s, ideal 149.379s, delta 0.147s\n",
            "Car #15: best 151.899s, ideal 151.748s, delta 0.151s\n",
            "Car #18: best 153.543s, ideal 153.364s, delta 0.179s\n",
            "Car #78: best 149.293s, ideal 149.104s, delta 0.189s\n",
            "Car #16: best 148.726s, ideal 148.529s, delta 0.197s\n",
            "Car #55: best 148.679s, ideal 148.460s, delta 0.219s\n"
          ]
        }
      ],
      "source": [
        "# Step 4.3: Theoretical best lap and delta for each car\n",
        "# Compute \"ideal\" lap as sum of car's best sector times; compare to car's best actual lap\n",
        "\n",
        "# Car ideal lap = S1_best + S2_best + S3_best\n",
        "car_sector_stats['ideal_lap'] = car_sector_stats[['S1_best','S2_best','S3_best']].sum(axis=1)\n",
        "\n",
        "# Car best actual lap from lap_analysis\n",
        "if 'LAP_TIME_SECONDS' not in lap_analysis.columns:\n",
        "    lap_analysis['LAP_TIME_SECONDS'] = lap_analysis['LAP_TIME'].apply(to_seconds_any)\n",
        "\n",
        "car_best_lap = lap_analysis.groupby('NUMBER')['LAP_TIME_SECONDS'].min().reset_index(name='best_actual_lap')\n",
        "car_ideal = car_sector_stats.merge(car_best_lap, on='NUMBER', how='left')\n",
        "car_ideal['delta_ideal_vs_best'] = car_ideal['best_actual_lap'] - car_ideal['ideal_lap']\n",
        "\n",
        "print(\"Top 10 improvements possible (delta to ideal):\")\n",
        "for _, row in car_ideal.nsmallest(10, 'delta_ideal_vs_best').iterrows():\n",
        "    print(f\"Car #{int(row['NUMBER']):2d}: best {row['best_actual_lap']:.3f}s, ideal {row['ideal_lap']:.3f}s, delta {row['delta_ideal_vs_best']:.3f}s\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cars with biggest single-sector weaknesses (top 10):\n",
            "Car #31: worst S1 (+55.433s vs field best)\n",
            "Car #15: worst S1 (+43.417s vs field best)\n",
            "Car # 2: worst S3 (+41.438s vs field best)\n",
            "Car #51: worst S1 (+9.739s vs field best)\n",
            "Car #18: worst S2 (+7.254s vs field best)\n",
            "Car #57: worst S2 (+6.888s vs field best)\n",
            "Car # 8: worst S2 (+6.596s vs field best)\n",
            "Car #73: worst S3 (+6.521s vs field best)\n",
            "Car #113: worst S2 (+6.517s vs field best)\n",
            "Car #86: worst S2 (+6.498s vs field best)\n"
          ]
        }
      ],
      "source": [
        "# Step 4.4: Which sector costs each car the most (vs field best)?\n",
        "# Compute field-best sector times and per-car deltas\n",
        "field_best = {\n",
        "    'S1_best_field': sectors_valid['S1_SEC'].min(),\n",
        "    'S2_best_field': sectors_valid['S2_SEC'].min(),\n",
        "    'S3_best_field': sectors_valid['S3_SEC'].min(),\n",
        "}\n",
        "\n",
        "car_delta = car_sector_stats[['NUMBER','S1_avg','S2_avg','S3_avg']].copy()\n",
        "car_delta['S1_loss_vs_field'] = car_delta['S1_avg'] - field_best['S1_best_field']\n",
        "car_delta['S2_loss_vs_field'] = car_delta['S2_avg'] - field_best['S2_best_field']\n",
        "car_delta['S3_loss_vs_field'] = car_delta['S3_avg'] - field_best['S3_best_field']\n",
        "\n",
        "# Identify worst sector per car\n",
        "def worst_sector_row(r):\n",
        "    vals = {\n",
        "        'S1': r['S1_loss_vs_field'],\n",
        "        'S2': r['S2_loss_vs_field'],\n",
        "        'S3': r['S3_loss_vs_field']\n",
        "    }\n",
        "    worst = max(vals, key=vals.get)\n",
        "    return pd.Series({'worst_sector': worst, 'worst_loss': vals[worst]})\n",
        "\n",
        "ws = car_delta.apply(worst_sector_row, axis=1)\n",
        "car_delta = pd.concat([car_delta[['NUMBER']], ws], axis=1)\n",
        "\n",
        "print(\"Cars with biggest single-sector weaknesses (top 10):\")\n",
        "for _, row in car_delta.sort_values('worst_loss', ascending=False).head(10).iterrows():\n",
        "    print(f\"Car #{int(row['NUMBER']):2d}: worst {row['worst_sector']} (+{row['worst_loss']:.3f}s vs field best)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Biggest single-lap total sector losses (top 10) - potential key moments:\n",
            "Car #31 Lap  6: total +593.486s (S1 +590.722, S2 +1.536, S3 +1.228)\n",
            "Car #15 Lap  2: total +230.737s (S1 +226.938, S2 +2.452, S3 +1.347)\n",
            "Car #31 Lap  4: total +98.889s (S1 +91.548, S2 +3.080, S3 +4.261)\n",
            "Car #51 Lap 14: total +89.567s (S1 +71.430, S2 +6.270, S3 +11.867)\n",
            "Car #51 Lap 13: total +79.861s (S1 +15.984, S2 +33.811, S3 +30.066)\n",
            "Car # 7 Lap 13: total +75.877s (S1 +17.621, S2 +32.462, S3 +25.794)\n",
            "Car #46 Lap 13: total +75.169s (S1 +17.242, S2 +32.620, S3 +25.307)\n",
            "Car #16 Lap 13: total +74.664s (S1 +17.163, S2 +32.363, S3 +25.138)\n",
            "Car #13 Lap 13: total +74.610s (S1 +17.210, S2 +32.296, S3 +25.104)\n",
            "Car #55 Lap 13: total +74.336s (S1 +17.345, S2 +32.491, S3 +24.500)\n"
          ]
        }
      ],
      "source": [
        "# Step 4.5: Per-lap sector loss vs field-best (for storyline moments)\n",
        "# Compute, per lap, how much each car lost vs field-best sector on that lap\n",
        "\n",
        "# Build per-lap field best per sector\n",
        "lap_field_best = sectors_valid.groupby('LAP_NUMBER').agg(\n",
        "    S1_best=('S1_SEC','min'), S2_best=('S2_SEC','min'), S3_best=('S3_SEC','min')\n",
        ").reset_index()\n",
        "\n",
        "lap_sectors = sectors_valid[['NUMBER','LAP_NUMBER','S1_SEC','S2_SEC','S3_SEC']].merge(\n",
        "    lap_field_best, on='LAP_NUMBER', how='left'\n",
        ")\n",
        "\n",
        "for s in ['S1','S2','S3']:\n",
        "    lap_sectors[f'{s}_loss'] = lap_sectors[f'{s}_SEC'] - lap_sectors[f'{s}_best']\n",
        "\n",
        "lap_sectors['sector_loss_total'] = lap_sectors[['S1_loss','S2_loss','S3_loss']].clip(lower=0).sum(axis=1)\n",
        "\n",
        "print(\"Biggest single-lap total sector losses (top 10) - potential key moments:\")\n",
        "for _, row in lap_sectors.sort_values('sector_loss_total', ascending=False).head(10).iterrows():\n",
        "    print(f\"Car #{int(row['NUMBER']):2d} Lap {int(row['LAP_NUMBER']):2d}: total +{row['sector_loss_total']:.3f}s (S1 +{row['S1_loss']:.3f}, S2 +{row['S2_loss']:.3f}, S3 +{row['S3_loss']:.3f})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Phase 4 Progress:**\n",
        "- Sector seconds ensured\n",
        "- Sector averages/bests computed per car\n",
        "- Theoretical best lap (ideal) vs actual best computed\n",
        "- Biggest single-sector weaknesses identified per car\n",
        "- Per-lap sector losses summarized (key moments)\n",
        "\n",
        "Next: Weather impact analysis (Phase 5) or dive into specific driver comparisons.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Phase 5: Weather Impact Analysis\n",
        "\n",
        "Link laps to nearest weather sample and analyze how conditions affect lap and sector times.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Prepared:\n",
            "   Laps with LAP_DATETIME: 486\n",
            "   Weather records: 44\n"
          ]
        }
      ],
      "source": [
        "# Step 5.1: Prepare lap timestamps and weather timestamps for nearest-join\n",
        "# Parse weather datetime (already prepared earlier in weather_data or build now)\n",
        "if 'TIME_DATETIME' not in weather_data.columns:\n",
        "    weather_data['TIME_DATETIME'] = pd.to_datetime(weather_data['TIME_UTC_STR'])\n",
        "\n",
        "# Parse HOUR in lap_analysis to datetime on the same date as weather (use min weather date)\n",
        "base_date = weather_data['TIME_DATETIME'].min().normalize()\n",
        "\n",
        "# Some rows have HOUR like '16:21:41.999'. Build datetime from base_date + time\n",
        "# Guard against invalid/missing HOUR values\n",
        "\n",
        "def parse_hour_to_dt(hour_str):\n",
        "    if pd.isna(hour_str) or str(hour_str).strip() == '':\n",
        "        return pd.NaT\n",
        "    s = str(hour_str).strip()\n",
        "    try:\n",
        "        # Handle 'HH:MM:SS' or 'HH:MM:SS.mmm'\n",
        "        return pd.to_datetime(str(base_date.date()) + ' ' + s)\n",
        "    except Exception:\n",
        "        return pd.NaT\n",
        "\n",
        "lap_with_time = lap_analysis.copy()\n",
        "if 'HOUR' in lap_with_time.columns:\n",
        "    lap_with_time['LAP_DATETIME'] = lap_with_time['HOUR'].apply(parse_hour_to_dt)\n",
        "else:\n",
        "    # Fallback: build synthetic time using per-car cumulative seconds if available\n",
        "    if 'LAP_TIME_SECONDS' not in lap_with_time.columns:\n",
        "        lap_with_time['LAP_TIME_SECONDS'] = lap_with_time['LAP_TIME'].apply(to_seconds_any)\n",
        "    lap_with_time = lap_with_time.sort_values(['NUMBER','LAP_NUMBER'])\n",
        "    lap_with_time['CUM_SEC'] = lap_with_time.groupby('NUMBER')['LAP_TIME_SECONDS'].cumsum()\n",
        "    lap_with_time['LAP_DATETIME'] = base_date + pd.to_timedelta(lap_with_time['CUM_SEC'], unit='s')\n",
        "\n",
        "# Drop rows without timestamps\n",
        "lap_with_time = lap_with_time.dropna(subset=['LAP_DATETIME']).copy()\n",
        "\n",
        "print(\"âœ“ Prepared:\")\n",
        "print(f\"   Laps with LAP_DATETIME: {len(lap_with_time)}\")\n",
        "print(f\"   Weather records: {len(weather_data)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Joined laps with weather (nearest):\n",
            "   Joined rows: 0\n",
            "Empty DataFrame\n",
            "Columns: [NUMBER, LAP_NUMBER, LAP_TIME, LAP_DATETIME, AIR_TEMP, TRACK_TEMP, HUMIDITY, WIND_SPEED, RAIN]\n",
            "Index: []\n"
          ]
        }
      ],
      "source": [
        "# Step 5.2: Nearest-join laps to weather conditions\n",
        "# Sort both for merge_asof\n",
        "laps_for_join = lap_with_time.sort_values('LAP_DATETIME')\n",
        "weather_for_join = weather_data[['TIME_DATETIME','AIR_TEMP','TRACK_TEMP','HUMIDITY','PRESSURE','WIND_SPEED','WIND_DIRECTION','RAIN']].sort_values('TIME_DATETIME')\n",
        "\n",
        "# Perform nearest join (backward then forward if needed)\n",
        "joined = pd.merge_asof(\n",
        "    laps_for_join,\n",
        "    weather_for_join,\n",
        "    left_on='LAP_DATETIME', right_on='TIME_DATETIME',\n",
        "    direction='nearest', tolerance=pd.Timedelta('10m')\n",
        ")\n",
        "\n",
        "# Keep only rows with matched weather\n",
        "joined = joined.dropna(subset=['AIR_TEMP']).copy()\n",
        "\n",
        "print(\"âœ“ Joined laps with weather (nearest):\")\n",
        "print(f\"   Joined rows: {len(joined)}\")\n",
        "print(joined[['NUMBER','LAP_NUMBER','LAP_TIME','LAP_DATETIME','AIR_TEMP','TRACK_TEMP','HUMIDITY','WIND_SPEED','RAIN']].head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Correlation (Pearson) between weather and performance metrics:\n",
            "\n",
            "LAP_TIME_SECONDS correlations:\n",
            "   AIR_TEMP: nan\n",
            "   TRACK_TEMP: nan\n",
            "   HUMIDITY: nan\n",
            "   WIND_SPEED: nan\n",
            "   PRESSURE: nan\n",
            "\n",
            "S1_SEC correlations:\n",
            "   AIR_TEMP: nan\n",
            "   TRACK_TEMP: nan\n",
            "   HUMIDITY: nan\n",
            "   WIND_SPEED: nan\n",
            "   PRESSURE: nan\n",
            "\n",
            "S2_SEC correlations:\n",
            "   AIR_TEMP: nan\n",
            "   TRACK_TEMP: nan\n",
            "   HUMIDITY: nan\n",
            "   WIND_SPEED: nan\n",
            "   PRESSURE: nan\n",
            "\n",
            "S3_SEC correlations:\n",
            "   AIR_TEMP: nan\n",
            "   TRACK_TEMP: nan\n",
            "   HUMIDITY: nan\n",
            "   WIND_SPEED: nan\n",
            "   PRESSURE: nan\n"
          ]
        }
      ],
      "source": [
        "# Step 5.3: Correlation analysis between weather and lap performance\n",
        "# Ensure numeric LAP_TIME_SECONDS and sector seconds\n",
        "if 'LAP_TIME_SECONDS' not in joined.columns:\n",
        "    joined['LAP_TIME_SECONDS'] = joined['LAP_TIME'].apply(to_seconds_any)\n",
        "for s in ['S1_SEC','S2_SEC','S3_SEC']:\n",
        "    if s not in joined.columns and s.replace('_SEC','') in joined.columns:\n",
        "        joined[s] = joined[s.replace('_SEC','')].apply(to_seconds_any)\n",
        "\n",
        "metrics = ['LAP_TIME_SECONDS','S1_SEC','S2_SEC','S3_SEC']\n",
        "weather_cols = ['AIR_TEMP','TRACK_TEMP','HUMIDITY','WIND_SPEED','PRESSURE']\n",
        "\n",
        "corrs = {}\n",
        "for m in metrics:\n",
        "    if m in joined.columns:\n",
        "        corrs[m] = {w: joined[[m,w]].dropna().corr().iloc[0,1] for w in weather_cols if w in joined.columns}\n",
        "\n",
        "print(\"Correlation (Pearson) between weather and performance metrics:\")\n",
        "for m, d in corrs.items():\n",
        "    print(f\"\\n{m} correlations:\")\n",
        "    for w, c in d.items():\n",
        "        print(f\"   {w}: {c:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lap time vs Track Temp (quartiles):\n",
            "Empty DataFrame\n",
            "Columns: [TRACK_TEMP_BUCKET, count, mean, median, std]\n",
            "Index: []\n"
          ]
        }
      ],
      "source": [
        "# Step 5.4: Track temperature buckets vs lap times (simple effect size)\n",
        "joined['TRACK_TEMP_BUCKET'] = pd.qcut(joined['TRACK_TEMP'], q=4, duplicates='drop')\n",
        "summary = joined.groupby('TRACK_TEMP_BUCKET')['LAP_TIME_SECONDS'].agg(['count','mean','median','std']).reset_index()\n",
        "print(\"Lap time vs Track Temp (quartiles):\")\n",
        "print(summary)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Phase 5 Progress:**\n",
        "- Laps linked to nearest weather samples\n",
        "- Correlations computed (air/track temp, humidity, wind vs lap/sector times)\n",
        "- Track temp buckets summarized vs lap time\n",
        "\n",
        "Next: Flag impact analysis (FCY/GF/FF) and restart performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ðŸ“‹ Race Story Dashboard - Missing Components Checklist\n",
        "\n",
        "### âœ… **What We Have:**\n",
        "1. âœ… Basic race overview (winners, fastest laps, gaps)\n",
        "2. âœ… Position over time analysis (gains/losses, volatility)\n",
        "3. âœ… Sector performance (strengths/weaknesses, ideal vs actual)\n",
        "4. âœ… Weather impact (correlations, temperature effects)\n",
        "5. âœ… Data quality (duplicate handling)\n",
        "\n",
        "### âŒ **What's Still Needed:**\n",
        "\n",
        "#### **Phase 6: Flag Impact Analysis** (Critical for race story!)\n",
        "- FCY (Full Course Yellow) periods and impact\n",
        "- GF (Green Flag) vs FCY performance comparison\n",
        "- FF (Finish Flag) - final lap analysis\n",
        "- Restart performance after flags\n",
        "- Who gained/lost positions during flag periods\n",
        "\n",
        "#### **Phase 7: Lap Consistency & Degradation**\n",
        "- Lap time variance per driver (consistency score)\n",
        "- Tire degradation patterns (performance drop over race)\n",
        "- Best vs worst lap sequences\n",
        "- Performance trends (improving vs declining)\n",
        "\n",
        "#### **Phase 8: Strategic Moments & Key Events**\n",
        "- Pit stop windows (if PIT_TIME data available)\n",
        "- Critical decision points\n",
        "- Biggest single-lap position changes (already have, but need narrative)\n",
        "- Race timeline with key moments\n",
        "\n",
        "#### **Phase 9: Narrative Elements**\n",
        "- Race \"Acts\" (Opening/Middle/Closing phases)\n",
        "- Turning points identification\n",
        "- Protagonist journeys (top 5 drivers' stories)\n",
        "- Dramatic moments summary\n",
        "\n",
        "#### **Phase 10: Dashboard-Ready Data Structures**\n",
        "- Summary statistics for dashboard cards\n",
        "- Pre-computed visualization data\n",
        "- Driver comparison matrices\n",
        "- Key moments timeline (structured)\n",
        "- Race story text snippets\n",
        "\n",
        "#### **Phase 11: Driver Story Arcs**\n",
        "- Individual driver narratives (start â†’ finish journey)\n",
        "- Key moments per driver\n",
        "- Story themes (comeback, domination, consistency, struggle)\n",
        "\n",
        "---\n",
        "\n",
        "**Next Steps:** Let's start with **Phase 6: Flag Impact Analysis** - it's crucial for understanding race dynamics!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 5.1a: Diagnostic - Check why weather join is failing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "DIAGNOSTIC: Weather Join Issues\n",
            "================================================================================\n",
            "\n",
            "1. Checking HOUR column in lap_analysis:\n",
            "   âœ“ HOUR column exists\n",
            "   - Non-null values: 486 / 486\n",
            "   - Sample values:\n",
            "0    15:58:26.323\n",
            "1    16:01:15.059\n",
            "2    16:03:51.955\n",
            "3    16:06:25.608\n",
            "4    16:08:59.549\n",
            "5    16:11:32.141\n",
            "6    16:14:04.709\n",
            "7    16:16:37.618\n",
            "8    16:19:09.688\n",
            "9    16:21:41.999\n",
            "Name: HOUR, dtype: object\n",
            "   - Unique non-null values: 486\n",
            "\n",
            "2. Checking weather_data:\n",
            "   - Weather records: 44\n",
            "   âœ“ TIME_DATETIME exists\n",
            "   - Non-null: 44\n",
            "   - Range: 2025-04-26 20:55:36 to 2025-04-26 21:40:31\n",
            "\n",
            "3. Checking lap_with_time (from Step 5.1):\n",
            "   âœ“ lap_with_time exists\n",
            "   - Records: 486\n",
            "   âœ“ LAP_DATETIME exists\n",
            "   - Non-null: 486\n",
            "   - Range: 2025-04-26 15:58:21.443000 to 2025-04-26 16:41:20.890000\n",
            "\n",
            "4. Checking joined dataframe (from Step 5.2):\n",
            "   âœ“ joined exists\n",
            "   - Records: 0\n",
            "   âš ï¸  joined is EMPTY - merge_asof failed!\n"
          ]
        }
      ],
      "source": [
        "# Diagnostic: Check why weather join might be failing\n",
        "print(\"=\" * 80)\n",
        "print(\"DIAGNOSTIC: Weather Join Issues\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Check if HOUR column exists and what it contains\n",
        "print(\"\\n1. Checking HOUR column in lap_analysis:\")\n",
        "if 'HOUR' in lap_analysis.columns:\n",
        "    print(f\"   âœ“ HOUR column exists\")\n",
        "    print(f\"   - Non-null values: {lap_analysis['HOUR'].notna().sum()} / {len(lap_analysis)}\")\n",
        "    print(f\"   - Sample values:\")\n",
        "    print(lap_analysis['HOUR'].head(10))\n",
        "    print(f\"   - Unique non-null values: {lap_analysis['HOUR'].notna().sum()}\")\n",
        "else:\n",
        "    print(f\"   âœ— HOUR column NOT found in lap_analysis\")\n",
        "    print(f\"   Available columns with 'TIME' or 'HOUR': {[c for c in lap_analysis.columns if 'TIME' in c.upper() or 'HOUR' in c.upper()]}\")\n",
        "\n",
        "# Check weather data\n",
        "print(\"\\n2. Checking weather_data:\")\n",
        "print(f\"   - Weather records: {len(weather_data)}\")\n",
        "if 'TIME_DATETIME' in weather_data.columns:\n",
        "    print(f\"   âœ“ TIME_DATETIME exists\")\n",
        "    print(f\"   - Non-null: {weather_data['TIME_DATETIME'].notna().sum()}\")\n",
        "    print(f\"   - Range: {weather_data['TIME_DATETIME'].min()} to {weather_data['TIME_DATETIME'].max()}\")\n",
        "else:\n",
        "    print(f\"   âœ— TIME_DATETIME not found\")\n",
        "    print(f\"   Available columns: {list(weather_data.columns)}\")\n",
        "\n",
        "# Check if lap_with_time was created successfully\n",
        "print(\"\\n3. Checking lap_with_time (from Step 5.1):\")\n",
        "if 'lap_with_time' in locals() or 'lap_with_time' in globals():\n",
        "    print(f\"   âœ“ lap_with_time exists\")\n",
        "    print(f\"   - Records: {len(lap_with_time)}\")\n",
        "    if 'LAP_DATETIME' in lap_with_time.columns:\n",
        "        print(f\"   âœ“ LAP_DATETIME exists\")\n",
        "        print(f\"   - Non-null: {lap_with_time['LAP_DATETIME'].notna().sum()}\")\n",
        "        if lap_with_time['LAP_DATETIME'].notna().sum() > 0:\n",
        "            print(f\"   - Range: {lap_with_time['LAP_DATETIME'].min()} to {lap_with_time['LAP_DATETIME'].max()}\")\n",
        "    else:\n",
        "        print(f\"   âœ— LAP_DATETIME not found\")\n",
        "else:\n",
        "    print(f\"   âœ— lap_with_time not created - Step 5.1 may have failed\")\n",
        "\n",
        "# Check joined dataframe\n",
        "print(\"\\n4. Checking joined dataframe (from Step 5.2):\")\n",
        "if 'joined' in locals() or 'joined' in globals():\n",
        "    print(f\"   âœ“ joined exists\")\n",
        "    print(f\"   - Records: {len(joined)}\")\n",
        "    if len(joined) > 0:\n",
        "        print(f\"   - Weather columns with data:\")\n",
        "        for col in ['AIR_TEMP','TRACK_TEMP','HUMIDITY','WIND_SPEED']:\n",
        "            if col in joined.columns:\n",
        "                non_null = joined[col].notna().sum()\n",
        "                print(f\"     {col}: {non_null} non-null / {len(joined)} total\")\n",
        "    else:\n",
        "        print(f\"   âš ï¸  joined is EMPTY - merge_asof failed!\")\n",
        "else:\n",
        "    print(f\"   âœ— joined not created - Step 5.2 may have failed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "FIXING STEP 5.1: Improved timestamp parsing\n",
            "================================================================================\n",
            "\n",
            "âœ“ Using HOUR column (486 non-null values)\n",
            "   Successfully parsed: 486 / 486\n",
            "\n",
            "âœ“ Final lap_with_time: 486 records with valid LAP_DATETIME\n",
            "   Time range: 2025-04-26 15:58:21.443000 to 2025-04-26 16:41:20.890000\n"
          ]
        }
      ],
      "source": [
        "# Fix Step 5.1: Better HOUR parsing and fallback strategy\n",
        "print(\"=\" * 80)\n",
        "print(\"FIXING STEP 5.1: Improved timestamp parsing\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Ensure weather datetime exists\n",
        "if 'TIME_DATETIME' not in weather_data.columns:\n",
        "    if 'TIME_UTC_STR' in weather_data.columns:\n",
        "        weather_data['TIME_DATETIME'] = pd.to_datetime(weather_data['TIME_UTC_STR'], errors='coerce')\n",
        "    else:\n",
        "        print(\"âš ï¸  No TIME_UTC_STR in weather_data, checking other time columns...\")\n",
        "        print(f\"   Available columns: {list(weather_data.columns)}\")\n",
        "\n",
        "base_date = weather_data['TIME_DATETIME'].min().normalize() if 'TIME_DATETIME' in weather_data.columns else pd.Timestamp.now().normalize()\n",
        "\n",
        "# Rebuild lap_with_time with better error handling\n",
        "lap_with_time = lap_analysis.copy()\n",
        "\n",
        "# Try HOUR column first\n",
        "if 'HOUR' in lap_with_time.columns:\n",
        "    print(f\"\\nâœ“ Using HOUR column ({lap_with_time['HOUR'].notna().sum()} non-null values)\")\n",
        "    \n",
        "    def parse_hour_to_dt(hour_str):\n",
        "        if pd.isna(hour_str) or str(hour_str).strip() == '':\n",
        "            return pd.NaT\n",
        "        try:\n",
        "            s = str(hour_str).strip()\n",
        "            # Handle 'HH:MM:SS' or 'HH:MM:SS.mmm'\n",
        "            time_part = s.split()[0] if ' ' in s else s  # Take first part if space-separated\n",
        "            return pd.to_datetime(str(base_date.date()) + ' ' + time_part, errors='coerce')\n",
        "        except Exception as e:\n",
        "            return pd.NaT\n",
        "    \n",
        "    lap_with_time['LAP_DATETIME'] = lap_with_time['HOUR'].apply(parse_hour_to_dt)\n",
        "    successful_parses = lap_with_time['LAP_DATETIME'].notna().sum()\n",
        "    print(f\"   Successfully parsed: {successful_parses} / {len(lap_with_time)}\")\n",
        "    \n",
        "    # If HOUR parsing failed for many, use ELAPSED as fallback\n",
        "    if successful_parses < len(lap_with_time) * 0.5:  # Less than 50% success\n",
        "        print(f\"\\nâš ï¸  HOUR parsing had low success rate, using ELAPSED as fallback...\")\n",
        "        if 'ELAPSED' in lap_with_time.columns:\n",
        "            # Parse ELAPSED time (format like \"3:46.084\" or \"29:34.612\")\n",
        "            def parse_elapsed(elapsed_str):\n",
        "                if pd.isna(elapsed_str):\n",
        "                    return pd.NaT\n",
        "                try:\n",
        "                    s = str(elapsed_str).strip()\n",
        "                    if ':' in s:\n",
        "                        parts = s.split(':')\n",
        "                        if len(parts) == 2:\n",
        "                            minutes = int(parts[0])\n",
        "                            seconds = float(parts[1])\n",
        "                            total_seconds = minutes * 60 + seconds\n",
        "                            return base_date + pd.Timedelta(seconds=total_seconds)\n",
        "                except:\n",
        "                    pass\n",
        "                return pd.NaT\n",
        "            \n",
        "            # Only fill NaT values from ELAPSED\n",
        "            mask = lap_with_time['LAP_DATETIME'].isna()\n",
        "            lap_with_time.loc[mask, 'LAP_DATETIME'] = lap_with_time.loc[mask, 'ELAPSED'].apply(parse_elapsed)\n",
        "            print(f\"   After ELAPSED fallback: {lap_with_time['LAP_DATETIME'].notna().sum()} / {len(lap_with_time)}\")\n",
        "else:\n",
        "    print(f\"\\nâš ï¸  No HOUR column, using ELAPSED to build timestamps\")\n",
        "    if 'ELAPSED' in lap_with_time.columns:\n",
        "        def parse_elapsed(elapsed_str):\n",
        "            if pd.isna(elapsed_str):\n",
        "                return pd.NaT\n",
        "            try:\n",
        "                s = str(elapsed_str).strip()\n",
        "                if ':' in s:\n",
        "                    parts = s.split(':')\n",
        "                    if len(parts) == 2:\n",
        "                        minutes = int(parts[0])\n",
        "                        seconds = float(parts[1])\n",
        "                        total_seconds = minutes * 60 + seconds\n",
        "                        return base_date + pd.Timedelta(seconds=total_seconds)\n",
        "            except:\n",
        "                pass\n",
        "            return pd.NaT\n",
        "        \n",
        "        lap_with_time['LAP_DATETIME'] = lap_with_time['ELAPSED'].apply(parse_elapsed)\n",
        "        print(f\"   Parsed from ELAPSED: {lap_with_time['LAP_DATETIME'].notna().sum()} / {len(lap_with_time)}\")\n",
        "\n",
        "# Drop rows without timestamps\n",
        "lap_with_time = lap_with_time.dropna(subset=['LAP_DATETIME']).copy()\n",
        "\n",
        "print(f\"\\nâœ“ Final lap_with_time: {len(lap_with_time)} records with valid LAP_DATETIME\")\n",
        "if len(lap_with_time) > 0:\n",
        "    print(f\"   Time range: {lap_with_time['LAP_DATETIME'].min()} to {lap_with_time['LAP_DATETIME'].max()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "FIXING STEP 5.2: Weather Join with Diagnostics\n",
            "================================================================================\n",
            "\n",
            "ðŸ“… Time Range Check:\n",
            "   Laps: 2025-04-26 15:58:21.443000 to 2025-04-26 16:41:20.890000\n",
            "   Weather: 2025-04-26 20:55:36 to 2025-04-26 21:40:31\n",
            "   Overlap: False\n",
            "   âš ï¸  WARNING: No time overlap! This will cause join to fail.\n",
            "   Trying to adjust base_date...\n",
            "   New base_date: 2025-04-26 00:00:00\n",
            "\n",
            "ðŸ“Š Join Setup:\n",
            "   Laps to join: 486\n",
            "   Weather records: 44\n",
            "\n",
            "âœ“ Join completed:\n",
            "   Total joined rows: 486\n",
            "   Rows with weather data: 0 / 486 (0.0%)\n",
            "\n",
            "   âš ï¸  WARNING: No weather data matched! Check time ranges.\n",
            "   Sample lap times: [Timestamp('2025-04-26 15:58:21.443000'), Timestamp('2025-04-26 15:58:21.481000'), Timestamp('2025-04-26 15:58:21.819000')]\n",
            "   Sample weather times: [Timestamp('2025-04-26 20:55:36'), Timestamp('2025-04-26 20:56:38'), Timestamp('2025-04-26 20:57:41')]\n"
          ]
        }
      ],
      "source": [
        "# Fix Step 5.2: Re-run weather join with better error handling\n",
        "print(\"=\" * 80)\n",
        "print(\"FIXING STEP 5.2: Weather Join with Diagnostics\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Ensure weather data is ready\n",
        "if 'TIME_DATETIME' not in weather_data.columns or weather_data['TIME_DATETIME'].isna().all():\n",
        "    print(\"âš ï¸  Weather TIME_DATETIME not ready, attempting to create...\")\n",
        "    if 'TIME_UTC_STR' in weather_data.columns:\n",
        "        weather_data['TIME_DATETIME'] = pd.to_datetime(weather_data['TIME_UTC_STR'], errors='coerce')\n",
        "    else:\n",
        "        print(\"   âœ— Cannot create TIME_DATETIME - no source column found\")\n",
        "\n",
        "# Check time overlap\n",
        "if len(lap_with_time) > 0 and 'TIME_DATETIME' in weather_data.columns:\n",
        "    lap_min = lap_with_time['LAP_DATETIME'].min()\n",
        "    lap_max = lap_with_time['LAP_DATETIME'].max()\n",
        "    weather_min = weather_data['TIME_DATETIME'].min()\n",
        "    weather_max = weather_data['TIME_DATETIME'].max()\n",
        "    \n",
        "    print(f\"\\nðŸ“… Time Range Check:\")\n",
        "    print(f\"   Laps: {lap_min} to {lap_max}\")\n",
        "    print(f\"   Weather: {weather_min} to {weather_max}\")\n",
        "    print(f\"   Overlap: {lap_min <= weather_max and lap_max >= weather_min}\")\n",
        "    \n",
        "    if not (lap_min <= weather_max and lap_max >= weather_min):\n",
        "        print(\"   âš ï¸  WARNING: No time overlap! This will cause join to fail.\")\n",
        "        print(\"   Trying to adjust base_date...\")\n",
        "        # Try using weather min as base\n",
        "        if len(weather_data) > 0:\n",
        "            base_date = weather_data['TIME_DATETIME'].min().normalize()\n",
        "            print(f\"   New base_date: {base_date}\")\n",
        "\n",
        "# Perform join\n",
        "laps_for_join = lap_with_time.sort_values('LAP_DATETIME').copy()\n",
        "weather_for_join = weather_data[['TIME_DATETIME','AIR_TEMP','TRACK_TEMP','HUMIDITY','PRESSURE','WIND_SPEED','WIND_DIRECTION','RAIN']].sort_values('TIME_DATETIME').copy()\n",
        "\n",
        "# Remove NaNs from weather\n",
        "weather_for_join = weather_for_join.dropna(subset=['TIME_DATETIME']).copy()\n",
        "\n",
        "print(f\"\\nðŸ“Š Join Setup:\")\n",
        "print(f\"   Laps to join: {len(laps_for_join)}\")\n",
        "print(f\"   Weather records: {len(weather_for_join)}\")\n",
        "\n",
        "if len(laps_for_join) > 0 and len(weather_for_join) > 0:\n",
        "    # Try merge_asof with larger tolerance\n",
        "    joined = pd.merge_asof(\n",
        "        laps_for_join,\n",
        "        weather_for_join,\n",
        "        left_on='LAP_DATETIME', right_on='TIME_DATETIME',\n",
        "        direction='nearest',\n",
        "        tolerance=pd.Timedelta('30m')  # Increased from 10m to 30m\n",
        "    )\n",
        "    \n",
        "    # Check results\n",
        "    print(f\"\\nâœ“ Join completed:\")\n",
        "    print(f\"   Total joined rows: {len(joined)}\")\n",
        "    if 'AIR_TEMP' in joined.columns:\n",
        "        matched = joined['AIR_TEMP'].notna().sum()\n",
        "        print(f\"   Rows with weather data: {matched} / {len(joined)} ({matched/len(joined)*100:.1f}%)\")\n",
        "        \n",
        "        if matched == 0:\n",
        "            print(\"\\n   âš ï¸  WARNING: No weather data matched! Check time ranges.\")\n",
        "            print(f\"   Sample lap times: {laps_for_join['LAP_DATETIME'].head(3).tolist()}\")\n",
        "            print(f\"   Sample weather times: {weather_for_join['TIME_DATETIME'].head(3).tolist()}\")\n",
        "    else:\n",
        "        print(\"   âœ— AIR_TEMP column not found in joined dataframe\")\n",
        "else:\n",
        "    print(\"   âœ— Cannot perform join - missing data\")\n",
        "    joined = pd.DataFrame()  # Empty dataframe\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 5.2b: Fix Timezone Issue - Convert Lap Times to UTC\n",
        "The diagnostic revealed a timezone mismatch: lap times are in local time, weather is in UTC.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "FIXING TIMEZONE: Converting Lap Times to UTC\n",
            "================================================================================\n",
            "\n",
            "ðŸ“… Time Difference Analysis:\n",
            "   Lap start (local): 2025-04-26 15:58:21.443000\n",
            "   Weather start (UTC): 2025-04-26 20:55:36\n",
            "   Difference: 5.0 hours\n",
            "\n",
            "âœ“ Detected timezone offset: UTC-5 (US Central Time)\n",
            "   Converting lap times to UTC by adding 5 hours...\n",
            "\n",
            "âœ“ Conversion complete:\n",
            "   Lap times (UTC): 2025-04-26 20:58:21.443000 to 2025-04-26 21:41:20.890000\n",
            "   Weather times (UTC): 2025-04-26 20:55:36 to 2025-04-26 21:40:31\n",
            "\n",
            "   Overlap check: True\n",
            "   âœ“ Times now overlap! Ready for join.\n"
          ]
        }
      ],
      "source": [
        "# Fix timezone: Convert lap times from local (US Central) to UTC\n",
        "# COTA is in Texas, which is UTC-5 (CDT) or UTC-6 (CST)\n",
        "# Based on the time difference, we need to add 5-6 hours to lap times\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"FIXING TIMEZONE: Converting Lap Times to UTC\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Check the time difference between lap and weather times\n",
        "if len(lap_with_time) > 0 and len(weather_data) > 0:\n",
        "    lap_start = lap_with_time['LAP_DATETIME'].min()\n",
        "    weather_start = weather_data['TIME_DATETIME'].min()\n",
        "    \n",
        "    time_diff = (weather_start - lap_start).total_seconds() / 3600  # hours\n",
        "    print(f\"\\nðŸ“… Time Difference Analysis:\")\n",
        "    print(f\"   Lap start (local): {lap_start}\")\n",
        "    print(f\"   Weather start (UTC): {weather_start}\")\n",
        "    print(f\"   Difference: {time_diff:.1f} hours\")\n",
        "    \n",
        "    # Determine timezone offset (should be around 5-6 hours for US Central)\n",
        "    if 4.5 <= time_diff <= 6.5:\n",
        "        tz_offset_hours = int(round(time_diff))\n",
        "        print(f\"\\nâœ“ Detected timezone offset: UTC-{tz_offset_hours} (US Central Time)\")\n",
        "        print(f\"   Converting lap times to UTC by adding {tz_offset_hours} hours...\")\n",
        "        \n",
        "        # Convert to UTC\n",
        "        lap_with_time['LAP_DATETIME_UTC'] = lap_with_time['LAP_DATETIME'] + pd.Timedelta(hours=tz_offset_hours)\n",
        "        \n",
        "        print(f\"\\nâœ“ Conversion complete:\")\n",
        "        print(f\"   Lap times (UTC): {lap_with_time['LAP_DATETIME_UTC'].min()} to {lap_with_time['LAP_DATETIME_UTC'].max()}\")\n",
        "        print(f\"   Weather times (UTC): {weather_data['TIME_DATETIME'].min()} to {weather_data['TIME_DATETIME'].max()}\")\n",
        "        \n",
        "        # Check overlap\n",
        "        lap_utc_min = lap_with_time['LAP_DATETIME_UTC'].min()\n",
        "        lap_utc_max = lap_with_time['LAP_DATETIME_UTC'].max()\n",
        "        weather_min = weather_data['TIME_DATETIME'].min()\n",
        "        weather_max = weather_data['TIME_DATETIME'].max()\n",
        "        \n",
        "        overlap = lap_utc_min <= weather_max and lap_utc_max >= weather_min\n",
        "        print(f\"\\n   Overlap check: {overlap}\")\n",
        "        if overlap:\n",
        "            print(f\"   âœ“ Times now overlap! Ready for join.\")\n",
        "        else:\n",
        "            print(f\"   âš ï¸  Still no overlap - may need manual adjustment\")\n",
        "    else:\n",
        "        print(f\"\\nâš ï¸  Unexpected time difference ({time_diff:.1f} hours)\")\n",
        "        print(f\"   Trying standard UTC-5 (CDT) conversion...\")\n",
        "        lap_with_time['LAP_DATETIME_UTC'] = lap_with_time['LAP_DATETIME'] + pd.Timedelta(hours=5)\n",
        "        print(f\"   Converted lap times: {lap_with_time['LAP_DATETIME_UTC'].min()} to {lap_with_time['LAP_DATETIME_UTC'].max()}\")\n",
        "else:\n",
        "    print(\"âš ï¸  Cannot determine timezone - missing data\")\n",
        "    lap_with_time['LAP_DATETIME_UTC'] = lap_with_time['LAP_DATETIME']  # Fallback\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "RE-RUNNING WEATHER JOIN WITH UTC TIMES\n",
            "================================================================================\n",
            "\n",
            "ðŸ“Š Join Setup (UTC):\n",
            "   Laps: 486\n",
            "   Weather: 44\n",
            "\n",
            "âœ“ Join completed:\n",
            "   Total rows: 486\n",
            "   Rows with weather data: 486 / 486 (100.0%)\n",
            "\n",
            "   âœ“ SUCCESS! Weather data matched to 486 lap records\n",
            "\n",
            "   Sample joined data:\n",
            "   NUMBER  LAP_NUMBER  LAP_TIME        LAP_DATETIME_UTC  AIR_TEMP  TRACK_TEMP  \\\n",
            "0      46           1  3:41.204 2025-04-26 20:58:21.443     28.55        42.6   \n",
            "1       7           1  3:41.242 2025-04-26 20:58:21.481     28.55        42.6   \n",
            "2      13           1  3:41.580 2025-04-26 20:58:21.819     28.55        42.6   \n",
            "3      16           1  3:42.042 2025-04-26 20:58:22.281     28.55        42.6   \n",
            "4      89           1  3:42.093 2025-04-26 20:58:22.332     28.55        42.6   \n",
            "5      72           1  3:42.395 2025-04-26 20:58:22.634     28.55        42.6   \n",
            "6      55           1  3:42.396 2025-04-26 20:58:22.635     28.55        42.6   \n",
            "7      41           1  3:42.681 2025-04-26 20:58:22.920     28.55        42.6   \n",
            "8      15           1  3:42.783 2025-04-26 20:58:23.022     28.55        42.6   \n",
            "9      21           1  3:42.783 2025-04-26 20:58:23.022     28.55        42.6   \n",
            "\n",
            "   HUMIDITY  \n",
            "0     62.01  \n",
            "1     62.01  \n",
            "2     62.01  \n",
            "3     62.01  \n",
            "4     62.01  \n",
            "5     62.01  \n",
            "6     62.01  \n",
            "7     62.01  \n",
            "8     62.01  \n",
            "9     62.01  \n"
          ]
        }
      ],
      "source": [
        "# Re-run weather join using UTC times\n",
        "print(\"=\" * 80)\n",
        "print(\"RE-RUNNING WEATHER JOIN WITH UTC TIMES\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Use UTC times for join\n",
        "laps_for_join_utc = lap_with_time.sort_values('LAP_DATETIME_UTC').copy()\n",
        "weather_for_join = weather_data[['TIME_DATETIME','AIR_TEMP','TRACK_TEMP','HUMIDITY','PRESSURE','WIND_SPEED','WIND_DIRECTION','RAIN']].sort_values('TIME_DATETIME').copy()\n",
        "weather_for_join = weather_for_join.dropna(subset=['TIME_DATETIME']).copy()\n",
        "\n",
        "print(f\"\\nðŸ“Š Join Setup (UTC):\")\n",
        "print(f\"   Laps: {len(laps_for_join_utc)}\")\n",
        "print(f\"   Weather: {len(weather_for_join)}\")\n",
        "\n",
        "if len(laps_for_join_utc) > 0 and len(weather_for_join) > 0:\n",
        "    # Perform join using UTC times\n",
        "    joined = pd.merge_asof(\n",
        "        laps_for_join_utc,\n",
        "        weather_for_join,\n",
        "        left_on='LAP_DATETIME_UTC', right_on='TIME_DATETIME',\n",
        "        direction='nearest',\n",
        "        tolerance=pd.Timedelta('30m')\n",
        "    )\n",
        "    \n",
        "    print(f\"\\nâœ“ Join completed:\")\n",
        "    print(f\"   Total rows: {len(joined)}\")\n",
        "    \n",
        "    if 'AIR_TEMP' in joined.columns:\n",
        "        matched = joined['AIR_TEMP'].notna().sum()\n",
        "        print(f\"   Rows with weather data: {matched} / {len(joined)} ({matched/len(joined)*100:.1f}%)\")\n",
        "        \n",
        "        if matched > 0:\n",
        "            print(f\"\\n   âœ“ SUCCESS! Weather data matched to {matched} lap records\")\n",
        "            print(f\"\\n   Sample joined data:\")\n",
        "            sample_cols = ['NUMBER','LAP_NUMBER','LAP_TIME','LAP_DATETIME_UTC','AIR_TEMP','TRACK_TEMP','HUMIDITY']\n",
        "            print(joined[sample_cols].head(10))\n",
        "        else:\n",
        "            print(f\"\\n   âš ï¸  Still no matches - check time ranges\")\n",
        "    else:\n",
        "        print(\"   âœ— AIR_TEMP column missing\")\n",
        "else:\n",
        "    print(\"   âœ— Cannot join - missing data\")\n",
        "    joined = pd.DataFrame()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Phase 6: Flag Impact Analysis\n",
        "\n",
        "Analyze how race flags (FCY, GF, FF) affected performance, positions, and race dynamics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "FLAG DISTRIBUTION ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "âœ“ FLAG_AT_FL column found\n",
            "\n",
            "ðŸ“Š Flag Distribution:\n",
            "   GF: 370 laps (76.1%)\n",
            "   FCY: 89 laps (18.3%)\n",
            "   FF: 27 laps (5.6%)\n",
            "\n",
            "   Unique flag types: ['FCY', 'FF', 'GF']\n"
          ]
        }
      ],
      "source": [
        "# Step 6.1: Analyze flag distribution and identify flag periods\n",
        "print(\"=\" * 80)\n",
        "print(\"FLAG DISTRIBUTION ANALYSIS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Check FLAG_AT_FL column\n",
        "if 'FLAG_AT_FL' in lap_analysis.columns:\n",
        "    print(f\"\\nâœ“ FLAG_AT_FL column found\")\n",
        "    \n",
        "    # Count flags by type\n",
        "    flag_counts = lap_analysis['FLAG_AT_FL'].value_counts()\n",
        "    print(f\"\\nðŸ“Š Flag Distribution:\")\n",
        "    for flag, count in flag_counts.items():\n",
        "        pct = (count / len(lap_analysis)) * 100\n",
        "        print(f\"   {flag}: {count} laps ({pct:.1f}%)\")\n",
        "    \n",
        "    # Identify unique flag values\n",
        "    unique_flags = lap_analysis['FLAG_AT_FL'].unique()\n",
        "    print(f\"\\n   Unique flag types: {sorted([f for f in unique_flags if pd.notna(f)])}\")\n",
        "    \n",
        "    # Check for missing flags\n",
        "    missing_flags = lap_analysis['FLAG_AT_FL'].isna().sum()\n",
        "    if missing_flags > 0:\n",
        "        print(f\"   Missing flag data: {missing_flags} laps\")\n",
        "else:\n",
        "    print(\"âœ— FLAG_AT_FL column not found in lap_analysis\")\n",
        "    print(f\"   Available columns: {[c for c in lap_analysis.columns if 'FLAG' in c.upper()]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "LAP TIME COMPARISON BY FLAG TYPE\n",
            "================================================================================\n",
            "\n",
            "ðŸ“Š Lap Time Statistics by Flag Type:\n",
            "            count     mean   median     std      min      max\n",
            "FLAG_AT_FL                                                   \n",
            "FCY            89  192.995  204.700  31.898  148.884  232.412\n",
            "FF             27  152.262  151.469   2.859  150.032  164.291\n",
            "GF            369  158.057  151.758  21.170  148.630  389.514\n",
            "\n",
            "âš¡ Fastest average lap time: FF (152.262s)\n",
            "ðŸŒ Slowest average lap time: FCY (192.995s)\n",
            "   Difference: 40.733s\n"
          ]
        }
      ],
      "source": [
        "# Step 6.2: Compare lap times under different flag conditions\n",
        "print(\"=\" * 80)\n",
        "print(\"LAP TIME COMPARISON BY FLAG TYPE\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Ensure LAP_TIME_SECONDS exists\n",
        "if 'LAP_TIME_SECONDS' not in lap_analysis.columns:\n",
        "    lap_analysis['LAP_TIME_SECONDS'] = lap_analysis['LAP_TIME'].apply(time_to_sec)\n",
        "\n",
        "# Filter valid lap times\n",
        "valid_flag_laps = lap_analysis[\n",
        "    (lap_analysis['LAP_TIME_SECONDS'].notna()) & \n",
        "    (lap_analysis['LAP_TIME_SECONDS'] < 500) &\n",
        "    (lap_analysis['FLAG_AT_FL'].notna())\n",
        "].copy()\n",
        "\n",
        "if len(valid_flag_laps) > 0:\n",
        "    # Group by flag type and calculate statistics\n",
        "    flag_stats = valid_flag_laps.groupby('FLAG_AT_FL')['LAP_TIME_SECONDS'].agg([\n",
        "        'count', 'mean', 'median', 'std', 'min', 'max'\n",
        "    ]).round(3)\n",
        "    \n",
        "    print(f\"\\nðŸ“Š Lap Time Statistics by Flag Type:\")\n",
        "    print(flag_stats)\n",
        "    \n",
        "    # Identify fastest flag condition\n",
        "    fastest_flag = flag_stats['mean'].idxmin()\n",
        "    slowest_flag = flag_stats['mean'].idxmax()\n",
        "    \n",
        "    print(f\"\\nâš¡ Fastest average lap time: {fastest_flag} ({flag_stats.loc[fastest_flag, 'mean']:.3f}s)\")\n",
        "    print(f\"ðŸŒ Slowest average lap time: {slowest_flag} ({flag_stats.loc[slowest_flag, 'mean']:.3f}s)\")\n",
        "    print(f\"   Difference: {flag_stats.loc[slowest_flag, 'mean'] - flag_stats.loc[fastest_flag, 'mean']:.3f}s\")\n",
        "else:\n",
        "    print(\"âš ï¸  No valid flag data available for comparison\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "FLAG PERIODS IDENTIFICATION\n",
            "================================================================================\n",
            "\n",
            "ðŸ“Š Flag Periods by Lap (dominant flag per lap):\n",
            "    LAP_NUMBER DOMINANT_FLAG\n",
            "0            1           FCY\n",
            "1            2            GF\n",
            "2            3            GF\n",
            "3            4            GF\n",
            "4            5            GF\n",
            "5            6            GF\n",
            "6            7            GF\n",
            "7            8            GF\n",
            "8            9            GF\n",
            "9           10            GF\n",
            "10          11           FCY\n",
            "11          12           FCY\n",
            "12          13            GF\n",
            "13          14            GF\n",
            "14          15            GF\n",
            "15          16            GF\n",
            "16          17            FF\n",
            "\n",
            "ðŸ“ˆ Flag Period Summary:\n",
            "   FCY: Laps 1 to 12 (3 laps)\n",
            "   FF: Laps 17 to 17 (1 laps)\n",
            "   GF: Laps 2 to 16 (13 laps)\n"
          ]
        }
      ],
      "source": [
        "# Step 6.3: Identify flag periods (consecutive laps with same flag)\n",
        "print(\"=\" * 80)\n",
        "print(\"FLAG PERIODS IDENTIFICATION\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Sort by car and lap number\n",
        "flag_periods = lap_analysis[['NUMBER', 'LAP_NUMBER', 'FLAG_AT_FL', 'LAP_TIME_SECONDS']].copy()\n",
        "flag_periods = flag_periods.sort_values(['NUMBER', 'LAP_NUMBER']).reset_index(drop=True)\n",
        "\n",
        "# For each car, identify flag changes\n",
        "flag_changes = []\n",
        "for car_num in sorted(flag_periods['NUMBER'].unique()):\n",
        "    car_laps = flag_periods[flag_periods['NUMBER'] == car_num].sort_values('LAP_NUMBER')\n",
        "    \n",
        "    prev_flag = None\n",
        "    period_start_lap = None\n",
        "    \n",
        "    for idx, row in car_laps.iterrows():\n",
        "        current_flag = row['FLAG_AT_FL']\n",
        "        \n",
        "        if prev_flag != current_flag:\n",
        "            # Flag changed\n",
        "            if prev_flag is not None and period_start_lap is not None:\n",
        "                # End previous period\n",
        "                period_end_lap = row['LAP_NUMBER'] - 1\n",
        "                flag_changes.append({\n",
        "                    'NUMBER': car_num,\n",
        "                    'FLAG': prev_flag,\n",
        "                    'START_LAP': period_start_lap,\n",
        "                    'END_LAP': period_end_lap,\n",
        "                    'DURATION': period_end_lap - period_start_lap + 1\n",
        "                })\n",
        "            \n",
        "            # Start new period\n",
        "            period_start_lap = row['LAP_NUMBER']\n",
        "            prev_flag = current_flag\n",
        "    \n",
        "    # Handle last period\n",
        "    if period_start_lap is not None:\n",
        "        last_lap = car_laps['LAP_NUMBER'].max()\n",
        "        flag_changes.append({\n",
        "            'NUMBER': car_num,\n",
        "            'FLAG': prev_flag,\n",
        "            'START_LAP': period_start_lap,\n",
        "            'END_LAP': last_lap,\n",
        "            'DURATION': last_lap - period_start_lap + 1\n",
        "        })\n",
        "\n",
        "flag_periods_df = pd.DataFrame(flag_changes)\n",
        "\n",
        "# Aggregate by flag type and lap (most common flag per lap)\n",
        "lap_flags = lap_analysis.groupby('LAP_NUMBER')['FLAG_AT_FL'].agg(lambda x: x.mode()[0] if len(x.mode()) > 0 else None).reset_index()\n",
        "lap_flags.columns = ['LAP_NUMBER', 'DOMINANT_FLAG']\n",
        "\n",
        "print(f\"\\nðŸ“Š Flag Periods by Lap (dominant flag per lap):\")\n",
        "print(lap_flags.head(20))\n",
        "\n",
        "# Count flag periods\n",
        "print(f\"\\nðŸ“ˆ Flag Period Summary:\")\n",
        "for flag in sorted(lap_flags['DOMINANT_FLAG'].dropna().unique()):\n",
        "    laps = lap_flags[lap_flags['DOMINANT_FLAG'] == flag]\n",
        "    print(f\"   {flag}: Laps {laps['LAP_NUMBER'].min():.0f} to {laps['LAP_NUMBER'].max():.0f} ({len(laps)} laps)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "POSITION CHANGES DURING FLAG PERIODS\n",
            "================================================================================\n",
            "\n",
            "ðŸš© FCY (Full Course Yellow) Periods:\n",
            "   FCY occurred on laps: [1, 11, 12]\n"
          ]
        }
      ],
      "source": [
        "# Step 6.4: Position changes during flag periods\n",
        "# Compare positions before, during, and after FCY periods\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"POSITION CHANGES DURING FLAG PERIODS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Merge position data with flag data\n",
        "if 'position_df' in locals() or 'position_df' in globals():\n",
        "    # Merge position with flags\n",
        "    pos_with_flags = position_df.merge(\n",
        "        lap_analysis[['NUMBER', 'LAP_NUMBER', 'FLAG_AT_FL']],\n",
        "        on=['NUMBER', 'LAP_NUMBER'],\n",
        "        how='left'\n",
        "    )\n",
        "    \n",
        "    # Identify FCY periods (most impactful)\n",
        "    fcy_laps = lap_flags[lap_flags['DOMINANT_FLAG'] == 'FCY']['LAP_NUMBER'].unique() if 'FCY' in lap_flags['DOMINANT_FLAG'].values else []\n",
        "    \n",
        "    if len(fcy_laps) > 0:\n",
        "        print(f\"\\nðŸš© FCY (Full Course Yellow) Periods:\")\n",
        "        print(f\"   FCY occurred on laps: {sorted(fcy_laps)}\")\n",
        "        \n",
        "        # For each car, compare position before FCY vs after FCY\n",
        "        fcy_impact = []\n",
        "        \n",
        "        for car_num in sorted(pos_with_flags['NUMBER'].unique()):\n",
        "            car_pos = pos_with_flags[pos_with_flags['NUMBER'] == car_num].sort_values('LAP_NUMBER')\n",
        "            \n",
        "            # Find first and last FCY lap\n",
        "            first_fcy = min(fcy_laps) if len(fcy_laps) > 0 else None\n",
        "            last_fcy = max(fcy_laps) if len(fcy_laps) > 0 else None\n",
        "            \n",
        "            if first_fcy and last_fcy:\n",
        "                # Position before FCY (lap before first FCY)\n",
        "                before_lap = first_fcy - 1\n",
        "                before_pos = car_pos[car_pos['LAP_NUMBER'] == before_lap]\n",
        "                \n",
        "                # Position after FCY (lap after last FCY)\n",
        "                after_lap = last_fcy + 1\n",
        "                after_pos = car_pos[car_pos['LAP_NUMBER'] == after_lap]\n",
        "                \n",
        "                if len(before_pos) > 0 and len(after_pos) > 0:\n",
        "                    pos_before = before_pos['POSITION_AT_LAP'].iloc[0]\n",
        "                    pos_after = after_pos['POSITION_AT_LAP'].iloc[0]\n",
        "                    pos_change = pos_before - pos_after  # Positive = gained positions\n",
        "                    \n",
        "                    fcy_impact.append({\n",
        "                        'NUMBER': car_num,\n",
        "                        'POS_BEFORE_FCY': pos_before,\n",
        "                        'POS_AFTER_FCY': pos_after,\n",
        "                        'POSITION_CHANGE': pos_change\n",
        "                    })\n",
        "        \n",
        "        fcy_impact_df = pd.DataFrame(fcy_impact)\n",
        "        \n",
        "        if len(fcy_impact_df) > 0:\n",
        "            print(f\"\\nðŸ“Š Position Changes During FCY Periods:\")\n",
        "            print(f\"\\n   Biggest Gains:\")\n",
        "            for _, row in fcy_impact_df.nlargest(5, 'POSITION_CHANGE').iterrows():\n",
        "                print(f\"   Car #{int(row['NUMBER']):2d}: P{int(row['POS_BEFORE_FCY']):2d} â†’ P{int(row['POS_AFTER_FCY']):2d} (Gained {row['POSITION_CHANGE']:.0f} positions)\")\n",
        "            \n",
        "            print(f\"\\n   Biggest Losses:\")\n",
        "            for _, row in fcy_impact_df.nsmallest(5, 'POSITION_CHANGE').iterrows():\n",
        "                print(f\"   Car #{int(row['NUMBER']):2d}: P{int(row['POS_BEFORE_FCY']):2d} â†’ P{int(row['POS_AFTER_FCY']):2d} (Lost {abs(row['POSITION_CHANGE']):.0f} positions)\")\n",
        "    else:\n",
        "        print(\"\\n   No FCY periods found in this race\")\n",
        "else:\n",
        "    print(\"âš ï¸  position_df not available - run Phase 3 first\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "RESTART PERFORMANCE ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "ðŸ“Š Restart Performance (FCY â†’ GF transitions):\n",
            "   Total restart laps identified: 56\n",
            "\n",
            "   Best Restart Performances (faster than average):\n",
            "   Car #31 Lap  9: 154.138s (vs avg 169.402s, -15.264s faster)\n",
            "   Car #46 Lap 14: 149.258s (vs avg 162.210s, -12.952s faster)\n",
            "   Car # 7 Lap 14: 149.309s (vs avg 162.251s, -12.942s faster)\n",
            "   Car #55 Lap 14: 149.726s (vs avg 162.287s, -12.561s faster)\n",
            "   Car #16 Lap 14: 149.768s (vs avg 162.270s, -12.502s faster)\n",
            "\n",
            "   Worst Restart Performances (slower than average):\n",
            "   Car #15 Lap  2: 389.514s (vs avg 204.817s, 184.697s slower)\n",
            "   Car #41 Lap 13: 223.197s (vs avg 162.561s, 60.636s slower)\n",
            "   Car #78 Lap 13: 222.934s (vs avg 162.506s, 60.428s slower)\n",
            "   Car #21 Lap 13: 222.609s (vs avg 162.609s, 60.000s slower)\n",
            "   Car #47 Lap 13: 222.462s (vs avg 162.747s, 59.715s slower)\n"
          ]
        }
      ],
      "source": [
        "# Step 6.5: Restart performance analysis (laps immediately after flag changes)\n",
        "print(\"=\" * 80)\n",
        "print(\"RESTART PERFORMANCE ANALYSIS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Identify laps that are restarts (lap after flag change from FCY to GF)\n",
        "restart_laps = []\n",
        "for car_num in sorted(lap_analysis['NUMBER'].unique()):\n",
        "    car_laps = lap_analysis[lap_analysis['NUMBER'] == car_num].sort_values('LAP_NUMBER')\n",
        "    \n",
        "    prev_flag = None\n",
        "    for idx, row in car_laps.iterrows():\n",
        "        current_flag = row['FLAG_AT_FL']\n",
        "        \n",
        "        # Check if this is a restart (FCY â†’ GF transition)\n",
        "        if prev_flag == 'FCY' and current_flag == 'GF':\n",
        "            restart_laps.append({\n",
        "                'NUMBER': car_num,\n",
        "                'LAP_NUMBER': row['LAP_NUMBER'],\n",
        "                'LAP_TIME_SECONDS': row.get('LAP_TIME_SECONDS', np.nan) if 'LAP_TIME_SECONDS' in row else np.nan\n",
        "            })\n",
        "        \n",
        "        prev_flag = current_flag\n",
        "\n",
        "if len(restart_laps) > 0:\n",
        "    restart_df = pd.DataFrame(restart_laps)\n",
        "    \n",
        "    # Compare restart lap times to average lap times\n",
        "    if 'LAP_TIME_SECONDS' not in lap_analysis.columns:\n",
        "        lap_analysis['LAP_TIME_SECONDS'] = lap_analysis['LAP_TIME'].apply(time_to_sec)\n",
        "    \n",
        "    # Get average lap time per car (excluding restart laps)\n",
        "    car_avg_lap = lap_analysis[\n",
        "        (lap_analysis['LAP_TIME_SECONDS'].notna()) & \n",
        "        (lap_analysis['LAP_TIME_SECONDS'] < 500)\n",
        "    ].groupby('NUMBER')['LAP_TIME_SECONDS'].mean().reset_index(name='AVG_LAP_TIME')\n",
        "    \n",
        "    restart_analysis = restart_df.merge(car_avg_lap, on='NUMBER', how='left')\n",
        "    restart_analysis['RESTART_DELTA'] = restart_analysis['LAP_TIME_SECONDS'] - restart_analysis['AVG_LAP_TIME']\n",
        "    \n",
        "    print(f\"\\nðŸ“Š Restart Performance (FCY â†’ GF transitions):\")\n",
        "    print(f\"   Total restart laps identified: {len(restart_analysis)}\")\n",
        "    \n",
        "    print(f\"\\n   Best Restart Performances (faster than average):\")\n",
        "    best_restarts = restart_analysis.nsmallest(5, 'RESTART_DELTA')\n",
        "    for _, row in best_restarts.iterrows():\n",
        "        print(f\"   Car #{int(row['NUMBER']):2d} Lap {int(row['LAP_NUMBER']):2d}: {row['LAP_TIME_SECONDS']:.3f}s (vs avg {row['AVG_LAP_TIME']:.3f}s, {row['RESTART_DELTA']:.3f}s faster)\")\n",
        "    \n",
        "    print(f\"\\n   Worst Restart Performances (slower than average):\")\n",
        "    worst_restarts = restart_analysis.nlargest(5, 'RESTART_DELTA')\n",
        "    for _, row in worst_restarts.iterrows():\n",
        "        print(f\"   Car #{int(row['NUMBER']):2d} Lap {int(row['LAP_NUMBER']):2d}: {row['LAP_TIME_SECONDS']:.3f}s (vs avg {row['AVG_LAP_TIME']:.3f}s, {row['RESTART_DELTA']:.3f}s slower)\")\n",
        "else:\n",
        "    print(\"   No FCY â†’ GF transitions found (no restarts identified)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Phase 6 Progress:**\n",
        "âœ… Flag distribution analyzed\n",
        "âœ… Lap time comparison by flag type\n",
        "âœ… Flag periods identified\n",
        "âœ… Position changes during flag periods\n",
        "âœ… Restart performance analyzed\n",
        "\n",
        "**Key Insights:**\n",
        "- FCY periods significantly slow lap times\n",
        "- Restart performance varies by driver\n",
        "- Flag periods can cause major position changes\n",
        "\n",
        "**Next:** Phase 7 - Lap Consistency & Degradation Analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Phase 7: Lap Consistency & Degradation Analysis\n",
        "\n",
        "Quantify driver consistency and tire/performance degradation trends over the race.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "CONSISTENCY & DEGRADATION SETUP\n",
            "================================================================================\n",
            "Valid laps: 485 across 30 cars\n",
            "   NUMBER  LAP_NUMBER  LAP_TIME  LAP_TIME_SECONDS\n",
            "0       2           1  3:52.412           232.412\n",
            "1       3           1  3:46.084           226.084\n",
            "2       3           1  3:45.016           225.016\n",
            "3       3           2  2:48.736           168.736\n",
            "4       3           2  2:47.237           167.237\n",
            "5       3           3  2:36.896           156.896\n",
            "6       3           3  2:32.634           152.634\n",
            "7       3           4  2:33.653           153.653\n",
            "8       3           4  2:32.869           152.869\n",
            "9       3           5  2:33.941           153.941\n"
          ]
        }
      ],
      "source": [
        "# Step 7.1: Build valid lap dataset and ensure numeric lap times\n",
        "print(\"=\" * 80)\n",
        "print(\"CONSISTENCY & DEGRADATION SETUP\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "if 'LAP_TIME_SECONDS' not in lap_analysis.columns:\n",
        "    lap_analysis['LAP_TIME_SECONDS'] = lap_analysis['LAP_TIME'].apply(to_seconds_any if 'to_seconds_any' in globals() else time_to_sec)\n",
        "\n",
        "laps_valid = lap_analysis[(lap_analysis['LAP_TIME_SECONDS'].notna()) & (lap_analysis['LAP_TIME_SECONDS'] < 500)].copy()\n",
        "laps_valid = laps_valid.sort_values(['NUMBER','LAP_NUMBER']).reset_index(drop=True)\n",
        "\n",
        "print(f\"Valid laps: {len(laps_valid)} across {laps_valid['NUMBER'].nunique()} cars\")\n",
        "print(laps_valid[['NUMBER','LAP_NUMBER','LAP_TIME','LAP_TIME_SECONDS']].head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 10 most consistent (lowest std):\n",
            "Car #80: std 19.053s, mean 163.803s, cv 11.6%\n",
            "Car #18: std 20.421s, mean 164.704s, cv 12.4%\n",
            "Car # 8: std 20.928s, mean 164.106s, cv 12.8%\n",
            "Car #57: std 22.102s, mean 164.022s, cv 13.5%\n",
            "Car #86: std 22.774s, mean 163.691s, cv 13.9%\n",
            "Car #73: std 22.941s, mean 164.729s, cv 13.9%\n",
            "Car #11: std 23.127s, mean 161.008s, cv 14.4%\n",
            "Car # 3: std 23.144s, mean 163.273s, cv 14.2%\n",
            "Car #89: std 24.009s, mean 163.202s, cv 14.7%\n",
            "Car # 5: std 24.183s, mean 163.170s, cv 14.8%\n"
          ]
        }
      ],
      "source": [
        "# Step 7.2: Consistency metrics per car\n",
        "import numpy as np\n",
        "\n",
        "consistency = laps_valid.groupby('NUMBER').agg(\n",
        "    laps=('LAP_NUMBER','count'),\n",
        "    mean_s=('LAP_TIME_SECONDS','mean'),\n",
        "    std_s=('LAP_TIME_SECONDS','std'),\n",
        "    p25=('LAP_TIME_SECONDS', lambda x: np.percentile(x, 25)),\n",
        "    p75=('LAP_TIME_SECONDS', lambda x: np.percentile(x, 75)),\n",
        "    best_s=('LAP_TIME_SECONDS','min'),\n",
        "    worst_s=('LAP_TIME_SECONDS','max')\n",
        ").reset_index()\n",
        "\n",
        "consistency['cv_pct'] = (consistency['std_s'] / consistency['mean_s']) * 100.0\n",
        "consistency['iqr_s'] = consistency['p75'] - consistency['p25']\n",
        "\n",
        "print(\"Top 10 most consistent (lowest std):\")\n",
        "for _, row in consistency.nsmallest(10, 'std_s').iterrows():\n",
        "    print(f\"Car #{int(row['NUMBER']):2d}: std {row['std_s']:.3f}s, mean {row['mean_s']:.3f}s, cv {row['cv_pct']:.1f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 10 most degrading (highest slope):\n",
            "Car #51: slope +2.059 s/lap over 14 laps\n",
            "Car #113: slope +-0.047 s/lap over 17 laps\n",
            "Car # 7: slope +-0.378 s/lap over 17 laps\n",
            "Car #46: slope +-0.404 s/lap over 17 laps\n",
            "Car #13: slope +-0.407 s/lap over 17 laps\n",
            "Car #16: slope +-0.424 s/lap over 17 laps\n",
            "Car #55: slope +-0.457 s/lap over 17 laps\n",
            "Car #72: slope +-0.463 s/lap over 17 laps\n",
            "Car #41: slope +-0.474 s/lap over 17 laps\n",
            "Car #21: slope +-0.505 s/lap over 17 laps\n",
            "\n",
            "Top 10 most improving (lowest slope):\n",
            "Car #15: slope -29.238 s/lap over 6 laps\n",
            "Car #31: slope -4.981 s/lap over 12 laps\n",
            "Car #11: slope -4.596 s/lap over 10 laps\n",
            "Car #89: slope -1.629 s/lap over 17 laps\n",
            "Car #80: slope -1.476 s/lap over 17 laps\n",
            "Car # 8: slope -1.205 s/lap over 17 laps\n",
            "Car #57: slope -1.025 s/lap over 17 laps\n",
            "Car #86: slope -1.015 s/lap over 17 laps\n",
            "Car #18: slope -0.996 s/lap over 17 laps\n",
            "Car # 3: slope -0.894 s/lap over 34 laps\n"
          ]
        }
      ],
      "source": [
        "# Step 7.3: Degradation slope per car (sec/lap) via linear fit\n",
        "# Positive slope = getting slower each lap; Negative = improving\n",
        "\n",
        "degradation_rows = []\n",
        "for car_num, g in laps_valid.groupby('NUMBER'):\n",
        "    x = g['LAP_NUMBER'].values.astype(float)\n",
        "    y = g['LAP_TIME_SECONDS'].values.astype(float)\n",
        "    if len(x) >= 3:\n",
        "        slope, intercept = np.polyfit(x, y, 1)\n",
        "        degradation_rows.append({'NUMBER': car_num, 'slope_sec_per_lap': slope, 'intercept': intercept, 'laps': len(x)})\n",
        "\n",
        "degradation = pd.DataFrame(degradation_rows)\n",
        "\n",
        "print(\"Top 10 most degrading (highest slope):\")\n",
        "for _, row in degradation.nlargest(10, 'slope_sec_per_lap').iterrows():\n",
        "    print(f\"Car #{int(row['NUMBER']):2d}: slope +{row['slope_sec_per_lap']:.3f} s/lap over {int(row['laps'])} laps\")\n",
        "\n",
        "print(\"\\nTop 10 most improving (lowest slope):\")\n",
        "for _, row in degradation.nsmallest(10, 'slope_sec_per_lap').iterrows():\n",
        "    print(f\"Car #{int(row['NUMBER']):2d}: slope {row['slope_sec_per_lap']:.3f} s/lap over {int(row['laps'])} laps\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Largest positive spikes (sudden worsening):\n",
            "Car #51: +27.722s (3-lap rolling)\n",
            "Car # 7: +25.793s (3-lap rolling)\n",
            "Car #46: +25.539s (3-lap rolling)\n",
            "Car #13: +25.326s (3-lap rolling)\n",
            "Car #16: +25.306s (3-lap rolling)\n",
            "Car #55: +25.300s (3-lap rolling)\n",
            "Car #72: +24.715s (3-lap rolling)\n",
            "Car #41: +24.567s (3-lap rolling)\n",
            "Car #78: +24.363s (3-lap rolling)\n",
            "Car #21: +24.227s (3-lap rolling)\n",
            "\n",
            "Largest negative spikes (sudden improvement):\n",
            "Car #15: -79.112s (3-lap rolling)\n",
            "Car #31: -31.722s (3-lap rolling)\n",
            "Car #71: -25.951s (3-lap rolling)\n",
            "Car # 7: -25.422s (3-lap rolling)\n",
            "Car #46: -25.285s (3-lap rolling)\n",
            "Car #16: -25.182s (3-lap rolling)\n",
            "Car #55: -25.144s (3-lap rolling)\n",
            "Car #13: -24.870s (3-lap rolling)\n",
            "Car #88: -24.692s (3-lap rolling)\n",
            "Car #41: -24.614s (3-lap rolling)\n"
          ]
        }
      ],
      "source": [
        "# Step 7.4: Rolling 3-lap average to find stability/spikes\n",
        "roll_rows = []\n",
        "for car_num, g in laps_valid.groupby('NUMBER'):\n",
        "    g = g.sort_values('LAP_NUMBER').copy()\n",
        "    g['ROLL_MEAN_3'] = g['LAP_TIME_SECONDS'].rolling(window=3, min_periods=3).mean()\n",
        "    g['ROLL_DELTA'] = g['ROLL_MEAN_3'].diff()\n",
        "    # Save spikes per car\n",
        "    if g['ROLL_DELTA'].notna().any():\n",
        "        max_spike = g['ROLL_DELTA'].max()\n",
        "        min_spike = g['ROLL_DELTA'].min()\n",
        "        roll_rows.append({'NUMBER': car_num, 'max_spike_s': max_spike, 'min_spike_s': min_spike})\n",
        "\n",
        "rolling_summary = pd.DataFrame(roll_rows)\n",
        "\n",
        "print(\"Largest positive spikes (sudden worsening):\")\n",
        "for _, row in rolling_summary.nlargest(10, 'max_spike_s').iterrows():\n",
        "    print(f\"Car #{int(row['NUMBER']):2d}: +{row['max_spike_s']:.3f}s (3-lap rolling)\")\n",
        "\n",
        "print(\"\\nLargest negative spikes (sudden improvement):\")\n",
        "for _, row in rolling_summary.nsmallest(10, 'min_spike_s').iterrows():\n",
        "    print(f\"Car #{int(row['NUMBER']):2d}: {row['min_spike_s']:.3f}s (3-lap rolling)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best 3-lap sequences (lowest totals):\n",
            "Car #46: 446.085s across laps 8â€“10\n",
            "Car #55: 446.279s across laps 8â€“10\n",
            "Car # 7: 446.446s across laps 6â€“8\n",
            "Car #13: 446.487s across laps 7â€“9\n",
            "Car #16: 446.525s across laps 7â€“9\n",
            "Car #72: 446.950s across laps 9â€“11\n",
            "Car #21: 447.604s across laps 6â€“8\n",
            "Car #78: 448.004s across laps 7â€“9\n",
            "Car #41: 448.123s across laps 7â€“9\n",
            "Car #71: 449.146s across laps 8â€“10\n",
            "\n",
            "Worst 3-lap sequences (highest totals):\n",
            "Car #15: 764.196s across laps 1â€“3\n",
            "Car #51: 632.331s across laps 12â€“14\n",
            "Car # 3: 622.933s across laps 11â€“13\n",
            "Car # 7: 584.057s across laps 12â€“14\n",
            "Car #46: 583.999s across laps 12â€“14\n",
            "Car #13: 583.692s across laps 12â€“14\n",
            "Car #16: 583.605s across laps 12â€“14\n",
            "Car #55: 582.578s across laps 11â€“13\n",
            "Car #72: 582.545s across laps 12â€“14\n",
            "Car #31: 580.947s across laps 2â€“4\n"
          ]
        }
      ],
      "source": [
        "# Step 7.5: Best/Worst 3-lap sequences per car\n",
        "streak_rows = []\n",
        "for car_num, g in laps_valid.groupby('NUMBER'):\n",
        "    g = g.sort_values('LAP_NUMBER').copy()\n",
        "    if len(g) >= 3:\n",
        "        # Compute rolling sums for 3-lap windows\n",
        "        g['SUM3'] = g['LAP_TIME_SECONDS'].rolling(window=3, min_periods=3).sum()\n",
        "        best_sum = g['SUM3'].min()\n",
        "        worst_sum = g['SUM3'].max()\n",
        "        if np.isfinite(best_sum):\n",
        "            best_idx = g['SUM3'].idxmin()\n",
        "            best_end_lap = int(g.loc[best_idx, 'LAP_NUMBER'])\n",
        "            best_start_lap = best_end_lap - 2\n",
        "        else:\n",
        "            best_start_lap = best_end_lap = None\n",
        "        if np.isfinite(worst_sum):\n",
        "            worst_idx = g['SUM3'].idxmax()\n",
        "            worst_end_lap = int(g.loc[worst_idx, 'LAP_NUMBER'])\n",
        "            worst_start_lap = worst_end_lap - 2\n",
        "        else:\n",
        "            worst_start_lap = worst_end_lap = None\n",
        "        streak_rows.append({\n",
        "            'NUMBER': car_num,\n",
        "            'best3_sum_s': best_sum,\n",
        "            'best3_laps': (best_start_lap, best_end_lap),\n",
        "            'worst3_sum_s': worst_sum,\n",
        "            'worst3_laps': (worst_start_lap, worst_end_lap)\n",
        "        })\n",
        "\n",
        "streaks = pd.DataFrame(streak_rows)\n",
        "\n",
        "print(\"Best 3-lap sequences (lowest totals):\")\n",
        "for _, row in streaks.nsmallest(10, 'best3_sum_s').iterrows():\n",
        "    print(f\"Car #{int(row['NUMBER']):2d}: {row['best3_sum_s']:.3f}s across laps {row['best3_laps'][0]}â€“{row['best3_laps'][1]}\")\n",
        "\n",
        "print(\"\\nWorst 3-lap sequences (highest totals):\")\n",
        "for _, row in streaks.nlargest(10, 'worst3_sum_s').iterrows():\n",
        "    print(f\"Car #{int(row['NUMBER']):2d}: {row['worst3_sum_s']:.3f}s across laps {row['worst3_laps'][0]}â€“{row['worst3_laps'][1]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Phase 7 Progress:**\n",
        "- Consistency metrics computed (std, CV, IQR)\n",
        "- Degradation slopes estimated (sec/lap)\n",
        "- Rolling trends analyzed (3-lap smoothing)\n",
        "- Best/worst 3-lap sequences identified\n",
        "\n",
        "Next: Phase 8 â€“ Strategic Moments & Key Events (pit windows, key decisions).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Phase 8: Strategic Moments & Key Events\n",
        "\n",
        "Identify pit windows, key overtakes, restarts, sector spikes, and compile a race timeline of notable events.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "PIT WINDOW DETECTION\n",
            "================================================================================\n",
            "Available pit-related columns: ['PIT_TIME', 'CROSSING_FINISH_LINE_IN_PIT']\n",
            "No pit-related columns/events detected in this race\n"
          ]
        }
      ],
      "source": [
        "# Step 8.1: Detect pit stop indicators (if available)\n",
        "print(\"=\" * 80)\n",
        "print(\"PIT WINDOW DETECTION\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "pit_cols = [c for c in ['PIT_TIME','CROSSING_FINISH_LINE_IN_PIT'] if c in lap_analysis.columns]\n",
        "print(f\"Available pit-related columns: {pit_cols}\")\n",
        "\n",
        "pit_events = pd.DataFrame()\n",
        "if 'PIT_TIME' in lap_analysis.columns:\n",
        "    # Consider a pit event when PIT_TIME is non-null and > 0\n",
        "    # pit_events = lap_analysis[lap_analysis['PIT_TIME'].notna() & (lap_analysis['PIT_TIME'] > 0)][['NUMBER','LAP_NUMBER','PIT_TIME']].copy()\n",
        "    # Fix: Proper parentheses and handle non-numeric types\n",
        "    pit_mask = lap_analysis['PIT_TIME'].notna()\n",
        "    # Try to convert to numeric if needed\n",
        "    pit_time_numeric = pd.to_numeric(lap_analysis['PIT_TIME'], errors='coerce')\n",
        "    pit_mask = pit_mask & (pit_time_numeric > 0)\n",
        "    pit_events = lap_analysis[pit_mask][['NUMBER','LAP_NUMBER','PIT_TIME']].copy()\n",
        "    pit_events['EVENT'] = 'PIT_STOP'\n",
        "elif 'CROSSING_FINISH_LINE_IN_PIT' in lap_analysis.columns:\n",
        "    pit_events = lap_analysis[lap_analysis['CROSSING_FINISH_LINE_IN_PIT'].notna()][['NUMBER','LAP_NUMBER','CROSSING_FINISH_LINE_IN_PIT']].copy()\n",
        "    pit_events['PIT_TIME'] = np.nan\n",
        "    pit_events['EVENT'] = 'PIT_XFINISH'\n",
        "\n",
        "if len(pit_events) > 0:\n",
        "    print(f\"Found {len(pit_events)} pit-related events\")\n",
        "    print(pit_events.head(10))\n",
        "else:\n",
        "    print(\"No pit-related columns/events detected in this race\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "KEY OVERTAKES (Single-lap position changes â‰¥ 2)\n",
            "================================================================================\n",
            "Total overtaking events (>=2 positions in one lap): 47\n",
            "     NUMBER  LAP_NUMBER  PREV_POSITION  POSITION_AT_LAP  POSITION_DELTA\n",
            "313       3          12           19.0                2            17.0\n",
            "418       3          16            1.0                3            -2.0\n",
            "443       3          17            3.0                5            -2.0\n",
            "31        5           2           17.0               13             4.0\n",
            "175       5           7           13.0               16            -3.0\n",
            "315       7          12            1.0                3            -2.0\n",
            "34       11           2           22.0               19             3.0\n",
            "317      13          12            4.0                6            -2.0\n",
            "36       14           2           18.0               14             4.0\n",
            "372      14          14           16.0               14             2.0\n"
          ]
        }
      ],
      "source": [
        "# Step 8.2: Key overtakes (single-lap position changes) from earlier analysis\n",
        "print(\"=\" * 80)\n",
        "print(\"KEY OVERTAKES (Single-lap position changes â‰¥ 2)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "if 'position_df' in locals() or 'position_df' in globals():\n",
        "    pos_sorted = position_df.sort_values(['NUMBER','LAP_NUMBER']).copy()\n",
        "    pos_sorted['PREV_POSITION'] = pos_sorted.groupby('NUMBER')['POSITION_AT_LAP'].shift(1)\n",
        "    pos_sorted['POSITION_DELTA'] = pos_sorted['PREV_POSITION'] - pos_sorted['POSITION_AT_LAP']\n",
        "\n",
        "    overtakes = pos_sorted[(pos_sorted['POSITION_DELTA'].abs() >= 2) & (pos_sorted['PREV_POSITION'].notna())].copy()\n",
        "    print(f\"Total overtaking events (>=2 positions in one lap): {len(overtakes)}\")\n",
        "    print(overtakes[['NUMBER','LAP_NUMBER','PREV_POSITION','POSITION_AT_LAP','POSITION_DELTA']].head(10))\n",
        "else:\n",
        "    print(\"position_df not available - run Phase 3\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "SECTOR-LOSS SPIKES (Potential incidents or big mistakes)\n",
            "================================================================================\n",
            "     NUMBER  LAP_NUMBER  S1_loss  S2_loss  S3_loss  sector_loss_total\n",
            "158      31           6  590.722    1.536    1.228            593.486\n",
            "79       15           2  226.938    2.452    1.347            230.737\n",
            "156      31           4   91.548    3.080    4.261             98.889\n",
            "247      51          14   71.430    6.270   11.867             89.567\n",
            "246      51          13   15.984   33.811   30.066             79.861\n",
            "294       7          13   17.621   32.462   25.794             75.877\n",
            "195      46          13   17.242   32.620   25.307             75.169\n",
            "96       16          13   17.163   32.363   25.138             74.664\n",
            "56       13          13   17.210   32.296   25.104             74.610\n",
            "260      55          13   17.345   32.491   24.500             74.336\n",
            "328      72          13   16.731   32.406   23.981             73.118\n",
            "178      41          13   16.580   32.725   23.648             72.953\n",
            "362      78          13   16.560   32.824   23.306             72.690\n",
            "131      21          13   16.343   32.922   23.100             72.365\n",
            "212      47          13   16.263   33.015   22.940             72.218\n"
          ]
        }
      ],
      "source": [
        "# Step 8.3: Sector-loss spikes (from Phase 4) as key moments\n",
        "print(\"=\" * 80)\n",
        "print(\"SECTOR-LOSS SPIKES (Potential incidents or big mistakes)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Recompute lap_sectors if needed\n",
        "if 'lap_sectors' not in globals():\n",
        "    if all(c in lap_analysis.columns for c in ['S1_SEC','S2_SEC','S3_SEC']):\n",
        "        lap_field_best = lap_analysis.dropna(subset=['S1_SEC','S2_SEC','S3_SEC']).groupby('LAP_NUMBER').agg(\n",
        "            S1_best=('S1_SEC','min'), S2_best=('S2_SEC','min'), S3_best=('S3_SEC','min')\n",
        "        ).reset_index()\n",
        "        lap_sectors = lap_analysis[['NUMBER','LAP_NUMBER','S1_SEC','S2_SEC','S3_SEC']].dropna().merge(lap_field_best, on='LAP_NUMBER', how='left')\n",
        "        for s in ['S1','S2','S3']:\n",
        "            lap_sectors[f'{s}_loss'] = lap_sectors[f'{s}_SEC'] - lap_sectors[f'{s}_best']\n",
        "        lap_sectors['sector_loss_total'] = lap_sectors[['S1_loss','S2_loss','S3_loss']].clip(lower=0).sum(axis=1)\n",
        "\n",
        "if 'lap_sectors' in globals():\n",
        "    spikes = lap_sectors.sort_values('sector_loss_total', ascending=False).head(15)\n",
        "    print(spikes[['NUMBER','LAP_NUMBER','S1_loss','S2_loss','S3_loss','sector_loss_total']])\n",
        "else:\n",
        "    print(\"Sector data not available - run Phase 4\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "RACE TIMELINE (Key Events by Lap)\n",
            "================================================================================\n",
            "    LAP FLAG  BEST_CAR  BEST_LAP_S  MOV_CAR  POS_DELTA  \\\n",
            "0     1  FCY        46     221.204      NaN        NaN   \n",
            "1     2   GF        46     160.534     15.0      -20.0   \n",
            "2     3   GF        55     149.734     31.0       -6.0   \n",
            "3     4   GF         7     149.479     89.0      -13.0   \n",
            "4     5   GF         7     149.056     89.0       -9.0   \n",
            "5     6   GF        13     148.862     80.0       -2.0   \n",
            "6     7   GF         7     148.678     31.0       27.0   \n",
            "7     8   GF        46     148.630      3.0        1.0   \n",
            "8     9   GF        46     148.659     31.0       -2.0   \n",
            "9    10   GF        55     148.679     31.0       -4.0   \n",
            "10   11  FCY        72     148.884      8.0        1.0   \n",
            "11   12  FCY        31     150.680      3.0       17.0   \n",
            "12   13   GF        31     150.244     51.0       -6.0   \n",
            "13   14   GF        46     149.258     89.0        4.0   \n",
            "14   15   GF        13     149.382     73.0       -6.0   \n",
            "\n",
            "                                           NOTES  \n",
            "0                     Fastest: Car 46 (221.204s)  \n",
            "1   Car 15 loses 20 | Fastest: Car 46 (160.534s)  \n",
            "2    Car 31 loses 6 | Fastest: Car 55 (149.734s)  \n",
            "3    Car 89 loses 13 | Fastest: Car 7 (149.479s)  \n",
            "4     Car 89 loses 9 | Fastest: Car 7 (149.056s)  \n",
            "5    Car 80 loses 2 | Fastest: Car 13 (148.862s)  \n",
            "6    Car 31 gains 27 | Fastest: Car 7 (148.678s)  \n",
            "7     Car 3 gains 1 | Fastest: Car 46 (148.630s)  \n",
            "8    Car 31 loses 2 | Fastest: Car 46 (148.659s)  \n",
            "9    Car 31 loses 4 | Fastest: Car 55 (148.679s)  \n",
            "10    Car 8 gains 1 | Fastest: Car 72 (148.884s)  \n",
            "11   Car 3 gains 17 | Fastest: Car 31 (150.680s)  \n",
            "12   Car 51 loses 6 | Fastest: Car 31 (150.244s)  \n",
            "13   Car 89 gains 4 | Fastest: Car 46 (149.258s)  \n",
            "14   Car 73 loses 6 | Fastest: Car 13 (149.382s)  \n"
          ]
        }
      ],
      "source": [
        "# Step 8.4: Build race timeline of key events (by lap)\n",
        "print(\"=\" * 80)\n",
        "print(\"RACE TIMELINE (Key Events by Lap)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Start with dominant flag per lap (from Phase 6)\n",
        "if 'lap_flags' not in globals():\n",
        "    lap_flags = lap_analysis.groupby('LAP_NUMBER')['FLAG_AT_FL'].agg(lambda x: x.mode()[0] if len(x.mode())>0 else None).reset_index()\n",
        "    lap_flags.columns = ['LAP','FLAG']\n",
        "else:\n",
        "    lap_flags = lap_flags.rename(columns={'LAP_NUMBER':'LAP','DOMINANT_FLAG':'FLAG'})[['LAP','FLAG']]\n",
        "\n",
        "# Fastest lap on each lap (best performer for that lap)\n",
        "if 'LAP_TIME_SECONDS' not in lap_analysis.columns:\n",
        "    lap_analysis['LAP_TIME_SECONDS'] = lap_analysis['LAP_TIME'].apply(to_seconds_any if 'to_seconds_any' in globals() else time_to_sec)\n",
        "\n",
        "best_each_lap = lap_analysis.loc[lap_analysis.groupby('LAP_NUMBER')['LAP_TIME_SECONDS'].idxmin()][['LAP_NUMBER','NUMBER','LAP_TIME_SECONDS']].rename(columns={'LAP_NUMBER':'LAP','NUMBER':'BEST_CAR','LAP_TIME_SECONDS':'BEST_LAP_S'})\n",
        "\n",
        "# Biggest overtake on each lap\n",
        "biggest_overtake = pd.DataFrame()\n",
        "if 'position_df' in globals():\n",
        "    p = position_df.sort_values(['NUMBER','LAP_NUMBER']).copy()\n",
        "    p['PREV_POSITION'] = p.groupby('NUMBER')['POSITION_AT_LAP'].shift(1)\n",
        "    p['POS_DELTA'] = p['PREV_POSITION'] - p['POSITION_AT_LAP']\n",
        "    \n",
        "    # Fix: Handle NaN values and empty groups\n",
        "    def get_biggest_overtake(g):\n",
        "        # Filter out NaN values\n",
        "        g_valid = g[g['POS_DELTA'].notna()]\n",
        "        if len(g_valid) == 0:\n",
        "            return pd.Series({'NUMBER': np.nan, 'POS_DELTA': np.nan})\n",
        "        idx = g_valid['POS_DELTA'].abs().idxmax()\n",
        "        return g_valid.loc[idx][['NUMBER','POS_DELTA']]\n",
        "    \n",
        "    biggest_overtake = p.groupby('LAP_NUMBER').apply(get_biggest_overtake).reset_index()\n",
        "    biggest_overtake = biggest_overtake.rename(columns={'LAP_NUMBER':'LAP','NUMBER':'MOV_CAR','POS_DELTA':'POS_DELTA'})\n",
        "    # Drop rows where MOV_CAR is NaN\n",
        "    biggest_overtake = biggest_overtake[biggest_overtake['MOV_CAR'].notna()].copy()\n",
        "\n",
        "# Merge timeline pieces\n",
        "timeline = lap_flags.merge(best_each_lap, on='LAP', how='left')\n",
        "if len(biggest_overtake) > 0:\n",
        "    timeline = timeline.merge(biggest_overtake, on='LAP', how='left')\n",
        "\n",
        "# Attach pit marker if any\n",
        "if len(pit_events) > 0:\n",
        "    pit_by_lap = pit_events.groupby('LAP_NUMBER').size().reset_index(name='PIT_EVENTS').rename(columns={'LAP_NUMBER':'LAP'})\n",
        "    timeline = timeline.merge(pit_by_lap, on='LAP', how='left')\n",
        "\n",
        "# Basic narrative string\n",
        "def mk_row_note(r):\n",
        "    notes = []\n",
        "    # Check PIT_EVENTS\n",
        "    pit_events = r.get('PIT_EVENTS', np.nan)\n",
        "    if pd.notna(pit_events) and pit_events > 0:\n",
        "        notes.append(f\"Pit activity x{int(pit_events)}\")\n",
        "    \n",
        "    # Check MOV_CAR and POS_DELTA\n",
        "    mov_car = r.get('MOV_CAR', np.nan)\n",
        "    pos_delta = r.get('POS_DELTA', np.nan)\n",
        "    if pd.notna(mov_car) and pd.notna(pos_delta) and not pd.isna(pos_delta) and pos_delta != 0:\n",
        "        direction = 'gains' if pos_delta > 0 else 'loses'\n",
        "        notes.append(f\"Car {int(mov_car)} {direction} {abs(int(pos_delta))}\")\n",
        "    \n",
        "    # Check BEST_CAR\n",
        "    best_car = r.get('BEST_CAR', np.nan)\n",
        "    best_lap_s = r.get('BEST_LAP_S', np.nan)\n",
        "    if pd.notna(best_car) and pd.notna(best_lap_s):\n",
        "        notes.append(f\"Fastest: Car {int(best_car)} ({best_lap_s:.3f}s)\")\n",
        "    \n",
        "    return ' | '.join(notes) if notes else ''\n",
        "\n",
        "timeline['NOTES'] = timeline.apply(mk_row_note, axis=1)\n",
        "\n",
        "print(timeline.head(15))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Phase 8 Progress:**\n",
        "- Pit indicators identified (if present)\n",
        "- Overtakes summarized (single-lap position changes)\n",
        "- Sector-loss spikes highlighted\n",
        "- Race timeline dataframe built (`timeline` with `LAP`, `FLAG`, `BEST_CAR`, `MOV_CAR`, `POS_DELTA`, `PIT_EVENTS`, `NOTES`)\n",
        "\n",
        "Next: Phase 9 â€“ Narrative extraction (Acts, turning points, protagonists).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Phase 9: Narrative Elements Extraction\n",
        "\n",
        "Identify race \"Acts\" (Opening/Middle/Closing), turning points, protagonists, and dramatic moments to structure the race story.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "RACE ACTS IDENTIFICATION\n",
            "================================================================================\n",
            "\n",
            "ðŸ“– Race Structure (Total Laps: 17):\n",
            "   Act 1 (Opening): Laps 1-5\n",
            "   Act 2 (Middle): Laps 6-11\n",
            "   Act 3 (Closing): Laps 12-17\n",
            "\n",
            "âœ“ Race acts defined\n"
          ]
        }
      ],
      "source": [
        "# Step 9.1: Divide race into Acts (Opening, Middle, Closing)\n",
        "print(\"=\" * 80)\n",
        "print(\"RACE ACTS IDENTIFICATION\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Get total laps\n",
        "total_laps = lap_analysis['LAP_NUMBER'].max() if 'LAP_NUMBER' in lap_analysis.columns else 0\n",
        "\n",
        "# Divide into thirds\n",
        "act1_end = int(total_laps / 3)\n",
        "act2_end = int(total_laps * 2 / 3)\n",
        "\n",
        "print(f\"\\nðŸ“– Race Structure (Total Laps: {total_laps}):\")\n",
        "print(f\"   Act 1 (Opening): Laps 1-{act1_end}\")\n",
        "print(f\"   Act 2 (Middle): Laps {act1_end+1}-{act2_end}\")\n",
        "print(f\"   Act 3 (Closing): Laps {act2_end+1}-{total_laps}\")\n",
        "\n",
        "# Store for later use\n",
        "race_acts = {\n",
        "    'ACT1': {'start': 1, 'end': act1_end, 'name': 'Opening'},\n",
        "    'ACT2': {'start': act1_end+1, 'end': act2_end, 'name': 'Middle'},\n",
        "    'ACT3': {'start': act2_end+1, 'end': total_laps, 'name': 'Closing'}\n",
        "}\n",
        "\n",
        "print(f\"\\nâœ“ Race acts defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "TURNING POINTS IDENTIFICATION\n",
            "================================================================================\n",
            "\n",
            "ðŸ“Š Identified 7 Turning Points:\n",
            "\n",
            "   1. Lap Multiple: BIG_GAIN\n",
            "      Car #71 gained 19 positions (P29 â†’ P10)\n",
            "      Impact: HIGH\n",
            "\n",
            "   2. Lap Multiple: BIG_GAIN\n",
            "      Car #3 gained 16 positions (P21 â†’ P5)\n",
            "      Impact: HIGH\n",
            "\n",
            "   3. Lap Multiple: BIG_GAIN\n",
            "      Car #3 gained 16 positions (P21 â†’ P5)\n",
            "      Impact: HIGH\n",
            "\n",
            "   4. Lap 1-12: FLAG_PERIOD\n",
            "      Full Course Yellow period (Laps 1-12)\n",
            "      Impact: HIGH\n",
            "\n",
            "   5. Lap 7: SINGLE_LAP_MOVE\n",
            "      Car #31 gained 27 positions on Lap 7\n",
            "      Impact: MEDIUM\n",
            "\n",
            "   6. Lap 12: SINGLE_LAP_MOVE\n",
            "      Car #3 gained 17 positions on Lap 12\n",
            "      Impact: MEDIUM\n",
            "\n",
            "   7. Lap 2: SINGLE_LAP_MOVE\n",
            "      Car #71 gained 12 positions on Lap 2\n",
            "      Impact: MEDIUM\n"
          ]
        }
      ],
      "source": [
        "# Step 9.2: Identify turning points (major position changes, flag periods, incidents)\n",
        "print(\"=\" * 80)\n",
        "print(\"TURNING POINTS IDENTIFICATION\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "turning_points = []\n",
        "\n",
        "# 1. Biggest position changes (from Phase 3)\n",
        "if 'position_change' in globals():\n",
        "    top_gains = position_change.nlargest(3, 'POSITION_CHANGE')\n",
        "    for _, row in top_gains.iterrows():\n",
        "        turning_points.append({\n",
        "            'LAP': 'Multiple',\n",
        "            'TYPE': 'BIG_GAIN',\n",
        "            'DESCRIPTION': f\"Car #{int(row['NUMBER'])} gained {int(row['POSITION_CHANGE'])} positions (P{int(row['START_POSITION'])} â†’ P{int(row['END_POSITION'])})\",\n",
        "            'IMPACT': 'HIGH'\n",
        "        })\n",
        "\n",
        "# 2. Flag periods (from Phase 6)\n",
        "if 'lap_flags' in globals():\n",
        "    fcy_laps = lap_flags[lap_flags['FLAG'] == 'FCY']['LAP'].unique() if 'FLAG' in lap_flags.columns else []\n",
        "    if len(fcy_laps) > 0:\n",
        "        turning_points.append({\n",
        "            'LAP': f\"{int(min(fcy_laps))}-{int(max(fcy_laps))}\",\n",
        "            'TYPE': 'FLAG_PERIOD',\n",
        "            'DESCRIPTION': f\"Full Course Yellow period (Laps {int(min(fcy_laps))}-{int(max(fcy_laps))})\",\n",
        "            'IMPACT': 'HIGH'\n",
        "        })\n",
        "\n",
        "# 3. Biggest single-lap position changes (from Phase 3)\n",
        "if 'position_df' in globals():\n",
        "    p = position_df.sort_values(['NUMBER','LAP_NUMBER']).copy()\n",
        "    p['PREV_POSITION'] = p.groupby('NUMBER')['POSITION_AT_LAP'].shift(1)\n",
        "    p['POS_DELTA'] = p['PREV_POSITION'] - p['POSITION_AT_LAP']\n",
        "    big_changes = p[p['POS_DELTA'].abs() >= 3].nlargest(3, 'POS_DELTA')\n",
        "    for _, row in big_changes.iterrows():\n",
        "        direction = 'gained' if row['POS_DELTA'] > 0 else 'lost'\n",
        "        turning_points.append({\n",
        "            'LAP': int(row['LAP_NUMBER']),\n",
        "            'TYPE': 'SINGLE_LAP_MOVE',\n",
        "            'DESCRIPTION': f\"Car #{int(row['NUMBER'])} {direction} {abs(int(row['POS_DELTA']))} positions on Lap {int(row['LAP_NUMBER'])}\",\n",
        "            'IMPACT': 'MEDIUM'\n",
        "        })\n",
        "\n",
        "turning_points_df = pd.DataFrame(turning_points)\n",
        "print(f\"\\nðŸ“Š Identified {len(turning_points_df)} Turning Points:\")\n",
        "for idx, tp in turning_points_df.iterrows():\n",
        "    print(f\"\\n   {idx+1}. Lap {tp['LAP']}: {tp['TYPE']}\")\n",
        "    print(f\"      {tp['DESCRIPTION']}\")\n",
        "    print(f\"      Impact: {tp['IMPACT']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "PROTAGONISTS IDENTIFICATION\n",
            "================================================================================\n",
            "\n",
            "ðŸ† Top 5 Protagonists:\n",
            "\n",
            "   1. Car #46 - Finished P1\n",
            "      Journey: P1 â†’ P1 (Best: P1, Worst: P4)\n",
            "      Maintained starting position\n",
            "\n",
            "   2. Car # 7 - Finished P2\n",
            "      Journey: P2 â†’ P2 (Best: P1, Worst: P3)\n",
            "      Maintained starting position\n",
            "\n",
            "   3. Car #16 - Finished P3\n",
            "      Journey: P4 â†’ P3 (Best: P3, Worst: P5)\n",
            "      Gained 1 positions from start\n",
            "\n",
            "   4. Car #55 - Finished P4\n",
            "      Journey: P7 â†’ P4 (Best: P4, Worst: P7)\n",
            "      Gained 3 positions from start\n",
            "\n",
            "   5. Car #72 - Finished P5\n",
            "      Journey: P6 â†’ P5 (Best: P6, Worst: P8)\n",
            "      Gained 1 positions from start\n"
          ]
        }
      ],
      "source": [
        "# Step 9.3: Identify protagonists (top 5 drivers and their journeys)\n",
        "print(\"=\" * 80)\n",
        "print(\"PROTAGONISTS IDENTIFICATION\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Get top 5 finishers from race results\n",
        "if 'race_results' in globals():\n",
        "    top_5 = race_results.nsmallest(5, 'POSITION')[['NUMBER', 'POSITION']].copy()\n",
        "    \n",
        "    protagonists = []\n",
        "    for _, row in top_5.iterrows():\n",
        "        car_num = int(row['NUMBER'])\n",
        "        final_pos = int(row['POSITION'])\n",
        "        \n",
        "        # Get their journey from position data\n",
        "        if 'position_df' in globals():\n",
        "            car_positions = position_df[position_df['NUMBER'] == car_num].sort_values('LAP_NUMBER')\n",
        "            if len(car_positions) > 0:\n",
        "                start_pos = int(car_positions.iloc[0]['POSITION_AT_LAP'])\n",
        "                best_pos = int(car_positions['POSITION_AT_LAP'].min())\n",
        "                worst_pos = int(car_positions['POSITION_AT_LAP'].max())\n",
        "                pos_change = start_pos - final_pos\n",
        "                \n",
        "                protagonists.append({\n",
        "                    'CAR_NUMBER': car_num,\n",
        "                    'FINAL_POSITION': final_pos,\n",
        "                    'START_POSITION': start_pos,\n",
        "                    'BEST_POSITION': best_pos,\n",
        "                    'WORST_POSITION': worst_pos,\n",
        "                    'POSITION_CHANGE': pos_change,\n",
        "                    'JOURNEY': f\"P{start_pos} â†’ P{final_pos} (Best: P{best_pos}, Worst: P{worst_pos})\"\n",
        "                })\n",
        "    \n",
        "    protagonists_df = pd.DataFrame(protagonists)\n",
        "    \n",
        "    print(f\"\\nðŸ† Top 5 Protagonists:\")\n",
        "    for idx, prot in protagonists_df.iterrows():\n",
        "        print(f\"\\n   {idx+1}. Car #{prot['CAR_NUMBER']:2d} - Finished P{prot['FINAL_POSITION']}\")\n",
        "        print(f\"      Journey: {prot['JOURNEY']}\")\n",
        "        if prot['POSITION_CHANGE'] > 0:\n",
        "            print(f\"      Gained {int(prot['POSITION_CHANGE'])} positions from start\")\n",
        "        elif prot['POSITION_CHANGE'] < 0:\n",
        "            print(f\"      Lost {abs(int(prot['POSITION_CHANGE']))} positions from start\")\n",
        "        else:\n",
        "            print(f\"      Maintained starting position\")\n",
        "else:\n",
        "    print(\"âš ï¸  race_results not available\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "DRAMATIC MOMENTS SUMMARY\n",
            "================================================================================\n",
            "\n",
            "ðŸŽ¬ Dramatic Moments (4):\n",
            "\n",
            "   1. [COMEBACK] Lap Race\n",
            "      Car #71: Biggest comeback - P29 â†’ P10 (+19 positions)\n",
            "\n",
            "   2. [FASTEST_LAP] Lap 8\n",
            "      Car #46: Fastest lap on Lap 8 (148.630s)\n",
            "\n",
            "   3. [VOLATILITY] Lap Race\n",
            "      Car #31: Most volatile - Position range P1 to P28\n",
            "\n",
            "   4. [LEADERSHIP] Lap 1-16\n",
            "      Race had 7 leader changes\n"
          ]
        }
      ],
      "source": [
        "# Step 9.4: Dramatic moments summary (comebacks, crashes, fastest laps)\n",
        "print(\"=\" * 80)\n",
        "print(\"DRAMATIC MOMENTS SUMMARY\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "dramatic_moments = []\n",
        "\n",
        "# 1. Biggest comeback (most positions gained)\n",
        "if 'position_change' in globals():\n",
        "    biggest_comeback = position_change.nlargest(1, 'POSITION_CHANGE')\n",
        "    if len(biggest_comeback) > 0:\n",
        "        row = biggest_comeback.iloc[0]\n",
        "        dramatic_moments.append({\n",
        "            'TYPE': 'COMEBACK',\n",
        "            'LAP': 'Race',\n",
        "            'DESCRIPTION': f\"Car #{int(row['NUMBER'])}: Biggest comeback - P{int(row['START_POSITION'])} â†’ P{int(row['END_POSITION'])} (+{int(row['POSITION_CHANGE'])} positions)\"\n",
        "        })\n",
        "\n",
        "# 2. Fastest lap of the race\n",
        "if 'LAP_TIME_SECONDS' in lap_analysis.columns:\n",
        "    fastest_lap = lap_analysis.loc[lap_analysis['LAP_TIME_SECONDS'].idxmin()]\n",
        "    dramatic_moments.append({\n",
        "        'TYPE': 'FASTEST_LAP',\n",
        "        'LAP': int(fastest_lap['LAP_NUMBER']),\n",
        "        'DESCRIPTION': f\"Car #{int(fastest_lap['NUMBER'])}: Fastest lap on Lap {int(fastest_lap['LAP_NUMBER'])} ({fastest_lap['LAP_TIME_SECONDS']:.3f}s)\"\n",
        "    })\n",
        "\n",
        "# 3. Most volatile driver (biggest position range)\n",
        "if 'position_stats' in globals():\n",
        "    most_volatile = position_stats.nlargest(1, 'POSITION_RANGE')\n",
        "    if len(most_volatile) > 0:\n",
        "        row = most_volatile.iloc[0]\n",
        "        dramatic_moments.append({\n",
        "            'TYPE': 'VOLATILITY',\n",
        "            'LAP': 'Race',\n",
        "            'DESCRIPTION': f\"Car #{int(row['NUMBER'])}: Most volatile - Position range P{int(row['BEST_POSITION'])} to P{int(row['WORST_POSITION'])}\"\n",
        "        })\n",
        "\n",
        "# 4. Leader changes\n",
        "if 'leader_changes' in globals() and len(leader_changes) > 0:\n",
        "    dramatic_moments.append({\n",
        "        'TYPE': 'LEADERSHIP',\n",
        "        'LAP': f\"{int(leader_changes['LAP_NUMBER'].min())}-{int(leader_changes['LAP_NUMBER'].max())}\",\n",
        "        'DESCRIPTION': f\"Race had {len(leader_changes)} leader changes\"\n",
        "    })\n",
        "\n",
        "dramatic_df = pd.DataFrame(dramatic_moments)\n",
        "print(f\"\\nðŸŽ¬ Dramatic Moments ({len(dramatic_df)}):\")\n",
        "for idx, moment in dramatic_df.iterrows():\n",
        "    print(f\"\\n   {idx+1}. [{moment['TYPE']}] Lap {moment['LAP']}\")\n",
        "    print(f\"      {moment['DESCRIPTION']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Phase 9 Progress:**\n",
        "âœ… Race Acts identified (Opening/Middle/Closing)\n",
        "âœ… Turning points extracted\n",
        "âœ… Protagonists (top 5) journeys mapped\n",
        "âœ… Dramatic moments summarized\n",
        "\n",
        "**Next:** Phase 10 - Dashboard-Ready Data Structures (summary stats, pre-computed visualizations)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Phase 10: Dashboard-Ready Data Structures\n",
        "\n",
        "Prepare summary statistics, pre-computed visualization data, and structured datasets ready for dashboard implementation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "DASHBOARD SUMMARY STATISTICS\n",
            "================================================================================\n",
            "\n",
            "âœ“ Dashboard Statistics Created:\n",
            "   total_drivers: 31\n",
            "   total_laps: 17\n",
            "   winner: 46\n",
            "   fastest_lap_car: 46\n",
            "   fastest_lap_time: 148.63\n",
            "   fastest_lap_lap: 8\n",
            "   biggest_gain: 19\n",
            "   biggest_loss: 13\n",
            "   fcy_laps: 3\n",
            "   avg_temp: 28.70127572016461\n",
            "   temp_range: 28.5Â°C - 29.1Â°C\n"
          ]
        }
      ],
      "source": [
        "# Step 10.1: Create summary statistics dictionary for dashboard cards\n",
        "print(\"=\" * 80)\n",
        "print(\"DASHBOARD SUMMARY STATISTICS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "dashboard_stats = {}\n",
        "\n",
        "# Basic race info\n",
        "if 'race_results' in globals():\n",
        "    dashboard_stats['total_drivers'] = len(race_results)\n",
        "    dashboard_stats['total_laps'] = int(race_results['LAPS'].max()) if 'LAPS' in race_results.columns else 0\n",
        "    dashboard_stats['winner'] = int(race_results[race_results['POSITION'] == 1]['NUMBER'].iloc[0]) if len(race_results[race_results['POSITION'] == 1]) > 0 else None\n",
        "\n",
        "# Fastest lap\n",
        "if 'LAP_TIME_SECONDS' in lap_analysis.columns:\n",
        "    fastest = lap_analysis.loc[lap_analysis['LAP_TIME_SECONDS'].idxmin()]\n",
        "    dashboard_stats['fastest_lap_car'] = int(fastest['NUMBER'])\n",
        "    dashboard_stats['fastest_lap_time'] = float(fastest['LAP_TIME_SECONDS'])\n",
        "    dashboard_stats['fastest_lap_lap'] = int(fastest['LAP_NUMBER'])\n",
        "\n",
        "# Position changes\n",
        "if 'position_change' in globals():\n",
        "    dashboard_stats['biggest_gain'] = int(position_change['POSITION_CHANGE'].max())\n",
        "    dashboard_stats['biggest_loss'] = int(abs(position_change['POSITION_CHANGE'].min()))\n",
        "\n",
        "# Flag periods\n",
        "if 'lap_flags' in globals() and 'FLAG' in lap_flags.columns:\n",
        "    fcy_count = len(lap_flags[lap_flags['FLAG'] == 'FCY'])\n",
        "    dashboard_stats['fcy_laps'] = fcy_count\n",
        "\n",
        "# Weather\n",
        "if 'joined' in globals() and 'AIR_TEMP' in joined.columns:\n",
        "    dashboard_stats['avg_temp'] = float(joined['AIR_TEMP'].mean())\n",
        "    dashboard_stats['temp_range'] = f\"{float(joined['AIR_TEMP'].min()):.1f}Â°C - {float(joined['AIR_TEMP'].max()):.1f}Â°C\"\n",
        "\n",
        "print(f\"\\nâœ“ Dashboard Statistics Created:\")\n",
        "for key, value in dashboard_stats.items():\n",
        "    print(f\"   {key}: {value}\")\n",
        "\n",
        "# Store as global for dashboard use\n",
        "dashboard_summary = dashboard_stats\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "POSITION OVER TIME DATA (For Visualization)\n",
            "================================================================================\n",
            "âœ“ Position over time data ready:\n",
            "   - Records: 468\n",
            "   - Unique cars: 30\n",
            "   - Laps: 1 to 17\n",
            "\n",
            "   Sample data:\n",
            "   NUMBER  LAP_NUMBER  POSITION_AT_LAP CAR_NUMBER\n",
            "0       2           1               30          2\n",
            "1       3           1               21          3\n",
            "2       3           2               20          3\n",
            "3       3           3               20          3\n",
            "4       3           4               20          3\n",
            "5       3           5               19          3\n",
            "6       3           6               19          3\n",
            "7       3           7               20          3\n",
            "8       3           8               19          3\n",
            "9       3           9               19          3\n"
          ]
        }
      ],
      "source": [
        "# Step 10.2: Create position over time data for line chart\n",
        "print(\"=\" * 80)\n",
        "print(\"POSITION OVER TIME DATA (For Visualization)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "if 'position_df' in globals():\n",
        "    # Clean and prepare for visualization\n",
        "    viz_position = position_df[['NUMBER', 'LAP_NUMBER', 'POSITION_AT_LAP']].copy()\n",
        "    viz_position = viz_position.sort_values(['NUMBER', 'LAP_NUMBER']).reset_index(drop=True)\n",
        "    \n",
        "    # Add car number as string for easier filtering\n",
        "    viz_position['CAR_NUMBER'] = viz_position['NUMBER'].astype(int).astype(str)\n",
        "    \n",
        "    print(f\"âœ“ Position over time data ready:\")\n",
        "    print(f\"   - Records: {len(viz_position):,}\")\n",
        "    print(f\"   - Unique cars: {viz_position['NUMBER'].nunique()}\")\n",
        "    print(f\"   - Laps: {viz_position['LAP_NUMBER'].min()} to {viz_position['LAP_NUMBER'].max()}\")\n",
        "    print(f\"\\n   Sample data:\")\n",
        "    print(viz_position.head(10))\n",
        "else:\n",
        "    print(\"âš ï¸  position_df not available\")\n",
        "    viz_position = pd.DataFrame()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "SECTOR PERFORMANCE DATA (For Visualization)\n",
            "================================================================================\n",
            "âœ“ Sector performance data ready:\n",
            "   - Cars: 30\n",
            "\n",
            "   Sample data:\n",
            "   NUMBER     S1_avg     S2_avg      S3_avg  S1_best  S2_best  S3_best  \\\n",
            "0       2  47.663000  84.393000  100.356000   47.663   84.393  100.356   \n",
            "1       3  36.020824  62.729618   64.522824   32.914   57.593   60.037   \n",
            "2       5  35.788824  62.686647   64.694412   32.663   57.820   59.768   \n",
            "3       7  35.884765  62.028824   64.336941   32.544   56.689   59.129   \n",
            "4       8  36.173647  63.284529   64.648118   33.467   58.681   61.245   \n",
            "5      11  36.427100  61.313700   63.267400   33.048   57.988   60.261   \n",
            "6      13  35.920471  62.148941   64.293647   32.526   56.786   59.131   \n",
            "7      14  36.055118  62.372588   64.359294   32.837   57.505   59.468   \n",
            "8      15  75.806333  63.268167   65.743000   33.127   58.301   60.320   \n",
            "9      16  35.854647  62.146176   64.269059   32.431   56.909   59.189   \n",
            "\n",
            "  CAR_NUMBER  S1_RANK  S2_RANK  S3_RANK  \n",
            "0          2     28.0     30.0     30.0  \n",
            "1          3     15.0     17.0     21.0  \n",
            "2          5      6.0     16.0     25.0  \n",
            "3          7     11.0      4.0     16.0  \n",
            "4          8     18.0     26.0     24.0  \n",
            "5         11     23.0      2.0      1.0  \n",
            "6         13     13.0      7.0     14.0  \n",
            "7         14     16.0     10.0     17.0  \n",
            "8         15     29.0     25.0     28.0  \n",
            "9         16     10.0      6.0     13.0  \n"
          ]
        }
      ],
      "source": [
        "# Step 10.3: Create sector performance comparison data\n",
        "print(\"=\" * 80)\n",
        "print(\"SECTOR PERFORMANCE DATA (For Visualization)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "if 'car_sector_stats' in globals():\n",
        "    # Prepare sector comparison data\n",
        "    viz_sectors = car_sector_stats[['NUMBER', 'S1_avg', 'S2_avg', 'S3_avg', 'S1_best', 'S2_best', 'S3_best']].copy()\n",
        "    viz_sectors['CAR_NUMBER'] = viz_sectors['NUMBER'].astype(int).astype(str)\n",
        "    \n",
        "    # Calculate sector ranks\n",
        "    viz_sectors['S1_RANK'] = viz_sectors['S1_avg'].rank()\n",
        "    viz_sectors['S2_RANK'] = viz_sectors['S2_avg'].rank()\n",
        "    viz_sectors['S3_RANK'] = viz_sectors['S3_avg'].rank()\n",
        "    \n",
        "    print(f\"âœ“ Sector performance data ready:\")\n",
        "    print(f\"   - Cars: {len(viz_sectors)}\")\n",
        "    print(f\"\\n   Sample data:\")\n",
        "    print(viz_sectors.head(10))\n",
        "else:\n",
        "    print(\"âš ï¸  car_sector_stats not available - run Phase 4\")\n",
        "    viz_sectors = pd.DataFrame()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "DRIVER COMPARISON MATRIX\n",
            "================================================================================\n",
            "âœ“ Driver comparison matrix created:\n",
            "   - Drivers: 30\n",
            "\n",
            "   Sample data (top 10):\n",
            "   CAR_NUMBER  FINAL_POSITION  TOTAL_LAPS  BEST_POSITION  WORST_POSITION  \\\n",
            "0          46               1          17              1               4   \n",
            "1           7               2          17              1               3   \n",
            "2          16               3          17              3               5   \n",
            "3          55               4          17              4               7   \n",
            "4          72               5          17              6               8   \n",
            "5          13               6          17              3               7   \n",
            "6          78               7          17              8              12   \n",
            "7          41               8          17              7               9   \n",
            "8          71               9          17             10              29   \n",
            "9          21              10          17              9              11   \n",
            "\n",
            "   AVG_POSITION  POSITION_RANGE  LAP_TIME_STD  CONSISTENCY_CV  FASTEST_LAP  \n",
            "0      2.176471               3     27.229551       16.786574      148.630  \n",
            "1      1.764706               2     27.254229       16.797621      148.678  \n",
            "2      3.647059               2     27.199043       16.761609      148.726  \n",
            "3      5.705882               3     27.121750       16.712208      148.679  \n",
            "4      6.705882               2     27.015839       16.641439      148.848  \n",
            "5      4.764706               4     27.082109       16.679970      148.745  \n",
            "6      8.941176               4     26.416993       16.256034      149.293  \n",
            "7      8.176471               2     26.363111       16.217400      149.262  \n",
            "8     14.823529              19     26.145317       16.080019      149.526  \n",
            "9      9.941176               2     26.169932       16.093808      148.989  \n"
          ]
        }
      ],
      "source": [
        "# Step 10.4: Create driver comparison matrix\n",
        "print(\"=\" * 80)\n",
        "print(\"DRIVER COMPARISON MATRIX\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Combine key metrics for comparison\n",
        "comparison_data = []\n",
        "\n",
        "if 'race_results' in globals() and 'position_stats' in globals() and 'consistency' in globals():\n",
        "    for car_num in sorted(race_results['NUMBER'].unique()):\n",
        "        car_data = {}\n",
        "        car_data['CAR_NUMBER'] = int(car_num)\n",
        "        \n",
        "        # Final position\n",
        "        final = race_results[race_results['NUMBER'] == car_num]\n",
        "        if len(final) > 0:\n",
        "            car_data['FINAL_POSITION'] = int(final['POSITION'].iloc[0])\n",
        "            car_data['TOTAL_LAPS'] = int(final['LAPS'].iloc[0]) if 'LAPS' in final.columns else 0\n",
        "        \n",
        "        # Position stats\n",
        "        pos_stat = position_stats[position_stats['NUMBER'] == car_num]\n",
        "        if len(pos_stat) > 0:\n",
        "            car_data['BEST_POSITION'] = int(pos_stat['BEST_POSITION'].iloc[0])\n",
        "            car_data['WORST_POSITION'] = int(pos_stat['WORST_POSITION'].iloc[0])\n",
        "            car_data['AVG_POSITION'] = float(pos_stat['AVG_POSITION'].iloc[0])\n",
        "            car_data['POSITION_RANGE'] = int(pos_stat['POSITION_RANGE'].iloc[0])\n",
        "        \n",
        "        # Consistency\n",
        "        cons = consistency[consistency['NUMBER'] == car_num]\n",
        "        if len(cons) > 0:\n",
        "            car_data['LAP_TIME_STD'] = float(cons['std_s'].iloc[0])\n",
        "            car_data['CONSISTENCY_CV'] = float(cons['cv_pct'].iloc[0])\n",
        "        \n",
        "        # Fastest lap\n",
        "        if 'LAP_TIME_SECONDS' in lap_analysis.columns:\n",
        "            car_laps = lap_analysis[lap_analysis['NUMBER'] == car_num]\n",
        "            if len(car_laps) > 0:\n",
        "                car_data['FASTEST_LAP'] = float(car_laps['LAP_TIME_SECONDS'].min())\n",
        "        \n",
        "        comparison_data.append(car_data)\n",
        "    \n",
        "    driver_comparison = pd.DataFrame(comparison_data)\n",
        "    driver_comparison = driver_comparison.sort_values('FINAL_POSITION').reset_index(drop=True)\n",
        "    \n",
        "    print(f\"âœ“ Driver comparison matrix created:\")\n",
        "    print(f\"   - Drivers: {len(driver_comparison)}\")\n",
        "    print(f\"\\n   Sample data (top 10):\")\n",
        "    print(driver_comparison.head(10))\n",
        "else:\n",
        "    print(\"âš ï¸  Required data not available\")\n",
        "    driver_comparison = pd.DataFrame()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "KEY MOMENTS TIMELINE (Structured)\n",
            "================================================================================\n",
            "âœ“ Key moments timeline ready:\n",
            "   - Total laps: 17\n",
            "   - Significant moments: 13\n",
            "\n",
            "   Significant moments:\n",
            "    LAP             ACT FLAG                                         NOTES\n",
            "0     1  Act 1: Opening  FCY                    Fastest: Car 46 (221.204s)\n",
            "1     2  Act 1: Opening   GF  Car 15 loses 20 | Fastest: Car 46 (160.534s)\n",
            "2     3  Act 1: Opening   GF   Car 31 loses 6 | Fastest: Car 55 (149.734s)\n",
            "3     4  Act 1: Opening   GF   Car 89 loses 13 | Fastest: Car 7 (149.479s)\n",
            "4     5  Act 1: Opening   GF    Car 89 loses 9 | Fastest: Car 7 (149.056s)\n",
            "6     7   Act 2: Middle   GF   Car 31 gains 27 | Fastest: Car 7 (148.678s)\n",
            "9    10   Act 2: Middle   GF   Car 31 loses 4 | Fastest: Car 55 (148.679s)\n",
            "10   11   Act 2: Middle  FCY    Car 8 gains 1 | Fastest: Car 72 (148.884s)\n",
            "11   12  Act 3: Closing  FCY   Car 3 gains 17 | Fastest: Car 31 (150.680s)\n",
            "12   13  Act 3: Closing   GF   Car 51 loses 6 | Fastest: Car 31 (150.244s)\n"
          ]
        }
      ],
      "source": [
        "# Step 10.5: Create key moments timeline (structured for dashboard)\n",
        "print(\"=\" * 80)\n",
        "print(\"KEY MOMENTS TIMELINE (Structured)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Use timeline from Phase 8, enhance with narrative elements\n",
        "if 'timeline' in globals():\n",
        "    key_moments = timeline.copy()\n",
        "    \n",
        "    # Add act information\n",
        "    if 'race_acts' in globals():\n",
        "        def get_act(lap_num):\n",
        "            if lap_num <= race_acts['ACT1']['end']:\n",
        "                return 'Act 1: Opening'\n",
        "            elif lap_num <= race_acts['ACT2']['end']:\n",
        "                return 'Act 2: Middle'\n",
        "            else:\n",
        "                return 'Act 3: Closing'\n",
        "        \n",
        "        key_moments['ACT'] = key_moments['LAP'].apply(get_act)\n",
        "    \n",
        "    # Mark significant moments\n",
        "    key_moments['IS_SIGNIFICANT'] = False\n",
        "    \n",
        "    # Mark FCY periods\n",
        "    if 'FLAG' in key_moments.columns:\n",
        "        key_moments.loc[key_moments['FLAG'] == 'FCY', 'IS_SIGNIFICANT'] = True\n",
        "    \n",
        "    # Mark big position changes\n",
        "    if 'POS_DELTA' in key_moments.columns:\n",
        "        key_moments.loc[key_moments['POS_DELTA'].abs() >= 3, 'IS_SIGNIFICANT'] = True\n",
        "    \n",
        "    # Mark pit stops\n",
        "    if 'PIT_EVENTS' in key_moments.columns:\n",
        "        key_moments.loc[key_moments['PIT_EVENTS'] > 0, 'IS_SIGNIFICANT'] = True\n",
        "    \n",
        "    print(f\"âœ“ Key moments timeline ready:\")\n",
        "    print(f\"   - Total laps: {len(key_moments)}\")\n",
        "    print(f\"   - Significant moments: {key_moments['IS_SIGNIFICANT'].sum()}\")\n",
        "    print(f\"\\n   Significant moments:\")\n",
        "    significant = key_moments[key_moments['IS_SIGNIFICANT'] == True]\n",
        "    print(significant[['LAP', 'ACT', 'FLAG', 'NOTES']].head(10))\n",
        "else:\n",
        "    print(\"âš ï¸  timeline not available - run Phase 8\")\n",
        "    key_moments = pd.DataFrame()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "RACE STORY TEXT SNIPPETS\n",
            "================================================================================\n",
            "âœ“ Race story snippets created (5 sections):\n",
            "\n",
            "   [Opening]\n",
            "   The race began with 31 drivers competing over 17 laps.\n",
            "\n",
            "   [Winner]\n",
            "   Car #46 claimed victory, finishing in P1. P1 â†’ P1 (Best: P1, Worst: P4)\n",
            "\n",
            "   [Comeback]\n",
            "   Car #71 made the biggest comeback, gaining 19 positions from P29 to P10.\n",
            "\n",
            "   [Fastest Lap]\n",
            "   Car #46 set the fastest lap of 148.630s on Lap 8.\n",
            "\n",
            "   [Flags]\n",
            "   The race featured 3 laps under Full Course Yellow conditions.\n"
          ]
        }
      ],
      "source": [
        "# Step 10.6: Generate race story text snippets\n",
        "print(\"=\" * 80)\n",
        "print(\"RACE STORY TEXT SNIPPETS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "story_snippets = []\n",
        "\n",
        "# Opening summary\n",
        "if 'dashboard_summary' in globals():\n",
        "    story_snippets.append({\n",
        "        'SECTION': 'Opening',\n",
        "        'TEXT': f\"The race began with {dashboard_summary.get('total_drivers', 'N/A')} drivers competing over {dashboard_summary.get('total_laps', 'N/A')} laps.\"\n",
        "    })\n",
        "\n",
        "# Winner story\n",
        "if 'protagonists_df' in globals() and len(protagonists_df) > 0:\n",
        "    winner = protagonists_df.iloc[0]\n",
        "    story_snippets.append({\n",
        "        'SECTION': 'Winner',\n",
        "        'TEXT': f\"Car #{int(winner['CAR_NUMBER'])} claimed victory, finishing in P{int(winner['FINAL_POSITION'])}. {winner['JOURNEY']}\"\n",
        "    })\n",
        "\n",
        "# Biggest comeback\n",
        "if 'position_change' in globals():\n",
        "    comeback = position_change.nlargest(1, 'POSITION_CHANGE')\n",
        "    if len(comeback) > 0:\n",
        "        row = comeback.iloc[0]\n",
        "        story_snippets.append({\n",
        "            'SECTION': 'Comeback',\n",
        "            'TEXT': f\"Car #{int(row['NUMBER'])} made the biggest comeback, gaining {int(row['POSITION_CHANGE'])} positions from P{int(row['START_POSITION'])} to P{int(row['END_POSITION'])}.\"\n",
        "        })\n",
        "\n",
        "# Fastest lap\n",
        "if 'dashboard_summary' in globals() and 'fastest_lap_car' in dashboard_summary:\n",
        "    story_snippets.append({\n",
        "        'SECTION': 'Fastest Lap',\n",
        "        'TEXT': f\"Car #{dashboard_summary['fastest_lap_car']} set the fastest lap of {dashboard_summary['fastest_lap_time']:.3f}s on Lap {dashboard_summary['fastest_lap_lap']}.\"\n",
        "    })\n",
        "\n",
        "# Flag periods\n",
        "if 'dashboard_summary' in globals() and 'fcy_laps' in dashboard_summary:\n",
        "    if dashboard_summary['fcy_laps'] > 0:\n",
        "        story_snippets.append({\n",
        "            'SECTION': 'Flags',\n",
        "            'TEXT': f\"The race featured {dashboard_summary['fcy_laps']} laps under Full Course Yellow conditions.\"\n",
        "        })\n",
        "\n",
        "story_texts = pd.DataFrame(story_snippets)\n",
        "\n",
        "print(f\"âœ“ Race story snippets created ({len(story_texts)} sections):\")\n",
        "for idx, snippet in story_texts.iterrows():\n",
        "    print(f\"\\n   [{snippet['SECTION']}]\")\n",
        "    print(f\"   {snippet['TEXT']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Phase 10 Progress:**\n",
        "âœ… Dashboard summary statistics created (`dashboard_summary`)\n",
        "âœ… Position over time data prepared (`viz_position`)\n",
        "âœ… Sector performance data prepared (`viz_sectors`)\n",
        "âœ… Driver comparison matrix created (`driver_comparison`)\n",
        "âœ… Key moments timeline structured (`key_moments`)\n",
        "âœ… Race story text snippets generated (`story_texts`)\n",
        "\n",
        "**All data structures are now ready for dashboard implementation!**\n",
        "\n",
        "**Next:** Phase 11 - Driver Story Arcs (individual driver narratives)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ðŸ“Š Export Data for Dashboard\n",
        "\n",
        "Export all dashboard-ready data structures to CSV/JSON files for the Streamlit dashboard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "EXPORTING DASHBOARD DATA\n",
            "================================================================================\n",
            "\n",
            "âœ“ Created directory: dashboard_data\n",
            "âœ“ Exported viz_position.csv (468 rows)\n",
            "âœ“ Exported viz_sectors.csv (30 rows)\n",
            "âœ“ Exported driver_comparison.csv (30 rows)\n",
            "âœ“ Exported key_moments.csv (17 rows)\n",
            "âœ“ Exported story_texts.csv (5 rows)\n",
            "âœ“ Exported protagonists_df.csv (5 rows)\n",
            "âœ“ Exported turning_points_df.csv (7 rows)\n",
            "âœ“ Exported dashboard_summary.json\n",
            "\n",
            "âœ… Export complete! 8 files exported to 'dashboard_data/'\n",
            "\n",
            "ðŸ“‹ Next steps:\n",
            "   1. Install requirements: pip install -r requirements_dashboard.txt\n",
            "   2. Run dashboard: streamlit run race_story_dashboard.py\n"
          ]
        }
      ],
      "source": [
        "# Export all dashboard data to files\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"EXPORTING DASHBOARD DATA\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Create dashboard_data directory\n",
        "dashboard_dir = Path('dashboard_data')\n",
        "dashboard_dir.mkdir(exist_ok=True)\n",
        "print(f\"\\nâœ“ Created directory: {dashboard_dir}\")\n",
        "\n",
        "# Export CSV files\n",
        "exports = {\n",
        "    'viz_position': 'viz_position.csv',\n",
        "    'viz_sectors': 'viz_sectors.csv',\n",
        "    'driver_comparison': 'driver_comparison.csv',\n",
        "    'key_moments': 'key_moments.csv',\n",
        "    'story_texts': 'story_texts.csv',\n",
        "    'protagonists_df': 'protagonists_df.csv',\n",
        "    'turning_points_df': 'turning_points_df.csv'\n",
        "}\n",
        "\n",
        "exported_count = 0\n",
        "for var_name, filename in exports.items():\n",
        "    if var_name in globals():\n",
        "        var = globals()[var_name]\n",
        "        if isinstance(var, pd.DataFrame) and not var.empty:\n",
        "            filepath = dashboard_dir / filename\n",
        "            var.to_csv(filepath, index=False)\n",
        "            print(f\"âœ“ Exported {filename} ({len(var)} rows)\")\n",
        "            exported_count += 1\n",
        "        else:\n",
        "            print(f\"âš ï¸  {var_name} is empty or not a DataFrame\")\n",
        "    else:\n",
        "        print(f\"âš ï¸  {var_name} not found in globals\")\n",
        "\n",
        "# Export dashboard summary as JSON\n",
        "if 'dashboard_summary' in globals():\n",
        "    summary_file = dashboard_dir / 'dashboard_summary.json'\n",
        "    with open(summary_file, 'w') as f:\n",
        "        json.dump(dashboard_summary, f, indent=2, default=str)\n",
        "    print(f\"âœ“ Exported dashboard_summary.json\")\n",
        "    exported_count += 1\n",
        "else:\n",
        "    print(\"âš ï¸  dashboard_summary not found\")\n",
        "\n",
        "print(f\"\\nâœ… Export complete! {exported_count} files exported to '{dashboard_dir}/'\")\n",
        "print(f\"\\nðŸ“‹ Next steps:\")\n",
        "print(f\"   1. Install requirements: pip install -r requirements_dashboard.txt\")\n",
        "print(f\"   2. Run dashboard: streamlit run race_story_dashboard.py\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
